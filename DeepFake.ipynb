{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28c1cd2862340abf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T14:46:51.413579Z",
     "start_time": "2024-09-02T14:46:31.617927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\r\n",
      "  Downloading scikit_image-0.21.0-cp38-cp38-macosx_12_0_arm64.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: numpy>=1.21.1 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from scikit-image) (1.23.5)\r\n",
      "Requirement already satisfied: scipy>=1.8 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from scikit-image) (1.10.1)\r\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from scikit-image) (3.1)\r\n",
      "Requirement already satisfied: pillow>=9.0.1 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from scikit-image) (10.4.0)\r\n",
      "Collecting imageio>=2.27 (from scikit-image)\r\n",
      "  Downloading imageio-2.35.1-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\r\n",
      "  Downloading tifffile-2023.7.10-py3-none-any.whl.metadata (31 kB)\r\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image)\r\n",
      "  Downloading PyWavelets-1.4.1-cp38-cp38-macosx_11_0_arm64.whl.metadata (1.9 kB)\r\n",
      "Requirement already satisfied: packaging>=21 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from scikit-image) (24.1)\r\n",
      "Collecting lazy_loader>=0.2 (from scikit-image)\r\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\r\n",
      "Downloading scikit_image-0.21.0-cp38-cp38-macosx_12_0_arm64.whl (12.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\r\n",
      "\u001b[?25hDownloading imageio-2.35.1-py3-none-any.whl (315 kB)\r\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\r\n",
      "Downloading PyWavelets-1.4.1-cp38-cp38-macosx_11_0_arm64.whl (4.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\r\n",
      "\u001b[?25hDownloading tifffile-2023.7.10-py3-none-any.whl (220 kB)\r\n",
      "Installing collected packages: tifffile, PyWavelets, lazy_loader, imageio, scikit-image\r\n",
      "Successfully installed PyWavelets-1.4.1 imageio-2.35.1 lazy_loader-0.4 scikit-image-0.21.0 tifffile-2023.7.10\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db8d1d25665004",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T19:08:25.750873Z",
     "start_time": "2024-09-02T19:08:25.029914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (2.4.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (0.19.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (3.7.5)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from torch) (3.15.4)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from torch) (4.11.0)\r\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from torch) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from torch) (2024.6.1)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from torchvision) (1.23.5)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from torchvision) (10.4.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from matplotlib) (1.1.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from matplotlib) (4.53.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from matplotlib) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from matplotlib) (24.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from matplotlib) (3.1.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from matplotlib) (6.4.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffc14c3113c30248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T14:31:07.084533Z",
     "start_time": "2024-09-02T14:30:55.293398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\r\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-macosx_12_0_arm64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from scikit-learn) (1.23.5)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\r\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\r\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\r\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Downloading scikit_learn-1.3.2-cp38-cp38-macosx_12_0_arm64.whl (9.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\r\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\r\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\r\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\r\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.3.2 threadpoolctl-3.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7458b7ee73e44405",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T13:41:21.558853Z",
     "start_time": "2024-09-02T13:41:04.465298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (4.10.0.84)\r\n",
      "Collecting pillow\r\n",
      "  Downloading pillow-10.4.0-cp38-cp38-macosx_11_0_arm64.whl.metadata (9.2 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (1.23.5)\r\n",
      "Collecting matplotlib\r\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-macosx_11_0_arm64.whl.metadata (5.7 kB)\r\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\r\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-macosx_11_0_arm64.whl.metadata (5.9 kB)\r\n",
      "Collecting cycler>=0.10 (from matplotlib)\r\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\r\n",
      "  Downloading fonttools-4.53.1-cp38-cp38-macosx_11_0_arm64.whl.metadata (162 kB)\r\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\r\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-macosx_11_0_arm64.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from matplotlib) (24.1)\r\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\r\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from matplotlib) (6.4.0)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/Implementation/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "Downloading pillow-10.4.0-cp38-cp38-macosx_11_0_arm64.whl (3.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hDownloading matplotlib-3.7.5-cp38-cp38-macosx_11_0_arm64.whl (7.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\r\n",
      "\u001b[?25hDownloading contourpy-1.1.1-cp38-cp38-macosx_11_0_arm64.whl (232 kB)\r\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\r\n",
      "Downloading fonttools-4.53.1-cp38-cp38-macosx_11_0_arm64.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp38-cp38-macosx_11_0_arm64.whl (66 kB)\r\n",
      "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\r\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\r\n",
      "Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.53.1 kiwisolver-1.4.5 matplotlib-3.7.5 pillow-10.4.0 pyparsing-3.1.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python pillow numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T04:57:28.697680Z",
     "start_time": "2024-09-03T03:16:11.501625Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete for train_sample_videos/cdaxixbosp.mp4\n",
      "Processing complete for train_sample_videos/btiysiskpf.mp4\n",
      "Processing complete for train_sample_videos/clihsshdkq.mp4\n",
      "Processing complete for train_sample_videos/alvgwypubw.mp4\n",
      "Processing complete for train_sample_videos/eqvuznuwsa.mp4\n",
      "Processing complete for train_sample_videos/eudeqjhdfd.mp4\n",
      "Processing complete for train_sample_videos/eeyhxisdfh.mp4\n",
      "Processing complete for train_sample_videos/cizlkenljw.mp4\n",
      "Processing complete for train_sample_videos/bndybcqhfr.mp4\n",
      "Processing complete for train_sample_videos/cuzrgrbvil.mp4\n",
      "Processing complete for train_sample_videos/atyntldecu.mp4\n",
      "Processing complete for train_sample_videos/bggsurpgpr.mp4\n",
      "Processing complete for train_sample_videos/eckvhdusax.mp4\n",
      "Processing complete for train_sample_videos/dvakowbgbt.mp4\n",
      "Processing complete for train_sample_videos/dqqtjcryjv.mp4\n",
      "Processing complete for train_sample_videos/djvutyvaio.mp4\n",
      "Processing complete for train_sample_videos/dzwkmcwkwl.mp4\n",
      "Processing complete for train_sample_videos/bpapbctoao.mp4\n",
      "Processing complete for train_sample_videos/aettqgevhz.mp4\n",
      "Processing complete for train_sample_videos/bbhtdfuqxq.mp4\n",
      "Processing complete for train_sample_videos/caifxvsozs.mp4\n",
      "Processing complete for train_sample_videos/bgaogsjehq.mp4\n",
      "Processing complete for train_sample_videos/agqphdxmwt.mp4\n",
      "Processing complete for train_sample_videos/ebywfrmhtd.mp4\n",
      "Processing complete for train_sample_videos/bsqgziaylx.mp4\n",
      "Processing complete for train_sample_videos/ciyoudyhly.mp4\n",
      "Processing complete for train_sample_videos/bxzakyopjf.mp4\n",
      "Processing complete for train_sample_videos/cknyxaqouy.mp4\n",
      "Processing complete for train_sample_videos/avnqydkqjj.mp4\n",
      "Processing complete for train_sample_videos/dakiztgtnw.mp4\n",
      "Processing complete for train_sample_videos/acifjvzvpm.mp4\n",
      "Processing complete for train_sample_videos/dofusvhnib.mp4\n",
      "Processing complete for train_sample_videos/ahqqqilsxt.mp4\n",
      "Processing complete for train_sample_videos/avtycwsgyb.mp4\n",
      "Processing complete for train_sample_videos/cvaksbpssm.mp4\n",
      "Processing complete for train_sample_videos/brwrlczjvi.mp4\n",
      "Processing complete for train_sample_videos/bgwmmujlmc.mp4\n",
      "Processing complete for train_sample_videos/dhkwmjxwrn.mp4\n",
      "Processing complete for train_sample_videos/bmjmjmbglm.mp4\n",
      "Processing complete for train_sample_videos/emgjphonqb.mp4\n",
      "Processing complete for train_sample_videos/bzmdrafeex.mp4\n",
      "Processing complete for train_sample_videos/dsgpbgsrdm.mp4\n",
      "Processing complete for train_sample_videos/afoovlsmtx.mp4\n",
      "Processing complete for train_sample_videos/ebeknhudxq.mp4\n",
      "Processing complete for train_sample_videos/ccfoszqabv.mp4\n",
      "Processing complete for train_sample_videos/dnexlwbcxq.mp4\n",
      "Processing complete for train_sample_videos/ensyyivobf.mp4\n",
      "Processing complete for train_sample_videos/apgjqzkoma.mp4\n",
      "Processing complete for train_sample_videos/bqeiblbxtl.mp4\n",
      "Processing complete for train_sample_videos/eqjscdagiv.mp4\n",
      "Processing complete for train_sample_videos/ejkqesyvam.mp4\n",
      "Processing complete for train_sample_videos/bilnggbxgu.mp4\n",
      "Processing complete for train_sample_videos/bulkxhhknf.mp4\n",
      "Processing complete for train_sample_videos/cdphtzqrvp.mp4\n",
      "Processing complete for train_sample_videos/cmxcfkrjiv.mp4\n",
      "Processing complete for train_sample_videos/cwsbspfzck.mp4\n",
      "Processing complete for train_sample_videos/bsfmwclnqy.mp4\n",
      "Processing complete for train_sample_videos/ajqslcypsw.mp4\n",
      "Processing complete for train_sample_videos/eebrkicpry.mp4\n",
      "Processing complete for train_sample_videos/aklqzsddfl.mp4\n",
      "Processing complete for train_sample_videos/aqpnvjhuzw.mp4\n",
      "Processing complete for train_sample_videos/bvzjkezkms.mp4\n",
      "Processing complete for train_sample_videos/bmhvktyiwp.mp4\n",
      "Processing complete for train_sample_videos/acxnxvbsxk.mp4\n",
      "Processing complete for train_sample_videos/cyboodqqyr.mp4\n",
      "Processing complete for train_sample_videos/czkdanyadc.mp4\n",
      "Processing complete for train_sample_videos/esgftaficx.mp4\n",
      "Processing complete for train_sample_videos/aagfhgtpmv.mp4\n",
      "Processing complete for train_sample_videos/bmbbkwmxqj.mp4\n",
      "Processing complete for train_sample_videos/dqnyszdong.mp4\n",
      "Processing complete for train_sample_videos/btunxncpjh.mp4\n",
      "Processing complete for train_sample_videos/bnbuonyoje.mp4\n",
      "Processing complete for train_sample_videos/bhpwpydzpo.mp4\n",
      "Processing complete for train_sample_videos/bbvgxeczei.mp4\n",
      "Processing complete for train_sample_videos/apogckdfrz.mp4\n",
      "Processing complete for train_sample_videos/esnntzzajv.mp4\n",
      "Processing complete for train_sample_videos/chzieimrwu.mp4\n",
      "Processing complete for train_sample_videos/dhcndnuwta.mp4\n",
      "Processing complete for train_sample_videos/awukslzjra.mp4\n",
      "Processing complete for train_sample_videos/amowujxmzc.mp4\n",
      "Processing complete for train_sample_videos/dbhoxkblzx.mp4\n",
      "Processing complete for train_sample_videos/akvmwkdyuv.mp4\n",
      "Processing complete for train_sample_videos/bqnymlsayl.mp4\n",
      "Processing complete for train_sample_videos/aevrfsexku.mp4\n",
      "Processing complete for train_sample_videos/abqwwspghj.mp4\n",
      "Processing complete for train_sample_videos/byofowlkki.mp4\n",
      "Processing complete for train_sample_videos/cycacemkmt.mp4\n",
      "Processing complete for train_sample_videos/arkroixhey.mp4\n",
      "Processing complete for train_sample_videos/asmpfjfzif.mp4\n",
      "Processing complete for train_sample_videos/eprybmbpba.mp4\n",
      "Processing complete for train_sample_videos/btugrnoton.mp4\n",
      "Processing complete for train_sample_videos/bwipwzzxxu.mp4\n",
      "Processing complete for train_sample_videos/cwwandrkus.mp4\n",
      "Processing complete for train_sample_videos/emaalmsonj.mp4\n",
      "Processing complete for train_sample_videos/bqkdbcqjvb.mp4\n",
      "Processing complete for train_sample_videos/aytzyidmgs.mp4\n",
      "Processing complete for train_sample_videos/avssvvsdhz.mp4\n",
      "Processing complete for train_sample_videos/avibnnhwhp.mp4\n",
      "Processing complete for train_sample_videos/bchnbulevv.mp4\n",
      "Processing complete for train_sample_videos/btohlidmru.mp4\n",
      "Processing complete for train_sample_videos/elginszwtk.mp4\n",
      "Processing complete for train_sample_videos/augtsuxpzc.mp4\n",
      "Processing complete for train_sample_videos/andaxzscny.mp4\n",
      "Processing complete for train_sample_videos/dulanfulol.mp4\n",
      "Processing complete for train_sample_videos/crktehraph.mp4\n",
      "Processing complete for train_sample_videos/alninxcyhg.mp4\n",
      "Processing complete for train_sample_videos/ecujsjhscd.mp4\n",
      "Processing complete for train_sample_videos/bwuwstvsbw.mp4\n",
      "Processing complete for train_sample_videos/doanjploai.mp4\n",
      "Processing complete for train_sample_videos/aelzhcnwgf.mp4\n",
      "Processing complete for train_sample_videos/efdyrflcpg.mp4\n",
      "Processing complete for train_sample_videos/aknbdpmgua.mp4\n",
      "Processing complete for train_sample_videos/agrmhtjdlk.mp4\n",
      "Processing complete for train_sample_videos/aapnvogymq.mp4\n",
      "Processing complete for train_sample_videos/edyncaijwx.mp4\n",
      "Processing complete for train_sample_videos/bweezhfpzp.mp4\n",
      "Processing complete for train_sample_videos/avywawptfc.mp4\n",
      "Processing complete for train_sample_videos/brvqtabyxj.mp4\n",
      "Processing complete for train_sample_videos/cpjxareypw.mp4\n",
      "Processing complete for train_sample_videos/cobjrlugvp.mp4\n",
      "Processing complete for train_sample_videos/ehtdtkmmli.mp4\n",
      "Processing complete for train_sample_videos/eajlrktemq.mp4\n",
      "Processing complete for train_sample_videos/aknmpoonls.mp4\n",
      "Processing complete for train_sample_videos/ceymbecxnj.mp4\n",
      "Processing complete for train_sample_videos/agdkmztvby.mp4\n",
      "Processing complete for train_sample_videos/aczrgyricp.mp4\n",
      "Processing complete for train_sample_videos/ebebgmtlcu.mp4\n",
      "Processing complete for train_sample_videos/btmsngnqhv.mp4\n",
      "Processing complete for train_sample_videos/btjlfpzbdu.mp4\n",
      "Processing complete for train_sample_videos/crzfebnfgb.mp4\n",
      "Processing complete for train_sample_videos/dcamvmuors.mp4\n",
      "Processing complete for train_sample_videos/bntlodcfeg.mp4\n",
      "Processing complete for train_sample_videos/abofeumbvv.mp4\n",
      "Processing complete for train_sample_videos/dcuiiorugd.mp4\n",
      "Processing complete for train_sample_videos/axczxisdtb.mp4\n",
      "Processing complete for train_sample_videos/cwrtyzndpx.mp4\n",
      "Processing complete for train_sample_videos/anpuvshzoo.mp4\n",
      "Processing complete for train_sample_videos/czfunozvwp.mp4\n",
      "Processing complete for train_sample_videos/bmehkyanbj.mp4\n",
      "Processing complete for train_sample_videos/eukvucdetx.mp4\n",
      "Processing complete for train_sample_videos/cqhngvpgyi.mp4\n",
      "Processing complete for train_sample_videos/cwbacdwrzo.mp4\n",
      "Processing complete for train_sample_videos/bguwlyazau.mp4\n",
      "Processing complete for train_sample_videos/byyqectxqa.mp4\n",
      "Processing complete for train_sample_videos/bahdpoesir.mp4\n",
      "Processing complete for train_sample_videos/dgxrqjdomn.mp4\n",
      "Processing complete for train_sample_videos/ctzmavwror.mp4\n",
      "Processing complete for train_sample_videos/dkrvorliqc.mp4\n",
      "Processing complete for train_sample_videos/etejaapnxh.mp4\n",
      "Processing complete for train_sample_videos/caqbrkogkb.mp4\n",
      "Processing complete for train_sample_videos/bkvetcojbt.mp4\n",
      "Processing complete for train_sample_videos/bdxuhamuqx.mp4\n",
      "Processing complete for train_sample_videos/bqtuuwzdtr.mp4\n",
      "Processing complete for train_sample_videos/bhsluedavd.mp4\n",
      "Processing complete for train_sample_videos/cttqtsjvgn.mp4\n",
      "Processing complete for train_sample_videos/covdcysmbi.mp4\n",
      "Processing complete for train_sample_videos/cthdnahrkh.mp4\n",
      "Processing complete for train_sample_videos/btjwbtsgln.mp4\n",
      "Processing complete for train_sample_videos/axwovszumc.mp4\n",
      "Processing complete for train_sample_videos/brhalypwoo.mp4\n",
      "Processing complete for train_sample_videos/cffffbcywc.mp4\n",
      "Processing complete for train_sample_videos/dzqwgqewhu.mp4\n",
      "Processing complete for train_sample_videos/adohikbdaz.mp4\n",
      "Processing complete for train_sample_videos/adylbeequz.mp4\n",
      "Processing complete for train_sample_videos/eqnoqyfquo.mp4\n",
      "Processing complete for train_sample_videos/dhevettufk.mp4\n",
      "Processing complete for train_sample_videos/ebkzwjgjhq.mp4\n",
      "Processing complete for train_sample_videos/cqrskwiqng.mp4\n",
      "Processing complete for train_sample_videos/eejswgycjc.mp4\n",
      "Processing complete for train_sample_videos/boovltmuwi.mp4\n",
      "Processing complete for train_sample_videos/cwqlvzefpg.mp4\n",
      "Processing complete for train_sample_videos/aorjvbyxhw.mp4\n",
      "Processing complete for train_sample_videos/ecnihjlfyt.mp4\n",
      "Processing complete for train_sample_videos/avfitoutyn.mp4\n",
      "Processing complete for train_sample_videos/eahlqmfvtj.mp4\n",
      "Processing complete for train_sample_videos/adhsbajydo.mp4\n",
      "Processing complete for train_sample_videos/ehfiekigla.mp4\n",
      "Processing complete for train_sample_videos/bdnaqemxmr.mp4\n",
      "Processing complete for train_sample_videos/asvcrfdpnq.mp4\n",
      "Processing complete for train_sample_videos/chtapglbcj.mp4\n",
      "Processing complete for train_sample_videos/bourlmzsio.mp4\n",
      "Processing complete for train_sample_videos/etmcruaihe.mp4\n",
      "Processing complete for train_sample_videos/acxwigylke.mp4\n",
      "Processing complete for train_sample_videos/atkdltyyen.mp4\n",
      "Processing complete for train_sample_videos/dbhrpizyeq.mp4\n",
      "Processing complete for train_sample_videos/ccmonzqfrz.mp4\n",
      "Processing complete for train_sample_videos/ahbweevwpv.mp4\n",
      "Processing complete for train_sample_videos/dntkzzzcdh.mp4\n",
      "Processing complete for train_sample_videos/bbhpvrmbse.mp4\n",
      "Processing complete for train_sample_videos/dakqwktlbi.mp4\n",
      "Processing complete for train_sample_videos/benmsfzfaz.mp4\n",
      "Processing complete for train_sample_videos/etdcqxabww.mp4\n",
      "Processing complete for train_sample_videos/atxvxouljq.mp4\n",
      "Processing complete for train_sample_videos/cgvrgibpfo.mp4\n",
      "Processing complete for train_sample_videos/bghphrsfxf.mp4\n",
      "Processing complete for train_sample_videos/blzydqdfem.mp4\n",
      "Processing complete for train_sample_videos/etohcvnzbj.mp4\n",
      "Processing complete for train_sample_videos/cmbzllswnl.mp4\n",
      "Processing complete for train_sample_videos/cnilkgvfei.mp4\n",
      "Processing complete for train_sample_videos/duzuusuajr.mp4\n",
      "Processing complete for train_sample_videos/asaxgevnnp.mp4\n",
      "Processing complete for train_sample_videos/egghxjjmfg.mp4\n",
      "Processing complete for train_sample_videos/bdgipnyobr.mp4\n",
      "Processing complete for train_sample_videos/eepezmygaq.mp4\n",
      "Processing complete for train_sample_videos/curpwogllm.mp4\n",
      "Processing complete for train_sample_videos/diopzaywor.mp4\n",
      "Processing complete for train_sample_videos/chviwxsfhg.mp4\n",
      "Processing complete for train_sample_videos/bmjzrlszhi.mp4\n",
      "Processing complete for train_sample_videos/dwediigjit.mp4\n",
      "Processing complete for train_sample_videos/cyclgfjdrv.mp4\n",
      "Processing complete for train_sample_videos/cettndmvzl.mp4\n",
      "Processing complete for train_sample_videos/ddhfabwpuz.mp4\n",
      "Processing complete for train_sample_videos/drgjzlxzxj.mp4\n",
      "Processing complete for train_sample_videos/dbtbbhakdv.mp4\n",
      "Processing complete for train_sample_videos/bjjbwsqjir.mp4\n",
      "Processing complete for train_sample_videos/dsdoseflas.mp4\n",
      "Processing complete for train_sample_videos/dsjbknkujw.mp4\n",
      "Processing complete for train_sample_videos/dhjmzhrcav.mp4\n",
      "Processing complete for train_sample_videos/dptbnjnkdg.mp4\n",
      "Processing complete for train_sample_videos/ddpvuimigj.mp4\n",
      "Processing complete for train_sample_videos/byfenovjnf.mp4\n",
      "Processing complete for train_sample_videos/asdpeebotb.mp4\n",
      "Processing complete for train_sample_videos/dptrzdvwpg.mp4\n",
      "Processing complete for train_sample_videos/ehieahnhte.mp4\n",
      "Processing complete for train_sample_videos/awnwkrqibf.mp4\n",
      "Processing complete for train_sample_videos/axoygtekut.mp4\n",
      "Processing complete for train_sample_videos/esxrvsgpvb.mp4\n",
      "Processing complete for train_sample_videos/bpxckdzddv.mp4\n",
      "Processing complete for train_sample_videos/dzieklokdr.mp4\n",
      "Processing complete for train_sample_videos/dkdwxmtpuo.mp4\n",
      "Processing complete for train_sample_videos/ckkuyewywx.mp4\n",
      "Processing complete for train_sample_videos/abarnvbtwb.mp4\n",
      "Processing complete for train_sample_videos/bydaidkpdp.mp4\n",
      "Processing complete for train_sample_videos/byijojkdba.mp4\n",
      "Processing complete for train_sample_videos/cglxirfaey.mp4\n",
      "Processing complete for train_sample_videos/cxfujlvsuw.mp4\n",
      "Processing complete for train_sample_videos/dkuayagnmc.mp4\n",
      "Processing complete for train_sample_videos/duycddgtrl.mp4\n",
      "Processing complete for train_sample_videos/ekcrtigpab.mp4\n",
      "Processing complete for train_sample_videos/amaivqofda.mp4\n",
      "Processing complete for train_sample_videos/ehdkmxgtxh.mp4\n",
      "Processing complete for train_sample_videos/byqzyxifza.mp4\n",
      "Processing complete for train_sample_videos/diomeixhrg.mp4\n",
      "Processing complete for train_sample_videos/dxbqjxrhin.mp4\n",
      "Processing complete for train_sample_videos/beboztfcme.mp4\n",
      "Processing complete for train_sample_videos/coadfnerlk.mp4\n",
      "Processing complete for train_sample_videos/drsakwyvqv.mp4\n",
      "Processing complete for train_sample_videos/errocgcham.mp4\n",
      "Processing complete for train_sample_videos/clrycekyst.mp4\n",
      "Processing complete for train_sample_videos/bffwsjxghk.mp4\n",
      "Processing complete for train_sample_videos/arrhsnjqku.mp4\n",
      "Processing complete for train_sample_videos/emfbhytfhc.mp4\n",
      "Processing complete for train_sample_videos/aladcziidp.mp4\n",
      "Processing complete for train_sample_videos/bmioepcpsx.mp4\n",
      "Processing complete for train_sample_videos/bqhtpqmmqp.mp4\n",
      "Processing complete for train_sample_videos/bopqhhalml.mp4\n",
      "Processing complete for train_sample_videos/ctpqeykqdp.mp4\n",
      "Processing complete for train_sample_videos/ayqvfdhslr.mp4\n",
      "Processing complete for train_sample_videos/dxuplhwvig.mp4\n",
      "Processing complete for train_sample_videos/eekozbeafq.mp4\n",
      "Processing complete for train_sample_videos/bkmdzhfzfh.mp4\n",
      "Processing complete for train_sample_videos/ecwaxgutkc.mp4\n",
      "Processing complete for train_sample_videos/cppdvdejkc.mp4\n",
      "Processing complete for train_sample_videos/dqzreruvje.mp4\n",
      "Processing complete for train_sample_videos/avgiuextiz.mp4\n",
      "Processing complete for train_sample_videos/arlmiizoob.mp4\n",
      "Processing complete for train_sample_videos/cxttmymlbn.mp4\n",
      "Processing complete for train_sample_videos/ahdbuwqxit.mp4\n",
      "Processing complete for train_sample_videos/cferslmfwh.mp4\n",
      "Processing complete for train_sample_videos/dlpoieqvfb.mp4\n",
      "Processing complete for train_sample_videos/akxoopqjqz.mp4\n",
      "Processing complete for train_sample_videos/dsndhujjjb.mp4\n",
      "Processing complete for train_sample_videos/axntxmycwd.mp4\n",
      "Processing complete for train_sample_videos/dbzpcjntve.mp4\n",
      "Processing complete for train_sample_videos/ckjaibzfxa.mp4\n",
      "Processing complete for train_sample_videos/bseamdrpbj.mp4\n",
      "Processing complete for train_sample_videos/dnhvalzvrt.mp4\n",
      "Processing complete for train_sample_videos/deywhkarol.mp4\n",
      "Processing complete for train_sample_videos/cdyakrxkia.mp4\n",
      "Processing complete for train_sample_videos/dhoqofwoxa.mp4\n",
      "Processing complete for train_sample_videos/eiriyukqqy.mp4\n",
      "Processing complete for train_sample_videos/deyyistcrd.mp4\n",
      "Processing complete for train_sample_videos/awhmfnnjih.mp4\n",
      "Processing complete for train_sample_videos/dvumqqhoac.mp4\n",
      "Processing complete for train_sample_videos/cfxkpiweqt.mp4\n",
      "Processing complete for train_sample_videos/eivxffliio.mp4\n",
      "Processing complete for train_sample_videos/dfbpceeaox.mp4\n",
      "Processing complete for train_sample_videos/dtocdfbwca.mp4\n",
      "Processing complete for train_sample_videos/diuzrpqjli.mp4\n",
      "Processing complete for train_sample_videos/dbzcqmxzaj.mp4\n",
      "Processing complete for train_sample_videos/bjkmjilrxp.mp4\n",
      "Processing complete for train_sample_videos/czmqpxrqoh.mp4\n",
      "Processing complete for train_sample_videos/aelfnikyqj.mp4\n",
      "Processing complete for train_sample_videos/cqfugiqupm.mp4\n",
      "Processing complete for train_sample_videos/bejhvclboh.mp4\n",
      "Processing complete for train_sample_videos/bddjdhzfze.mp4\n",
      "Processing complete for train_sample_videos/bctvsmddgq.mp4\n",
      "Processing complete for train_sample_videos/degpbqvcay.mp4\n",
      "Processing complete for train_sample_videos/duvyaxbzvp.mp4\n",
      "Processing complete for train_sample_videos/bqqpbzjgup.mp4\n",
      "Processing complete for train_sample_videos/ehbnclaukr.mp4\n",
      "Processing complete for train_sample_videos/ddjggcasdw.mp4\n",
      "Processing complete for train_sample_videos/cepxysienc.mp4\n",
      "Processing complete for train_sample_videos/btxlttbpkj.mp4\n",
      "Processing complete for train_sample_videos/bofqajtwve.mp4\n",
      "Processing complete for train_sample_videos/aybumesmpk.mp4\n",
      "Processing complete for train_sample_videos/axwgcsyphv.mp4\n",
      "Processing complete for train_sample_videos/cfyduhpbps.mp4\n",
      "Processing complete for train_sample_videos/ckbdwedgmc.mp4\n",
      "Processing complete for train_sample_videos/crezycjqyk.mp4\n",
      "Processing complete for train_sample_videos/dboxtiehng.mp4\n",
      "Processing complete for train_sample_videos/ekhacizpah.mp4\n",
      "Processing complete for train_sample_videos/cprhtltsjp.mp4\n",
      "Processing complete for train_sample_videos/bzythlfnhq.mp4\n",
      "Processing complete for train_sample_videos/elvvackpjh.mp4\n",
      "Processing complete for train_sample_videos/ebchwmwayp.mp4\n",
      "Processing complete for train_sample_videos/bjsmaqefoi.mp4\n",
      "Processing complete for train_sample_videos/aufmsmnoye.mp4\n",
      "Processing complete for train_sample_videos/esyhwdfnxs.mp4\n",
      "Processing complete for train_sample_videos/dzvyfiarrq.mp4\n",
      "Processing complete for train_sample_videos/cdbsbdymzd.mp4\n",
      "Processing complete for train_sample_videos/bpwzipqtxf.mp4\n",
      "Processing complete for train_sample_videos/bnjcdrfuov.mp4\n",
      "Processing complete for train_sample_videos/ajwpjhrbcv.mp4\n",
      "Processing complete for train_sample_videos/aybgughjxh.mp4\n",
      "Processing complete for train_sample_videos/efwfxwwlbw.mp4\n",
      "Processing complete for train_sample_videos/bwhlgysghg.mp4\n",
      "Processing complete for train_sample_videos/akzbnazxtz.mp4\n",
      "Processing complete for train_sample_videos/azpuxunqyo.mp4\n",
      "Processing complete for train_sample_videos/cksanfsjhc.mp4\n",
      "Processing complete for train_sample_videos/bgmlwsoamc.mp4\n",
      "Processing complete for train_sample_videos/cxrfacemmq.mp4\n",
      "Processing complete for train_sample_videos/eggbjzxnmg.mp4\n",
      "Processing complete for train_sample_videos/eoewqcpbgt.mp4\n",
      "Processing complete for train_sample_videos/drtbksnpol.mp4\n",
      "Processing complete for train_sample_videos/dqppxmoqdl.mp4\n",
      "Processing complete for train_sample_videos/dhcselezer.mp4\n",
      "Processing complete for train_sample_videos/bvgwelbeof.mp4\n",
      "Processing complete for train_sample_videos/bqdjzqhcft.mp4\n",
      "Processing complete for train_sample_videos/aslsvlvpth.mp4\n",
      "Processing complete for train_sample_videos/ddqccgmtka.mp4\n",
      "Processing complete for train_sample_videos/dgmevclvzy.mp4\n",
      "Processing complete for train_sample_videos/altziddtxi.mp4\n",
      "Processing complete for train_sample_videos/dhxctgyoqj.mp4\n",
      "Processing complete for train_sample_videos/ahfazfbntc.mp4\n",
      "Processing complete for train_sample_videos/djvtbgwdcc.mp4\n",
      "Processing complete for train_sample_videos/dgzklxjmix.mp4\n",
      "Processing complete for train_sample_videos/alaijyygdv.mp4\n",
      "Processing complete for train_sample_videos/eebserckhh.mp4\n",
      "Processing complete for train_sample_videos/erqgqacbqe.mp4\n",
      "Processing complete for train_sample_videos/avvdgsennp.mp4\n",
      "Processing complete for train_sample_videos/dkzvdrzcnr.mp4\n",
      "Processing complete for train_sample_videos/ekkdjkirzq.mp4\n",
      "Processing complete for train_sample_videos/apatcsqejh.mp4\n",
      "Processing complete for train_sample_videos/djxdyjopjd.mp4\n",
      "Processing complete for train_sample_videos/bhaaboftbc.mp4\n",
      "Processing complete for train_sample_videos/blpchvmhxx.mp4\n",
      "Processing complete for train_sample_videos/bhbdugnurr.mp4\n",
      "Processing complete for train_sample_videos/aipfdnwpoo.mp4\n",
      "Processing complete for train_sample_videos/drcyabprvt.mp4\n",
      "Processing complete for train_sample_videos/bdbhekrrwo.mp4\n",
      "Processing complete for train_sample_videos/ehccixxzoe.mp4\n",
      "Processing complete for train_sample_videos/eixwxvxbbn.mp4\n",
      "Processing complete for train_sample_videos/atvmxvwyns.mp4\n",
      "Processing complete for train_sample_videos/cyxlcuyznd.mp4\n",
      "Processing complete for train_sample_videos/dozyddhild.mp4\n",
      "Processing complete for train_sample_videos/bgvhtpzknn.mp4\n",
      "Processing complete for train_sample_videos/cbbibzcoih.mp4\n",
      "Processing complete for train_sample_videos/atzdznmder.mp4\n",
      "Processing complete for train_sample_videos/eiwopxzjfn.mp4\n",
      "Processing complete for train_sample_videos/esyrimvzsa.mp4\n",
      "Processing complete for train_sample_videos/cbltdtxglo.mp4\n",
      "Processing complete for train_sample_videos/dbnygxtwek.mp4\n",
      "Processing complete for train_sample_videos/dubiroskqn.mp4\n",
      "Processing complete for train_sample_videos/bkwxhglwct.mp4\n",
      "Processing complete for train_sample_videos/azsmewqghg.mp4\n",
      "Processing complete for train_sample_videos/aneclqfpbt.mp4\n",
      "Processing complete for train_sample_videos/ehevsxtecd.mp4\n",
      "Processing complete for train_sample_videos/dnyvfblxpm.mp4\n",
      "Processing complete for train_sample_videos/dkhlttuvmx.mp4\n",
      "Processing complete for train_sample_videos/erlvuvjsjf.mp4\n",
      "Processing complete for train_sample_videos/dtbpmdqvao.mp4\n",
      "Processing complete for train_sample_videos/beyebyhrph.mp4\n",
      "Processing complete for train_sample_videos/epymyyiblu.mp4\n",
      "Processing complete for train_sample_videos/dzyuwjkjui.mp4\n",
      "Processing complete for train_sample_videos/dxuliowugt.mp4\n",
      "Processing complete for train_sample_videos/ecuvtoltue.mp4\n",
      "Processing complete for train_sample_videos/dqswpjoepo.mp4\n",
      "Processing complete for train_sample_videos/acqfdwsrhi.mp4\n",
      "Processing complete for train_sample_videos/diqraixiov.mp4\n",
      "Processing complete for train_sample_videos/ellavthztb.mp4\n",
      "Processing complete for train_sample_videos/avmjormvsx.mp4\n",
      "Processing complete for train_sample_videos/egbbcxcuqy.mp4\n",
      "Processing complete for train_sample_videos/byunigvnay.mp4\n",
      "Processing complete for train_sample_videos/ddepeddixj.mp4\n",
      "Processing complete for train_sample_videos/dkwjwbwgey.mp4\n",
      "Processing complete for train_sample_videos/esckbnkkvb.mp4\n",
      "Processing complete for train_sample_videos/eczrseixwq.mp4\n",
      "Processing complete for train_sample_videos/dlrsbscitn.mp4\n",
      "Processing complete for train_sample_videos/dafhtipaml.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def resize_frame(frame, scale_factor=0.5):\n",
    "    height, width = frame.shape[:2]\n",
    "    new_size = (int(width * scale_factor), int(height * scale_factor))\n",
    "    resized_frame = cv2.resize(frame, new_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "    return resized_frame\n",
    "\n",
    "def apply_ela(image_path, scale_factor=0.5):\n",
    "    original = Image.open(image_path)\n",
    "    original = original.convert(\"RGB\")\n",
    "\n",
    "    # Resize image\n",
    "    resized = original.resize((int(original.width * scale_factor), int(original.height * scale_factor)), Image.Resampling.LANCZOS)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    original_np = np.array(original)\n",
    "    resized_np = np.array(resized)\n",
    "\n",
    "    # Calculate error level\n",
    "    error_level = ImageChops.difference(Image.fromarray(original_np), Image.fromarray(resized_np))\n",
    "\n",
    "    # Convert error level image to numpy array\n",
    "    error_level_np = np.array(error_level)\n",
    "\n",
    "    # Calculate the mean error level value\n",
    "    mean_error = np.mean(error_level_np)\n",
    "\n",
    "    return mean_error\n",
    "\n",
    "def process_videos(video_folder, output_folder):\n",
    "    # Create the output base directory if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Get all video files in the specified folder\n",
    "    video_files = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "\n",
    "    for video_file in video_files:\n",
    "        # Create a subfolder for each video\n",
    "        video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
    "        video_output_folder = os.path.join(output_folder, video_name)\n",
    "        if not os.path.exists(video_output_folder):\n",
    "            os.makedirs(video_output_folder)\n",
    "\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video file {video_file}\")\n",
    "            continue\n",
    "\n",
    "        frame_number = 0\n",
    "        mean_errors = []\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Resize frame\n",
    "            resized_frame = resize_frame(frame)\n",
    "\n",
    "            # Save resized frame\n",
    "            frame_filename = os.path.join(video_output_folder, f\"frame_{frame_number}.png\")\n",
    "            cv2.imwrite(frame_filename, resized_frame)\n",
    "\n",
    "            # Calculate ELA and get mean error level\n",
    "            mean_error = apply_ela(frame_filename)\n",
    "            mean_errors.append(mean_error)\n",
    "\n",
    "            frame_number += 1\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"Processing complete for {video_file}\")\n",
    "\n",
    "        # Plotting the mean error levels\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(mean_errors, label=f'Error Level - {video_name}')\n",
    "        plt.xlabel('Frame Number')\n",
    "        plt.ylabel('Mean Error Level')\n",
    "        plt.title(f'Mean Error Level Across Frames for {video_name}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(video_output_folder, 'error_level_plot.png'))\n",
    "        plt.close()\n",
    "\n",
    "# Example usage\n",
    "video_folder = \"train_sample_videos\"\n",
    "output_folder = \"output_frames\"\n",
    "\n",
    "process_videos(video_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a062c15fb4d32f73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T04:57:30.290149Z",
     "start_time": "2024-09-03T04:57:28.724489Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bcaa01cfcfbbe9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T04:57:30.481335Z",
     "start_time": "2024-09-03T04:57:30.318174Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Remove the final classification layer to get the feature extraction model\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b0f10b44843d1de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T04:57:30.489405Z",
     "start_time": "2024-09-03T04:57:30.487561Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd5a8d3a77628fd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T04:57:39.427668Z",
     "start_time": "2024-09-03T04:57:30.495347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video folder: ahqqqilsxt\n",
      "Processing image: output_frames/ahqqqilsxt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ahqqqilsxt\n",
      "Processing video folder: djvtbgwdcc\n",
      "Processing image: output_frames/djvtbgwdcc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for djvtbgwdcc\n",
      "Processing video folder: atzdznmder\n",
      "Processing image: output_frames/atzdznmder/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for atzdznmder\n",
      "Processing video folder: esyrimvzsa\n",
      "Processing image: output_frames/esyrimvzsa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for esyrimvzsa\n",
      "Processing video folder: dptrzdvwpg\n",
      "Processing image: output_frames/dptrzdvwpg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dptrzdvwpg\n",
      "Processing video folder: bjkmjilrxp\n",
      "Processing image: output_frames/bjkmjilrxp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bjkmjilrxp\n",
      "Processing video folder: dbhrpizyeq\n",
      "Processing image: output_frames/dbhrpizyeq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dbhrpizyeq\n",
      "Processing video folder: cffffbcywc\n",
      "Processing image: output_frames/cffffbcywc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cffffbcywc\n",
      "Processing video folder: caifxvsozs\n",
      "Processing image: output_frames/caifxvsozs/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for caifxvsozs\n",
      "Processing video folder: dzqwgqewhu\n",
      "Processing image: output_frames/dzqwgqewhu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dzqwgqewhu\n",
      "Processing video folder: bpwzipqtxf\n",
      "Processing image: output_frames/bpwzipqtxf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bpwzipqtxf\n",
      "Processing video folder: dbzpcjntve\n",
      "Processing image: output_frames/dbzpcjntve/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dbzpcjntve\n",
      "Processing video folder: chviwxsfhg\n",
      "Processing image: output_frames/chviwxsfhg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for chviwxsfhg\n",
      "Processing video folder: aettqgevhz\n",
      "Processing image: output_frames/aettqgevhz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aettqgevhz\n",
      "Processing video folder: ekkdjkirzq\n",
      "Processing image: output_frames/ekkdjkirzq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ekkdjkirzq\n",
      "Processing video folder: esckbnkkvb\n",
      "Processing image: output_frames/esckbnkkvb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for esckbnkkvb\n",
      "Processing video folder: coadfnerlk\n",
      "Processing image: output_frames/coadfnerlk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for coadfnerlk\n",
      "Processing video folder: diqraixiov\n",
      "Processing image: output_frames/diqraixiov/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for diqraixiov\n",
      "Processing video folder: ddepeddixj\n",
      "Processing image: output_frames/ddepeddixj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ddepeddixj\n",
      "Processing video folder: cxfujlvsuw\n",
      "Processing image: output_frames/cxfujlvsuw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cxfujlvsuw\n",
      "Processing video folder: diomeixhrg\n",
      "Processing image: output_frames/diomeixhrg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for diomeixhrg\n",
      "Processing video folder: bffwsjxghk\n",
      "Processing image: output_frames/bffwsjxghk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bffwsjxghk\n",
      "Processing video folder: bvgwelbeof\n",
      "Processing image: output_frames/bvgwelbeof/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bvgwelbeof\n",
      "Processing video folder: ebchwmwayp\n",
      "Processing image: output_frames/ebchwmwayp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ebchwmwayp\n",
      "Processing video folder: brhalypwoo\n",
      "Processing image: output_frames/brhalypwoo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for brhalypwoo\n",
      "Processing video folder: alvgwypubw\n",
      "Processing image: output_frames/alvgwypubw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for alvgwypubw\n",
      "Processing video folder: bsfmwclnqy\n",
      "Processing image: output_frames/bsfmwclnqy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bsfmwclnqy\n",
      "Processing video folder: deywhkarol\n",
      "Processing image: output_frames/deywhkarol/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for deywhkarol\n",
      "Processing video folder: dakqwktlbi\n",
      "Processing image: output_frames/dakqwktlbi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dakqwktlbi\n",
      "Processing video folder: bwhlgysghg\n",
      "Processing image: output_frames/bwhlgysghg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bwhlgysghg\n",
      "Processing video folder: cyboodqqyr\n",
      "Processing image: output_frames/cyboodqqyr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cyboodqqyr\n",
      "Processing video folder: bmbbkwmxqj\n",
      "Processing image: output_frames/bmbbkwmxqj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bmbbkwmxqj\n",
      "Processing video folder: acxnxvbsxk\n",
      "Processing image: output_frames/acxnxvbsxk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for acxnxvbsxk\n",
      "Processing video folder: eivxffliio\n",
      "Processing image: output_frames/eivxffliio/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eivxffliio\n",
      "Processing video folder: djvutyvaio\n",
      "Processing image: output_frames/djvutyvaio/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for djvutyvaio\n",
      "Processing video folder: eudeqjhdfd\n",
      "Processing image: output_frames/eudeqjhdfd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eudeqjhdfd\n",
      "Processing video folder: ecwaxgutkc\n",
      "Processing image: output_frames/ecwaxgutkc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ecwaxgutkc\n",
      "Processing video folder: dcuiiorugd\n",
      "Processing image: output_frames/dcuiiorugd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dcuiiorugd\n",
      "Processing video folder: cwwandrkus\n",
      "Processing image: output_frames/cwwandrkus/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cwwandrkus\n",
      "Processing video folder: avmjormvsx\n",
      "Processing image: output_frames/avmjormvsx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avmjormvsx\n",
      "Processing video folder: ciyoudyhly\n",
      "Processing image: output_frames/ciyoudyhly/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ciyoudyhly\n",
      "Processing video folder: bggsurpgpr\n",
      "Processing image: output_frames/bggsurpgpr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bggsurpgpr\n",
      "Processing video folder: avnqydkqjj\n",
      "Processing image: output_frames/avnqydkqjj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avnqydkqjj\n",
      "Processing video folder: edyncaijwx\n",
      "Processing image: output_frames/edyncaijwx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for edyncaijwx\n",
      "Processing video folder: drsakwyvqv\n",
      "Processing image: output_frames/drsakwyvqv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for drsakwyvqv\n",
      "Processing video folder: benmsfzfaz\n",
      "Processing image: output_frames/benmsfzfaz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for benmsfzfaz\n",
      "Processing video folder: ckjaibzfxa\n",
      "Processing image: output_frames/ckjaibzfxa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ckjaibzfxa\n",
      "Processing video folder: eqnoqyfquo\n",
      "Processing image: output_frames/eqnoqyfquo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eqnoqyfquo\n",
      "Processing video folder: ddpvuimigj\n",
      "Processing image: output_frames/ddpvuimigj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ddpvuimigj\n",
      "Processing video folder: bctvsmddgq\n",
      "Processing image: output_frames/bctvsmddgq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bctvsmddgq\n",
      "Processing video folder: dvakowbgbt\n",
      "Processing image: output_frames/dvakowbgbt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dvakowbgbt\n",
      "Processing video folder: ahfazfbntc\n",
      "Processing image: output_frames/ahfazfbntc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ahfazfbntc\n",
      "Processing video folder: ekhacizpah\n",
      "Processing image: output_frames/ekhacizpah/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ekhacizpah\n",
      "Processing video folder: bwuwstvsbw\n",
      "Processing image: output_frames/bwuwstvsbw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bwuwstvsbw\n",
      "Processing video folder: abqwwspghj\n",
      "Processing image: output_frames/abqwwspghj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for abqwwspghj\n",
      "Processing video folder: bhpwpydzpo\n",
      "Processing image: output_frames/bhpwpydzpo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bhpwpydzpo\n",
      "Processing video folder: dsndhujjjb\n",
      "Processing image: output_frames/dsndhujjjb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dsndhujjjb\n",
      "Processing video folder: cdyakrxkia\n",
      "Processing image: output_frames/cdyakrxkia/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cdyakrxkia\n",
      "Processing video folder: bpapbctoao\n",
      "Processing image: output_frames/bpapbctoao/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bpapbctoao\n",
      "Processing video folder: bnjcdrfuov\n",
      "Processing image: output_frames/bnjcdrfuov/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bnjcdrfuov\n",
      "Processing video folder: dgxrqjdomn\n",
      "Processing image: output_frames/dgxrqjdomn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dgxrqjdomn\n",
      "Processing video folder: axwgcsyphv\n",
      "Processing image: output_frames/axwgcsyphv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for axwgcsyphv\n",
      "Processing video folder: dtbpmdqvao\n",
      "Processing image: output_frames/dtbpmdqvao/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dtbpmdqvao\n",
      "Processing video folder: dntkzzzcdh\n",
      "Processing image: output_frames/dntkzzzcdh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dntkzzzcdh\n",
      "Processing video folder: ayqvfdhslr\n",
      "Processing image: output_frames/ayqvfdhslr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ayqvfdhslr\n",
      "Processing video folder: ehfiekigla\n",
      "Processing image: output_frames/ehfiekigla/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ehfiekigla\n",
      "Processing video folder: byyqectxqa\n",
      "Processing image: output_frames/byyqectxqa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for byyqectxqa\n",
      "Processing video folder: drcyabprvt\n",
      "Processing image: output_frames/drcyabprvt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for drcyabprvt\n",
      "Processing video folder: dsjbknkujw\n",
      "Processing image: output_frames/dsjbknkujw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dsjbknkujw\n",
      "Processing video folder: avywawptfc\n",
      "Processing image: output_frames/avywawptfc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avywawptfc\n",
      "Processing video folder: avssvvsdhz\n",
      "Processing image: output_frames/avssvvsdhz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avssvvsdhz\n",
      "Processing video folder: aybgughjxh\n",
      "Processing image: output_frames/aybgughjxh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aybgughjxh\n",
      "Processing video folder: egghxjjmfg\n",
      "Processing image: output_frames/egghxjjmfg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for egghxjjmfg\n",
      "Processing video folder: curpwogllm\n",
      "Processing image: output_frames/curpwogllm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for curpwogllm\n",
      "Processing video folder: cbltdtxglo\n",
      "Processing image: output_frames/cbltdtxglo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cbltdtxglo\n",
      "Processing video folder: dhcndnuwta\n",
      "Processing image: output_frames/dhcndnuwta/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dhcndnuwta\n",
      "Processing video folder: dvumqqhoac\n",
      "Processing image: output_frames/dvumqqhoac/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dvumqqhoac\n",
      "Processing video folder: dqzreruvje\n",
      "Processing image: output_frames/dqzreruvje/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dqzreruvje\n",
      "Processing video folder: bdbhekrrwo\n",
      "Processing image: output_frames/bdbhekrrwo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bdbhekrrwo\n",
      "Processing video folder: awukslzjra\n",
      "Processing image: output_frames/awukslzjra/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for awukslzjra\n",
      "Processing video folder: czkdanyadc\n",
      "Processing image: output_frames/czkdanyadc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for czkdanyadc\n",
      "Processing video folder: aslsvlvpth\n",
      "Processing image: output_frames/aslsvlvpth/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aslsvlvpth\n",
      "Processing video folder: dozyddhild\n",
      "Processing image: output_frames/dozyddhild/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dozyddhild\n",
      "Processing video folder: dqnyszdong\n",
      "Processing image: output_frames/dqnyszdong/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dqnyszdong\n",
      "Processing video folder: bqkdbcqjvb\n",
      "Processing image: output_frames/bqkdbcqjvb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bqkdbcqjvb\n",
      "Processing video folder: bvzjkezkms\n",
      "Processing image: output_frames/bvzjkezkms/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bvzjkezkms\n",
      "Processing video folder: ensyyivobf\n",
      "Processing image: output_frames/ensyyivobf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ensyyivobf\n",
      "Processing video folder: cuzrgrbvil\n",
      "Processing image: output_frames/cuzrgrbvil/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cuzrgrbvil\n",
      "Processing video folder: dzyuwjkjui\n",
      "Processing image: output_frames/dzyuwjkjui/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dzyuwjkjui\n",
      "Processing video folder: dafhtipaml\n",
      "Processing image: output_frames/dafhtipaml/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dafhtipaml\n",
      "Processing video folder: dqswpjoepo\n",
      "Processing image: output_frames/dqswpjoepo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dqswpjoepo\n",
      "Processing video folder: etdcqxabww\n",
      "Processing image: output_frames/etdcqxabww/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for etdcqxabww\n",
      "Processing video folder: bgwmmujlmc\n",
      "Processing image: output_frames/bgwmmujlmc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bgwmmujlmc\n",
      "Processing video folder: esyhwdfnxs\n",
      "Processing image: output_frames/esyhwdfnxs/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for esyhwdfnxs\n",
      "Processing video folder: bndybcqhfr\n",
      "Processing image: output_frames/bndybcqhfr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bndybcqhfr\n",
      "Processing video folder: cnilkgvfei\n",
      "Processing image: output_frames/cnilkgvfei/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cnilkgvfei\n",
      "Processing video folder: djxdyjopjd\n",
      "Processing image: output_frames/djxdyjopjd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for djxdyjopjd\n",
      "Processing video folder: dkwjwbwgey\n",
      "Processing image: output_frames/dkwjwbwgey/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dkwjwbwgey\n",
      "Processing video folder: dqqtjcryjv\n",
      "Processing image: output_frames/dqqtjcryjv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dqqtjcryjv\n",
      "Processing video folder: eepezmygaq\n",
      "Processing image: output_frames/eepezmygaq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eepezmygaq\n",
      "Processing video folder: bkvetcojbt\n",
      "Processing image: output_frames/bkvetcojbt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bkvetcojbt\n",
      "Processing video folder: cyxlcuyznd\n",
      "Processing image: output_frames/cyxlcuyznd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cyxlcuyznd\n",
      "Processing video folder: bseamdrpbj\n",
      "Processing image: output_frames/bseamdrpbj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bseamdrpbj\n",
      "Processing video folder: bchnbulevv\n",
      "Processing image: output_frames/bchnbulevv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bchnbulevv\n",
      "Processing video folder: cqrskwiqng\n",
      "Processing image: output_frames/cqrskwiqng/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cqrskwiqng\n",
      "Processing video folder: atyntldecu\n",
      "Processing image: output_frames/atyntldecu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for atyntldecu\n",
      "Processing video folder: cthdnahrkh\n",
      "Processing image: output_frames/cthdnahrkh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cthdnahrkh\n",
      "Processing video folder: eqvuznuwsa\n",
      "Processing image: output_frames/eqvuznuwsa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eqvuznuwsa\n",
      "Processing video folder: aytzyidmgs\n",
      "Processing image: output_frames/aytzyidmgs/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aytzyidmgs\n",
      "Processing video folder: egbbcxcuqy\n",
      "Processing image: output_frames/egbbcxcuqy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for egbbcxcuqy\n",
      "Processing video folder: emfbhytfhc\n",
      "Processing image: output_frames/emfbhytfhc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for emfbhytfhc\n",
      "Processing video folder: amowujxmzc\n",
      "Processing image: output_frames/amowujxmzc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for amowujxmzc\n",
      "Processing video folder: ekcrtigpab\n",
      "Processing image: output_frames/ekcrtigpab/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ekcrtigpab\n",
      "Processing video folder: dhjmzhrcav\n",
      "Processing image: output_frames/dhjmzhrcav/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dhjmzhrcav\n",
      "Processing video folder: bqdjzqhcft\n",
      "Processing image: output_frames/bqdjzqhcft/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bqdjzqhcft\n",
      "Processing video folder: erlvuvjsjf\n",
      "Processing image: output_frames/erlvuvjsjf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for erlvuvjsjf\n",
      "Processing video folder: efwfxwwlbw\n",
      "Processing image: output_frames/efwfxwwlbw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for efwfxwwlbw\n",
      "Processing video folder: eggbjzxnmg\n",
      "Processing image: output_frames/eggbjzxnmg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eggbjzxnmg\n",
      "Processing video folder: asmpfjfzif\n",
      "Processing image: output_frames/asmpfjfzif/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for asmpfjfzif\n",
      "Processing video folder: btxlttbpkj\n",
      "Processing image: output_frames/btxlttbpkj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btxlttbpkj\n",
      "Processing video folder: ehtdtkmmli\n",
      "Processing image: output_frames/ehtdtkmmli/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ehtdtkmmli\n",
      "Processing video folder: arlmiizoob\n",
      "Processing image: output_frames/arlmiizoob/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for arlmiizoob\n",
      "Processing video folder: etejaapnxh\n",
      "Processing image: output_frames/etejaapnxh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for etejaapnxh\n",
      "Processing video folder: eekozbeafq\n",
      "Processing image: output_frames/eekozbeafq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eekozbeafq\n",
      "Processing video folder: apgjqzkoma\n",
      "Processing image: output_frames/apgjqzkoma/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for apgjqzkoma\n",
      "Processing video folder: epymyyiblu\n",
      "Processing image: output_frames/epymyyiblu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for epymyyiblu\n",
      "Processing video folder: adylbeequz\n",
      "Processing image: output_frames/adylbeequz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for adylbeequz\n",
      "Processing video folder: deyyistcrd\n",
      "Processing image: output_frames/deyyistcrd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for deyyistcrd\n",
      "Processing video folder: dlrsbscitn\n",
      "Processing image: output_frames/dlrsbscitn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dlrsbscitn\n",
      "Processing video folder: dxuliowugt\n",
      "Processing image: output_frames/dxuliowugt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dxuliowugt\n",
      "Processing video folder: cferslmfwh\n",
      "Processing image: output_frames/cferslmfwh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cferslmfwh\n",
      "Processing video folder: aapnvogymq\n",
      "Processing image: output_frames/aapnvogymq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aapnvogymq\n",
      "Processing video folder: efdyrflcpg\n",
      "Processing image: output_frames/efdyrflcpg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for efdyrflcpg\n",
      "Processing video folder: bwipwzzxxu\n",
      "Processing image: output_frames/bwipwzzxxu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bwipwzzxxu\n",
      "Processing video folder: drgjzlxzxj\n",
      "Processing image: output_frames/drgjzlxzxj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for drgjzlxzxj\n",
      "Processing video folder: aknmpoonls\n",
      "Processing image: output_frames/aknmpoonls/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aknmpoonls\n",
      "Processing video folder: dulanfulol\n",
      "Processing image: output_frames/dulanfulol/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dulanfulol\n",
      "Processing video folder: cobjrlugvp\n",
      "Processing image: output_frames/cobjrlugvp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cobjrlugvp\n",
      "Processing video folder: aknbdpmgua\n",
      "Processing image: output_frames/aknbdpmgua/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aknbdpmgua\n",
      "Processing video folder: bdnaqemxmr\n",
      "Processing image: output_frames/bdnaqemxmr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bdnaqemxmr\n",
      "Processing video folder: eukvucdetx\n",
      "Processing image: output_frames/eukvucdetx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eukvucdetx\n",
      "Processing video folder: awhmfnnjih\n",
      "Processing image: output_frames/awhmfnnjih/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for awhmfnnjih\n",
      "Processing video folder: duycddgtrl\n",
      "Processing image: output_frames/duycddgtrl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for duycddgtrl\n",
      "Processing video folder: duzuusuajr\n",
      "Processing image: output_frames/duzuusuajr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for duzuusuajr\n",
      "Processing video folder: bahdpoesir\n",
      "Processing image: output_frames/bahdpoesir/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bahdpoesir\n",
      "Processing video folder: etmcruaihe\n",
      "Processing image: output_frames/etmcruaihe/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for etmcruaihe\n",
      "Processing video folder: eajlrktemq\n",
      "Processing image: output_frames/eajlrktemq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eajlrktemq\n",
      "Processing video folder: bxzakyopjf\n",
      "Processing image: output_frames/bxzakyopjf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bxzakyopjf\n",
      "Processing video folder: blzydqdfem\n",
      "Processing image: output_frames/blzydqdfem/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for blzydqdfem\n",
      "Processing video folder: btohlidmru\n",
      "Processing image: output_frames/btohlidmru/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btohlidmru\n",
      "Processing video folder: aladcziidp\n",
      "Processing image: output_frames/aladcziidp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aladcziidp\n",
      "Processing video folder: czfunozvwp\n",
      "Processing image: output_frames/czfunozvwp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for czfunozvwp\n",
      "Processing video folder: axwovszumc\n",
      "Processing image: output_frames/axwovszumc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for axwovszumc\n",
      "Processing video folder: bweezhfpzp\n",
      "Processing image: output_frames/bweezhfpzp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bweezhfpzp\n",
      "Processing video folder: btjwbtsgln\n",
      "Processing image: output_frames/btjwbtsgln/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btjwbtsgln\n",
      "Processing video folder: aybumesmpk\n",
      "Processing image: output_frames/aybumesmpk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aybumesmpk\n",
      "Processing video folder: cdphtzqrvp\n",
      "Processing image: output_frames/cdphtzqrvp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cdphtzqrvp\n",
      "Processing video folder: elvvackpjh\n",
      "Processing image: output_frames/elvvackpjh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for elvvackpjh\n",
      "Processing video folder: bbvgxeczei\n",
      "Processing image: output_frames/bbvgxeczei/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bbvgxeczei\n",
      "Processing video folder: diopzaywor\n",
      "Processing image: output_frames/diopzaywor/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for diopzaywor\n",
      "Processing video folder: cttqtsjvgn\n",
      "Processing image: output_frames/cttqtsjvgn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cttqtsjvgn\n",
      "Processing video folder: beboztfcme\n",
      "Processing image: output_frames/beboztfcme/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for beboztfcme\n",
      "Processing video folder: cdbsbdymzd\n",
      "Processing image: output_frames/cdbsbdymzd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cdbsbdymzd\n",
      "Processing video folder: bdxuhamuqx\n",
      "Processing image: output_frames/bdxuhamuqx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bdxuhamuqx\n",
      "Processing video folder: dboxtiehng\n",
      "Processing image: output_frames/dboxtiehng/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dboxtiehng\n",
      "Processing video folder: ehieahnhte\n",
      "Processing image: output_frames/ehieahnhte/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ehieahnhte\n",
      "Processing video folder: ckkuyewywx\n",
      "Processing image: output_frames/ckkuyewywx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ckkuyewywx\n",
      "Processing video folder: cbbibzcoih\n",
      "Processing image: output_frames/cbbibzcoih/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cbbibzcoih\n",
      "Processing video folder: btjlfpzbdu\n",
      "Processing image: output_frames/btjlfpzbdu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btjlfpzbdu\n",
      "Processing video folder: acifjvzvpm\n",
      "Processing image: output_frames/acifjvzvpm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for acifjvzvpm\n",
      "Processing video folder: cfxkpiweqt\n",
      "Processing image: output_frames/cfxkpiweqt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cfxkpiweqt\n",
      "Processing video folder: cmxcfkrjiv\n",
      "Processing image: output_frames/cmxcfkrjiv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cmxcfkrjiv\n",
      "Processing video folder: bqhtpqmmqp\n",
      "Processing image: output_frames/bqhtpqmmqp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bqhtpqmmqp\n",
      "Processing video folder: apatcsqejh\n",
      "Processing image: output_frames/apatcsqejh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for apatcsqejh\n",
      "Processing video folder: dkhlttuvmx\n",
      "Processing image: output_frames/dkhlttuvmx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dkhlttuvmx\n",
      "Processing video folder: aipfdnwpoo\n",
      "Processing image: output_frames/aipfdnwpoo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aipfdnwpoo\n",
      "Processing video folder: btmsngnqhv\n",
      "Processing image: output_frames/btmsngnqhv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btmsngnqhv\n",
      "Processing video folder: brvqtabyxj\n",
      "Processing image: output_frames/brvqtabyxj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for brvqtabyxj\n",
      "Processing video folder: chzieimrwu\n",
      "Processing image: output_frames/chzieimrwu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for chzieimrwu\n",
      "Processing video folder: cizlkenljw\n",
      "Processing image: output_frames/cizlkenljw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cizlkenljw\n",
      "Processing video folder: dbnygxtwek\n",
      "Processing image: output_frames/dbnygxtwek/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dbnygxtwek\n",
      "Processing video folder: dsdoseflas\n",
      "Processing image: output_frames/dsdoseflas/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dsdoseflas\n",
      "Processing video folder: crktehraph\n",
      "Processing image: output_frames/crktehraph/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for crktehraph\n",
      "Processing video folder: ddjggcasdw\n",
      "Processing image: output_frames/ddjggcasdw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ddjggcasdw\n",
      "Processing video folder: emaalmsonj\n",
      "Processing image: output_frames/emaalmsonj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for emaalmsonj\n",
      "Processing video folder: eixwxvxbbn\n",
      "Processing image: output_frames/eixwxvxbbn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eixwxvxbbn\n",
      "Processing video folder: dkuayagnmc\n",
      "Processing image: output_frames/dkuayagnmc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dkuayagnmc\n",
      "Processing video folder: eckvhdusax\n",
      "Processing image: output_frames/eckvhdusax/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eckvhdusax\n",
      "Processing video folder: dkzvdrzcnr\n",
      "Processing image: output_frames/dkzvdrzcnr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dkzvdrzcnr\n",
      "Processing video folder: aklqzsddfl\n",
      "Processing image: output_frames/aklqzsddfl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aklqzsddfl\n",
      "Processing video folder: dsgpbgsrdm\n",
      "Processing image: output_frames/dsgpbgsrdm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dsgpbgsrdm\n",
      "Processing video folder: diuzrpqjli\n",
      "Processing image: output_frames/diuzrpqjli/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for diuzrpqjli\n",
      "Processing video folder: cknyxaqouy\n",
      "Processing image: output_frames/cknyxaqouy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cknyxaqouy\n",
      "Processing video folder: arkroixhey\n",
      "Processing image: output_frames/arkroixhey/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for arkroixhey\n",
      "Processing video folder: eeyhxisdfh\n",
      "Processing image: output_frames/eeyhxisdfh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eeyhxisdfh\n",
      "Processing video folder: dzvyfiarrq\n",
      "Processing image: output_frames/dzvyfiarrq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dzvyfiarrq\n",
      "Processing video folder: bsqgziaylx\n",
      "Processing image: output_frames/bsqgziaylx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bsqgziaylx\n",
      "Processing video folder: dbzcqmxzaj\n",
      "Processing image: output_frames/dbzcqmxzaj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dbzcqmxzaj\n",
      "Processing video folder: boovltmuwi\n",
      "Processing image: output_frames/boovltmuwi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for boovltmuwi\n",
      "Processing video folder: blpchvmhxx\n",
      "Processing image: output_frames/blpchvmhxx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for blpchvmhxx\n",
      "Processing video folder: bpxckdzddv\n",
      "Processing image: output_frames/bpxckdzddv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bpxckdzddv\n",
      "Processing video folder: bhaaboftbc\n",
      "Processing image: output_frames/bhaaboftbc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bhaaboftbc\n",
      "Processing video folder: dubiroskqn\n",
      "Processing image: output_frames/dubiroskqn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dubiroskqn\n",
      "Processing video folder: agdkmztvby\n",
      "Processing image: output_frames/agdkmztvby/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for agdkmztvby\n",
      "Processing video folder: cycacemkmt\n",
      "Processing image: output_frames/cycacemkmt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cycacemkmt\n",
      "Processing video folder: bdgipnyobr\n",
      "Processing image: output_frames/bdgipnyobr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bdgipnyobr\n",
      "Processing video folder: ejkqesyvam\n",
      "Processing image: output_frames/ejkqesyvam/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ejkqesyvam\n",
      "Processing video folder: errocgcham\n",
      "Processing image: output_frames/errocgcham/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for errocgcham\n",
      "Processing video folder: byfenovjnf\n",
      "Processing image: output_frames/byfenovjnf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for byfenovjnf\n",
      "Processing video folder: anpuvshzoo\n",
      "Processing image: output_frames/anpuvshzoo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for anpuvshzoo\n",
      "Processing video folder: btunxncpjh\n",
      "Processing image: output_frames/btunxncpjh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btunxncpjh\n",
      "Processing video folder: bqnymlsayl\n",
      "Processing image: output_frames/bqnymlsayl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bqnymlsayl\n",
      "Processing video folder: azsmewqghg\n",
      "Processing image: output_frames/azsmewqghg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for azsmewqghg\n",
      "Processing video folder: atvmxvwyns\n",
      "Processing image: output_frames/atvmxvwyns/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for atvmxvwyns\n",
      "Processing video folder: adhsbajydo\n",
      "Processing image: output_frames/adhsbajydo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for adhsbajydo\n",
      "Processing video folder: arrhsnjqku\n",
      "Processing image: output_frames/arrhsnjqku/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for arrhsnjqku\n",
      "Processing video folder: ddqccgmtka\n",
      "Processing image: output_frames/ddqccgmtka/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ddqccgmtka\n",
      "Processing video folder: elginszwtk\n",
      "Processing image: output_frames/elginszwtk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for elginszwtk\n",
      "Processing video folder: avibnnhwhp\n",
      "Processing image: output_frames/avibnnhwhp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avibnnhwhp\n",
      "Processing video folder: bilnggbxgu\n",
      "Processing image: output_frames/bilnggbxgu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bilnggbxgu\n",
      "Processing video folder: eebserckhh\n",
      "Processing image: output_frames/eebserckhh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eebserckhh\n",
      "Processing video folder: axczxisdtb\n",
      "Processing image: output_frames/axczxisdtb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for axczxisdtb\n",
      "Processing video folder: alninxcyhg\n",
      "Processing image: output_frames/alninxcyhg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for alninxcyhg\n",
      "Processing video folder: byunigvnay\n",
      "Processing image: output_frames/byunigvnay/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for byunigvnay\n",
      "Processing video folder: bnbuonyoje\n",
      "Processing image: output_frames/bnbuonyoje/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bnbuonyoje\n",
      "Processing video folder: bbhpvrmbse\n",
      "Processing image: output_frames/bbhpvrmbse/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bbhpvrmbse\n",
      "Processing video folder: ecuvtoltue\n",
      "Processing image: output_frames/ecuvtoltue/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ecuvtoltue\n",
      "Processing video folder: dtocdfbwca\n",
      "Processing image: output_frames/dtocdfbwca/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dtocdfbwca\n",
      "Processing video folder: dxbqjxrhin\n",
      "Processing image: output_frames/dxbqjxrhin/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dxbqjxrhin\n",
      "Processing video folder: amaivqofda\n",
      "Processing image: output_frames/amaivqofda/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for amaivqofda\n",
      "Processing video folder: bmhvktyiwp\n",
      "Processing image: output_frames/bmhvktyiwp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bmhvktyiwp\n",
      "Processing video folder: cwsbspfzck\n",
      "Processing image: output_frames/cwsbspfzck/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cwsbspfzck\n",
      "Processing video folder: clrycekyst\n",
      "Processing image: output_frames/clrycekyst/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for clrycekyst\n",
      "Processing video folder: ehbnclaukr\n",
      "Processing image: output_frames/ehbnclaukr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ehbnclaukr\n",
      "Processing video folder: akxoopqjqz\n",
      "Processing image: output_frames/akxoopqjqz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for akxoopqjqz\n",
      "Processing video folder: dnhvalzvrt\n",
      "Processing image: output_frames/dnhvalzvrt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dnhvalzvrt\n",
      "Processing video folder: atkdltyyen\n",
      "Processing image: output_frames/atkdltyyen/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for atkdltyyen\n",
      "Processing video folder: ckbdwedgmc\n",
      "Processing image: output_frames/ckbdwedgmc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ckbdwedgmc\n",
      "Processing video folder: aneclqfpbt\n",
      "Processing image: output_frames/aneclqfpbt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aneclqfpbt\n",
      "Processing video folder: cqhngvpgyi\n",
      "Processing image: output_frames/cqhngvpgyi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cqhngvpgyi\n",
      "Processing video folder: bddjdhzfze\n",
      "Processing image: output_frames/bddjdhzfze/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bddjdhzfze\n",
      "Processing video folder: cvaksbpssm\n",
      "Processing image: output_frames/cvaksbpssm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cvaksbpssm\n",
      "Processing video folder: aufmsmnoye\n",
      "Processing image: output_frames/aufmsmnoye/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aufmsmnoye\n",
      "Processing video folder: dbhoxkblzx\n",
      "Processing image: output_frames/dbhoxkblzx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dbhoxkblzx\n",
      "Processing video folder: ctpqeykqdp\n",
      "Processing image: output_frames/ctpqeykqdp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ctpqeykqdp\n",
      "Processing video folder: ellavthztb\n",
      "Processing image: output_frames/ellavthztb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ellavthztb\n",
      "Processing video folder: duvyaxbzvp\n",
      "Processing image: output_frames/duvyaxbzvp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for duvyaxbzvp\n",
      "Processing video folder: cmbzllswnl\n",
      "Processing image: output_frames/cmbzllswnl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cmbzllswnl\n",
      "Processing video folder: cppdvdejkc\n",
      "Processing image: output_frames/cppdvdejkc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cppdvdejkc\n",
      "Processing video folder: btiysiskpf\n",
      "Processing image: output_frames/btiysiskpf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btiysiskpf\n",
      "Processing video folder: dgzklxjmix\n",
      "Processing image: output_frames/dgzklxjmix/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dgzklxjmix\n",
      "Processing video folder: erqgqacbqe\n",
      "Processing image: output_frames/erqgqacbqe/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for erqgqacbqe\n",
      "Processing video folder: dkdwxmtpuo\n",
      "Processing image: output_frames/dkdwxmtpuo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dkdwxmtpuo\n",
      "Processing video folder: bhsluedavd\n",
      "Processing image: output_frames/bhsluedavd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bhsluedavd\n",
      "Processing video folder: brwrlczjvi\n",
      "Processing image: output_frames/brwrlczjvi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for brwrlczjvi\n",
      "Processing video folder: asaxgevnnp\n",
      "Processing image: output_frames/asaxgevnnp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for asaxgevnnp\n",
      "Processing video folder: caqbrkogkb\n",
      "Processing image: output_frames/caqbrkogkb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for caqbrkogkb\n",
      "Processing video folder: dofusvhnib\n",
      "Processing image: output_frames/dofusvhnib/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dofusvhnib\n",
      "Processing video folder: ahbweevwpv\n",
      "Processing image: output_frames/ahbweevwpv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ahbweevwpv\n",
      "Processing video folder: bmehkyanbj\n",
      "Processing image: output_frames/bmehkyanbj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bmehkyanbj\n",
      "Processing video folder: byofowlkki\n",
      "Processing image: output_frames/byofowlkki/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for byofowlkki\n",
      "Processing video folder: dxuplhwvig\n",
      "Processing image: output_frames/dxuplhwvig/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dxuplhwvig\n",
      "Processing video folder: avfitoutyn\n",
      "Processing image: output_frames/avfitoutyn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avfitoutyn\n",
      "Processing video folder: eoewqcpbgt\n",
      "Processing image: output_frames/eoewqcpbgt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eoewqcpbgt\n",
      "Processing video folder: avgiuextiz\n",
      "Processing image: output_frames/avgiuextiz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avgiuextiz\n",
      "Processing video folder: aagfhgtpmv\n",
      "Processing image: output_frames/aagfhgtpmv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aagfhgtpmv\n",
      "Processing video folder: axoygtekut\n",
      "Processing image: output_frames/axoygtekut/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for axoygtekut\n",
      "Processing video folder: eqjscdagiv\n",
      "Processing image: output_frames/eqjscdagiv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eqjscdagiv\n",
      "Processing video folder: ajwpjhrbcv\n",
      "Processing image: output_frames/ajwpjhrbcv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ajwpjhrbcv\n",
      "Processing video folder: bmjmjmbglm\n",
      "Processing image: output_frames/bmjmjmbglm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bmjmjmbglm\n",
      "Processing video folder: crzfebnfgb\n",
      "Processing image: output_frames/crzfebnfgb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for crzfebnfgb\n",
      "Processing video folder: ehdkmxgtxh\n",
      "Processing image: output_frames/ehdkmxgtxh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ehdkmxgtxh\n",
      "Processing video folder: czmqpxrqoh\n",
      "Processing image: output_frames/czmqpxrqoh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for czmqpxrqoh\n",
      "Processing video folder: ecnihjlfyt\n",
      "Processing image: output_frames/ecnihjlfyt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ecnihjlfyt\n",
      "Processing video folder: ceymbecxnj\n",
      "Processing image: output_frames/ceymbecxnj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ceymbecxnj\n",
      "Processing video folder: bjsmaqefoi\n",
      "Processing image: output_frames/bjsmaqefoi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bjsmaqefoi\n",
      "Processing video folder: andaxzscny\n",
      "Processing image: output_frames/andaxzscny/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for andaxzscny\n",
      "Processing video folder: bghphrsfxf\n",
      "Processing image: output_frames/bghphrsfxf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bghphrsfxf\n",
      "Processing video folder: esgftaficx\n",
      "Processing image: output_frames/esgftaficx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for esgftaficx\n",
      "Processing video folder: aorjvbyxhw\n",
      "Processing image: output_frames/aorjvbyxhw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aorjvbyxhw\n",
      "Processing video folder: emgjphonqb\n",
      "Processing image: output_frames/emgjphonqb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for emgjphonqb\n",
      "Processing video folder: cksanfsjhc\n",
      "Processing image: output_frames/cksanfsjhc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cksanfsjhc\n",
      "Processing video folder: cwqlvzefpg\n",
      "Processing image: output_frames/cwqlvzefpg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cwqlvzefpg\n",
      "Processing video folder: afoovlsmtx\n",
      "Processing image: output_frames/afoovlsmtx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for afoovlsmtx\n",
      "Processing video folder: ajqslcypsw\n",
      "Processing image: output_frames/ajqslcypsw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ajqslcypsw\n",
      "Processing video folder: btugrnoton\n",
      "Processing image: output_frames/btugrnoton/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btugrnoton\n",
      "Processing video folder: abofeumbvv\n",
      "Processing image: output_frames/abofeumbvv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for abofeumbvv\n",
      "Processing video folder: agqphdxmwt\n",
      "Processing image: output_frames/agqphdxmwt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for agqphdxmwt\n",
      "Processing video folder: ebywfrmhtd\n",
      "Processing image: output_frames/ebywfrmhtd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ebywfrmhtd\n",
      "Processing video folder: cfyduhpbps\n",
      "Processing image: output_frames/cfyduhpbps/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cfyduhpbps\n",
      "Processing video folder: bgaogsjehq\n",
      "Processing image: output_frames/bgaogsjehq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bgaogsjehq\n",
      "Processing video folder: bhbdugnurr\n",
      "Processing image: output_frames/bhbdugnurr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bhbdugnurr\n",
      "Processing video folder: altziddtxi\n",
      "Processing image: output_frames/altziddtxi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for altziddtxi\n",
      "Processing video folder: agrmhtjdlk\n",
      "Processing image: output_frames/agrmhtjdlk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for agrmhtjdlk\n",
      "Processing video folder: bkmdzhfzfh\n",
      "Processing image: output_frames/bkmdzhfzfh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bkmdzhfzfh\n",
      "Processing video folder: esxrvsgpvb\n",
      "Processing image: output_frames/esxrvsgpvb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for esxrvsgpvb\n",
      "Processing video folder: bopqhhalml\n",
      "Processing image: output_frames/bopqhhalml/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bopqhhalml\n",
      "Processing video folder: ccfoszqabv\n",
      "Processing image: output_frames/ccfoszqabv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ccfoszqabv\n",
      "Processing video folder: dgmevclvzy\n",
      "Processing image: output_frames/dgmevclvzy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dgmevclvzy\n",
      "Processing video folder: dzieklokdr\n",
      "Processing image: output_frames/dzieklokdr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dzieklokdr\n",
      "Processing video folder: cyclgfjdrv\n",
      "Processing image: output_frames/cyclgfjdrv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cyclgfjdrv\n",
      "Processing video folder: ecujsjhscd\n",
      "Processing image: output_frames/ecujsjhscd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ecujsjhscd\n",
      "Processing video folder: dbtbbhakdv\n",
      "Processing image: output_frames/dbtbbhakdv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dbtbbhakdv\n",
      "Processing video folder: apogckdfrz\n",
      "Processing image: output_frames/apogckdfrz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for apogckdfrz\n",
      "Processing video folder: eiriyukqqy\n",
      "Processing image: output_frames/eiriyukqqy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eiriyukqqy\n",
      "Processing video folder: eejswgycjc\n",
      "Processing image: output_frames/eejswgycjc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eejswgycjc\n",
      "Processing video folder: bejhvclboh\n",
      "Processing image: output_frames/bejhvclboh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bejhvclboh\n",
      "Processing video folder: cxrfacemmq\n",
      "Processing image: output_frames/cxrfacemmq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cxrfacemmq\n",
      "Processing video folder: cdaxixbosp\n",
      "Processing image: output_frames/cdaxixbosp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cdaxixbosp\n",
      "Processing video folder: bmioepcpsx\n",
      "Processing image: output_frames/bmioepcpsx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bmioepcpsx\n",
      "Processing video folder: acqfdwsrhi\n",
      "Processing image: output_frames/acqfdwsrhi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for acqfdwsrhi\n",
      "Processing video folder: ebkzwjgjhq\n",
      "Processing image: output_frames/ebkzwjgjhq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ebkzwjgjhq\n",
      "Processing video folder: bgvhtpzknn\n",
      "Processing image: output_frames/bgvhtpzknn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bgvhtpzknn\n",
      "Processing video folder: avvdgsennp\n",
      "Processing image: output_frames/avvdgsennp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avvdgsennp\n",
      "Processing video folder: dnyvfblxpm\n",
      "Processing image: output_frames/dnyvfblxpm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dnyvfblxpm\n",
      "Processing video folder: cpjxareypw\n",
      "Processing image: output_frames/cpjxareypw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cpjxareypw\n",
      "Processing video folder: dptbnjnkdg\n",
      "Processing image: output_frames/dptbnjnkdg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dptbnjnkdg\n",
      "Processing video folder: asvcrfdpnq\n",
      "Processing image: output_frames/asvcrfdpnq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for asvcrfdpnq\n",
      "Processing video folder: alaijyygdv\n",
      "Processing image: output_frames/alaijyygdv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for alaijyygdv\n",
      "Processing video folder: dhoqofwoxa\n",
      "Processing image: output_frames/dhoqofwoxa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dhoqofwoxa\n",
      "Processing video folder: bguwlyazau\n",
      "Processing image: output_frames/bguwlyazau/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bguwlyazau\n",
      "Processing video folder: cxttmymlbn\n",
      "Processing image: output_frames/cxttmymlbn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cxttmymlbn\n",
      "Processing video folder: eiwopxzjfn\n",
      "Processing image: output_frames/eiwopxzjfn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eiwopxzjfn\n",
      "Processing video folder: eprybmbpba\n",
      "Processing image: output_frames/eprybmbpba/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eprybmbpba\n",
      "Processing video folder: doanjploai\n",
      "Processing image: output_frames/doanjploai/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for doanjploai\n",
      "Processing video folder: cgvrgibpfo\n",
      "Processing image: output_frames/cgvrgibpfo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cgvrgibpfo\n",
      "Processing video folder: dnexlwbcxq\n",
      "Processing image: output_frames/dnexlwbcxq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dnexlwbcxq\n",
      "Processing video folder: ehevsxtecd\n",
      "Processing image: output_frames/ehevsxtecd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ehevsxtecd\n",
      "Processing video folder: byijojkdba\n",
      "Processing image: output_frames/byijojkdba/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for byijojkdba\n",
      "Processing video folder: chtapglbcj\n",
      "Processing image: output_frames/chtapglbcj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for chtapglbcj\n",
      "Processing video folder: bbhtdfuqxq\n",
      "Processing image: output_frames/bbhtdfuqxq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bbhtdfuqxq\n",
      "Processing video folder: covdcysmbi\n",
      "Processing image: output_frames/covdcysmbi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for covdcysmbi\n",
      "Processing video folder: ahdbuwqxit\n",
      "Processing image: output_frames/ahdbuwqxit/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ahdbuwqxit\n",
      "Processing video folder: bzmdrafeex\n",
      "Processing image: output_frames/bzmdrafeex/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bzmdrafeex\n",
      "Processing video folder: eebrkicpry\n",
      "Processing image: output_frames/eebrkicpry/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eebrkicpry\n",
      "Processing video folder: bourlmzsio\n",
      "Processing image: output_frames/bourlmzsio/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bourlmzsio\n",
      "Processing video folder: cettndmvzl\n",
      "Processing image: output_frames/cettndmvzl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cettndmvzl\n",
      "Processing video folder: akvmwkdyuv\n",
      "Processing image: output_frames/akvmwkdyuv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for akvmwkdyuv\n",
      "Processing video folder: bydaidkpdp\n",
      "Processing image: output_frames/bydaidkpdp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bydaidkpdp\n",
      "Processing video folder: dhcselezer\n",
      "Processing image: output_frames/dhcselezer/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dhcselezer\n",
      "Processing video folder: bmjzrlszhi\n",
      "Processing image: output_frames/bmjzrlszhi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bmjzrlszhi\n",
      "Processing video folder: aevrfsexku\n",
      "Processing image: output_frames/aevrfsexku/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aevrfsexku\n",
      "Processing video folder: augtsuxpzc\n",
      "Processing image: output_frames/augtsuxpzc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for augtsuxpzc\n",
      "Processing video folder: cwrtyzndpx\n",
      "Processing image: output_frames/cwrtyzndpx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cwrtyzndpx\n",
      "Processing video folder: akzbnazxtz\n",
      "Processing image: output_frames/akzbnazxtz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for akzbnazxtz\n",
      "Processing video folder: dqppxmoqdl\n",
      "Processing image: output_frames/dqppxmoqdl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dqppxmoqdl\n",
      "Processing video folder: avtycwsgyb\n",
      "Processing image: output_frames/avtycwsgyb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avtycwsgyb\n",
      "Processing video folder: axntxmycwd\n",
      "Processing image: output_frames/axntxmycwd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for axntxmycwd\n",
      "Processing video folder: bofqajtwve\n",
      "Processing image: output_frames/bofqajtwve/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bofqajtwve\n",
      "Processing video folder: ebebgmtlcu\n",
      "Processing image: output_frames/ebebgmtlcu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ebebgmtlcu\n",
      "Processing video folder: eahlqmfvtj\n",
      "Processing image: output_frames/eahlqmfvtj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eahlqmfvtj\n",
      "Processing video folder: cepxysienc\n",
      "Processing image: output_frames/cepxysienc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cepxysienc\n",
      "Processing video folder: aqpnvjhuzw\n",
      "Processing image: output_frames/aqpnvjhuzw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aqpnvjhuzw\n",
      "Processing video folder: ebeknhudxq\n",
      "Processing image: output_frames/ebeknhudxq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ebeknhudxq\n",
      "Processing video folder: dzwkmcwkwl\n",
      "Processing image: output_frames/dzwkmcwkwl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dzwkmcwkwl\n",
      "Processing video folder: cglxirfaey\n",
      "Processing image: output_frames/cglxirfaey/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cglxirfaey\n",
      "Processing video folder: abarnvbtwb\n",
      "Processing image: output_frames/abarnvbtwb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for abarnvbtwb\n",
      "Processing video folder: atxvxouljq\n",
      "Processing image: output_frames/atxvxouljq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for atxvxouljq\n",
      "Processing video folder: esnntzzajv\n",
      "Processing image: output_frames/esnntzzajv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for esnntzzajv\n",
      "Processing video folder: bgmlwsoamc\n",
      "Processing image: output_frames/bgmlwsoamc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bgmlwsoamc\n",
      "Processing video folder: acxwigylke\n",
      "Processing image: output_frames/acxwigylke/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for acxwigylke\n",
      "Processing video folder: eczrseixwq\n",
      "Processing image: output_frames/eczrseixwq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eczrseixwq\n",
      "Processing video folder: bjjbwsqjir\n",
      "Processing image: output_frames/bjjbwsqjir/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bjjbwsqjir\n",
      "Processing video folder: dcamvmuors\n",
      "Processing image: output_frames/dcamvmuors/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dcamvmuors\n",
      "Processing video folder: dhkwmjxwrn\n",
      "Processing image: output_frames/dhkwmjxwrn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dhkwmjxwrn\n",
      "Processing video folder: bkwxhglwct\n",
      "Processing image: output_frames/bkwxhglwct/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bkwxhglwct\n",
      "Processing video folder: awnwkrqibf\n",
      "Processing image: output_frames/awnwkrqibf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for awnwkrqibf\n",
      "Processing video folder: ccmonzqfrz\n",
      "Processing image: output_frames/ccmonzqfrz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ccmonzqfrz\n",
      "Processing video folder: crezycjqyk\n",
      "Processing image: output_frames/crezycjqyk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for crezycjqyk\n",
      "Processing video folder: aelfnikyqj\n",
      "Processing image: output_frames/aelfnikyqj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aelfnikyqj\n",
      "Processing video folder: drtbksnpol\n",
      "Processing image: output_frames/drtbksnpol/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for drtbksnpol\n",
      "Processing video folder: degpbqvcay\n",
      "Processing image: output_frames/degpbqvcay/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for degpbqvcay\n",
      "Processing video folder: dwediigjit\n",
      "Processing image: output_frames/dwediigjit/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dwediigjit\n",
      "Processing video folder: ddhfabwpuz\n",
      "Processing image: output_frames/ddhfabwpuz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ddhfabwpuz\n",
      "Processing video folder: cwbacdwrzo\n",
      "Processing image: output_frames/cwbacdwrzo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cwbacdwrzo\n",
      "Processing video folder: dlpoieqvfb\n",
      "Processing image: output_frames/dlpoieqvfb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dlpoieqvfb\n",
      "Processing video folder: aczrgyricp\n",
      "Processing image: output_frames/aczrgyricp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aczrgyricp\n",
      "Processing video folder: clihsshdkq\n",
      "Processing image: output_frames/clihsshdkq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for clihsshdkq\n",
      "Processing video folder: byqzyxifza\n",
      "Processing image: output_frames/byqzyxifza/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for byqzyxifza\n",
      "Processing video folder: ehccixxzoe\n",
      "Processing image: output_frames/ehccixxzoe/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ehccixxzoe\n",
      "Processing video folder: bqtuuwzdtr\n",
      "Processing image: output_frames/bqtuuwzdtr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bqtuuwzdtr\n",
      "Processing video folder: asdpeebotb\n",
      "Processing image: output_frames/asdpeebotb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for asdpeebotb\n",
      "Processing video folder: beyebyhrph\n",
      "Processing image: output_frames/beyebyhrph/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for beyebyhrph\n",
      "Processing video folder: bntlodcfeg\n",
      "Processing image: output_frames/bntlodcfeg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bntlodcfeg\n",
      "Processing video folder: azpuxunqyo\n",
      "Processing image: output_frames/azpuxunqyo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for azpuxunqyo\n",
      "Processing video folder: bzythlfnhq\n",
      "Processing image: output_frames/bzythlfnhq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bzythlfnhq\n",
      "Processing video folder: bqqpbzjgup\n",
      "Processing image: output_frames/bqqpbzjgup/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bqqpbzjgup\n",
      "Processing video folder: aelzhcnwgf\n",
      "Processing image: output_frames/aelzhcnwgf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aelzhcnwgf\n",
      "Processing video folder: cprhtltsjp\n",
      "Processing image: output_frames/cprhtltsjp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cprhtltsjp\n",
      "Processing video folder: dkrvorliqc\n",
      "Processing image: output_frames/dkrvorliqc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dkrvorliqc\n",
      "Processing video folder: dhevettufk\n",
      "Processing image: output_frames/dhevettufk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dhevettufk\n",
      "Processing video folder: ctzmavwror\n",
      "Processing image: output_frames/ctzmavwror/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ctzmavwror\n",
      "Processing video folder: bqeiblbxtl\n",
      "Processing image: output_frames/bqeiblbxtl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bqeiblbxtl\n",
      "Processing video folder: etohcvnzbj\n",
      "Processing image: output_frames/etohcvnzbj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for etohcvnzbj\n",
      "Processing video folder: dhxctgyoqj\n",
      "Processing image: output_frames/dhxctgyoqj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dhxctgyoqj\n",
      "Processing video folder: bulkxhhknf\n",
      "Processing image: output_frames/bulkxhhknf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bulkxhhknf\n",
      "Processing video folder: dakiztgtnw\n",
      "Processing image: output_frames/dakiztgtnw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dakiztgtnw\n",
      "Processing video folder: adohikbdaz\n",
      "Processing image: output_frames/adohikbdaz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for adohikbdaz\n",
      "Processing video folder: cqfugiqupm\n",
      "Processing image: output_frames/cqfugiqupm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cqfugiqupm\n",
      "Processing video folder: dfbpceeaox\n",
      "Processing image: output_frames/dfbpceeaox/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dfbpceeaox\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove the final classification layer\n",
    "model.eval()\n",
    "\n",
    "def extract_features(image_path):\n",
    "    try:\n",
    "        # Load and transform the image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        print(f\"Processing image: {image_path}\")\n",
    "        print(f\"Image tensor shape: {image_tensor.shape}\")\n",
    "\n",
    "        # Pass the image through the model\n",
    "        with torch.no_grad():\n",
    "            features = model(image_tensor)\n",
    "            print(f\"Extracted features shape: {features.shape}\")\n",
    "\n",
    "        features = features.squeeze().numpy()\n",
    "        print(f\"Squeezed features shape: {features.shape}\")\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_video_folders(base_folder):\n",
    "    # Iterate over each folder in the base directory\n",
    "    for video_folder in os.listdir(base_folder):\n",
    "        video_folder_path = os.path.join(base_folder, video_folder)\n",
    "        if not os.path.isdir(video_folder_path):\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing video folder: {video_folder}\")\n",
    "\n",
    "        # Prepare to store features\n",
    "        features_list = []\n",
    "\n",
    "        # Iterate over each file in the video folder\n",
    "        for file_name in os.listdir(video_folder_path):\n",
    "            if file_name.startswith(\"error\") and file_name.lower().endswith('.png'):\n",
    "                ela_image_path = os.path.join(video_folder_path, file_name)\n",
    "\n",
    "                # Extract features from the ELA image\n",
    "                features = extract_features(ela_image_path)\n",
    "                if features is not None and features.size > 0:\n",
    "                    features_list.append(features)\n",
    "                else:\n",
    "                    print(f\"Skipped {ela_image_path} due to no features extracted.\")\n",
    "\n",
    "        # Save the features to a numpy file\n",
    "        features_output_path = os.path.join(video_folder_path, 'features.npy')\n",
    "        if features_list:\n",
    "            np.save(features_output_path, np.array(features_list))\n",
    "            print(f\"Features saved for {video_folder}\")\n",
    "        else:\n",
    "            print(f\"No features were extracted for {video_folder}\")\n",
    "\n",
    "# Example usage\n",
    "base_folder = \"output_frames\"\n",
    "process_video_folders(base_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0955fe203c0a908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T20:11:02.976210Z",
     "start_time": "2024-09-02T20:11:02.968685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.30054009e+00, 1.75150499e-01, 1.47206461e+00, 1.21956062e+00,\n",
       "        7.80197233e-02, 5.38589209e-02, 4.36189264e-01, 4.47781891e-01,\n",
       "        1.50521302e+00, 6.22210324e-01, 9.45242960e-03, 2.12246060e+00,\n",
       "        5.79149663e-01, 5.79591691e-01, 1.41811058e-01, 1.46813661e-01,\n",
       "        5.45903981e-01, 9.11980748e-01, 1.15721858e+00, 4.55431640e-02,\n",
       "        3.47043097e-01, 1.53117821e-01, 1.37424842e-01, 1.53564918e+00,\n",
       "        6.04817450e-01, 2.34549522e-01, 4.98942971e-01, 5.41440785e-01,\n",
       "        1.03637785e-01, 8.10079947e-02, 1.65779912e+00, 9.80842933e-02,\n",
       "        1.15696631e-01, 9.21311677e-02, 3.90869111e-01, 1.31433296e+00,\n",
       "        6.62818849e-02, 9.76481557e-01, 2.83193398e+00, 2.66995788e-01,\n",
       "        8.43623728e-02, 2.04649150e-01, 3.60843353e-02, 3.89950812e-01,\n",
       "        5.17459750e-01, 7.21907973e-01, 2.48763800e+00, 0.00000000e+00,\n",
       "        6.92498028e-01, 9.26984727e-01, 7.98257113e-01, 3.29818702e+00,\n",
       "        4.48163390e-01, 8.52723420e-02, 5.87730050e-01, 3.25417489e-01,\n",
       "        5.70606887e-02, 7.84889221e-01, 9.70757782e-01, 1.35865510e-01,\n",
       "        7.86255419e-01, 5.78317225e-01, 7.11563289e-01, 6.16557360e-01,\n",
       "        1.74499607e+00, 6.80965126e-01, 1.14920521e+00, 6.45769060e-01,\n",
       "        1.35991824e+00, 4.50741239e-02, 2.70125240e-01, 2.04485750e+00,\n",
       "        7.89856836e-02, 2.78439313e-01, 9.60964620e-01, 2.21930481e-02,\n",
       "        7.51383126e-01, 1.07399821e-01, 8.55447292e-01, 1.02237177e+00,\n",
       "        5.58905452e-02, 1.81092274e+00, 2.49236494e-01, 1.00409377e+00,\n",
       "        5.86068451e-01, 4.53153610e-01, 3.50163206e-02, 2.14491785e-02,\n",
       "        3.79632026e-01, 3.11545264e-02, 7.35149905e-02, 3.24389672e+00,\n",
       "        3.97955418e-01, 1.77463993e-01, 7.18360960e-01, 6.03500962e-01,\n",
       "        4.95499820e-01, 2.93285519e-01, 2.94278175e-01, 2.99540162e-01,\n",
       "        1.00539637e+00, 4.05375706e-03, 9.55887698e-03, 9.50909734e-01,\n",
       "        1.97156310e+00, 5.66291952e+00, 5.20965271e-03, 6.87974831e-03,\n",
       "        5.89472115e-01, 1.62415111e+00, 1.08265899e-01, 2.42838915e-02,\n",
       "        2.76902854e-01, 1.57168615e+00, 3.25613260e-01, 5.91467977e-01,\n",
       "        2.56723851e-01, 2.14481026e-01, 0.00000000e+00, 2.17908788e-02,\n",
       "        2.62021780e+00, 1.37974262e+00, 1.82011668e-02, 6.51778281e-01,\n",
       "        1.29390407e+00, 3.64329576e-01, 4.83140945e-01, 1.26328921e+00,\n",
       "        2.53556848e+00, 2.41623431e-01, 6.30738167e-03, 6.04370415e-01,\n",
       "        2.71191541e-02, 1.48589328e-01, 7.58601546e-01, 1.24634750e-01,\n",
       "        2.07294941e+00, 0.00000000e+00, 0.00000000e+00, 2.67584085e-01,\n",
       "        5.87598085e-01, 9.87262502e-02, 3.61801624e-01, 3.10837775e-01,\n",
       "        6.43237531e-01, 1.54786557e-01, 1.81717128e-01, 7.02335656e-01,\n",
       "        4.05290008e-01, 6.24150150e-02, 1.57021475e+00, 6.30961880e-02,\n",
       "        1.94321617e-01, 1.59087610e+00, 1.36978090e+00, 8.07967130e-03,\n",
       "        5.69066823e-01, 1.19940436e+00, 5.66299856e-01, 2.65799671e-01,\n",
       "        1.78193271e+00, 5.29358089e-01, 3.12263787e-01, 1.27047205e+00,\n",
       "        2.26886344e+00, 2.45915391e-02, 8.35642517e-01, 2.69403458e-01,\n",
       "        1.11478046e-01, 1.39017284e+00, 3.99084568e-01, 6.25210524e-01,\n",
       "        1.43701231e+00, 6.30841255e-01, 3.43877935e+00, 2.52777600e+00,\n",
       "        2.88814425e-01, 6.52814135e-02, 0.00000000e+00, 1.28873861e+00,\n",
       "        4.06538725e-01, 5.49446583e-01, 7.71185458e-02, 2.81480932e+00,\n",
       "        5.59356630e-01, 9.83773232e-01, 8.61741453e-02, 4.72946942e-01,\n",
       "        1.02095798e-01, 1.25450301e+00, 2.10331202e+00, 4.89427924e-01,\n",
       "        3.14725232e+00, 0.00000000e+00, 2.29680181e-01, 5.80215417e-02,\n",
       "        1.41801548e+00, 1.55365789e+00, 1.01040328e+00, 2.64857057e-02,\n",
       "        4.39419061e-01, 1.11554575e+00, 3.98779333e-01, 4.05093236e-03,\n",
       "        9.78807360e-02, 1.10559881e-01, 8.62483442e-01, 4.33935642e-01,\n",
       "        3.89507949e-01, 2.54527593e+00, 1.11708987e+00, 9.22361255e-01,\n",
       "        9.03873518e-02, 1.84063956e-01, 3.75023365e-01, 1.31988835e+00,\n",
       "        9.52019989e-01, 7.86590338e-01, 3.19173217e-01, 1.30125493e-01,\n",
       "        5.24070919e-01, 1.33403051e+00, 9.99364816e-03, 6.65175319e-01,\n",
       "        4.49919030e-02, 2.01081857e-02, 1.42118841e-01, 1.99640676e-01,\n",
       "        3.85552585e-01, 2.55575150e-01, 1.43976614e-01, 7.13157356e-01,\n",
       "        3.45264152e-02, 1.11644626e+00, 9.84652936e-01, 1.17313407e-01,\n",
       "        1.86623585e+00, 4.55790728e-01, 6.16920650e-01, 7.64470935e-01,\n",
       "        6.43243670e-01, 6.49084926e-01, 7.77653605e-02, 1.26195431e+00,\n",
       "        8.57414067e-01, 8.87299836e-01, 1.32290184e+00, 7.05288172e-01,\n",
       "        8.94559443e-01, 3.04501951e-01, 1.91704899e-01, 3.00039381e-01,\n",
       "        7.50435293e-01, 2.80414205e-02, 1.02559078e+00, 1.15041625e+00,\n",
       "        5.86074591e-01, 5.51234558e-02, 5.16692042e-01, 3.05808187e-01,\n",
       "        5.68237007e-01, 2.40986437e-01, 1.33493459e+00, 1.96237743e-01,\n",
       "        2.86962807e-01, 6.05378389e-01, 1.57246757e+00, 8.78319610e-03,\n",
       "        9.02242362e-01, 1.24656379e+00, 2.32577696e-01, 3.51397157e-01,\n",
       "        5.31221032e-01, 2.56472588e+00, 3.92252088e-01, 2.02381134e-01,\n",
       "        7.00563252e-01, 6.39612734e-01, 1.06279969e+00, 7.99241960e-01,\n",
       "        1.22250009e+00, 6.50498390e-01, 1.05118036e+00, 1.00484587e-01,\n",
       "        1.11072920e-01, 6.64995238e-02, 1.23802751e-01, 3.58934760e-01,\n",
       "        1.14767087e+00, 9.19555947e-02, 1.17668498e+00, 2.76395321e-01,\n",
       "        1.27004671e+00, 9.80870783e-01, 1.59833574e+00, 1.11702152e-01,\n",
       "        7.47369468e-01, 7.29933381e-01, 1.15696096e+00, 1.77958727e+00,\n",
       "        2.82259250e+00, 3.20338964e-01, 2.02105522e+00, 7.71639168e-01,\n",
       "        1.30728352e+00, 3.31963509e-01, 9.38631892e-02, 7.35169291e-01,\n",
       "        1.69217601e-01, 4.57380563e-01, 6.90785229e-01, 1.03724849e+00,\n",
       "        3.99732590e-02, 1.97050557e-01, 1.31621861e+00, 8.08198273e-01,\n",
       "        1.61742523e-01, 1.02211392e+00, 1.80824077e+00, 9.64300811e-01,\n",
       "        2.76504421e+00, 8.67328882e-01, 1.09303474e+00, 4.85662341e-01,\n",
       "        2.54517138e-01, 1.80706799e+00, 1.62559867e-01, 2.05902249e-01,\n",
       "        1.21813258e-02, 1.47833192e+00, 4.11151409e-01, 1.34604692e-01,\n",
       "        1.52119970e+00, 2.59904843e-02, 2.29940510e+00, 7.17723310e-01,\n",
       "        1.06864107e+00, 1.67258590e-01, 3.83428067e-01, 7.72576571e-01,\n",
       "        5.24829840e-04, 3.79266620e-01, 4.87885177e-01, 1.48087668e+00,\n",
       "        3.95841599e-01, 1.23047626e+00, 3.04109156e-01, 9.50406194e-01,\n",
       "        5.46095073e-01, 1.17201805e-01, 5.14568508e-01, 2.33434677e+00,\n",
       "        4.62003231e-01, 1.07938141e-01, 9.55212831e-01, 6.18816435e-01,\n",
       "        2.26313615e+00, 9.32224274e-01, 3.78176644e-02, 1.98502973e-01,\n",
       "        3.60315347e+00, 1.99809313e+00, 3.60609126e+00, 9.72379088e-01,\n",
       "        1.18012339e-01, 5.24767101e-01, 1.86056507e+00, 6.90815970e-02,\n",
       "        1.82356381e+00, 1.11526203e+00, 2.14194879e-01, 1.53569126e+00,\n",
       "        2.24398635e-02, 4.54430252e-01, 1.55073225e+00, 5.19405723e-01,\n",
       "        2.33500168e-01, 1.90051466e-01, 1.65152505e-01, 2.39742541e+00,\n",
       "        4.27441657e-01, 1.98962009e+00, 1.79467928e+00, 1.75038397e+00,\n",
       "        9.22489241e-02, 4.91837293e-01, 2.35812902e-01, 5.95715165e-01,\n",
       "        2.97019426e-02, 1.54799819e-01, 1.44310403e+00, 8.36869061e-01,\n",
       "        9.13677931e-01, 4.40279916e-02, 2.92223901e-01, 8.58177722e-01,\n",
       "        8.80153656e-01, 2.53524899e+00, 4.00345612e+00, 5.47147531e-04,\n",
       "        9.29875672e-01, 2.09615207e+00, 5.11689901e-01, 1.26889825e+00,\n",
       "        3.39222646e+00, 8.40905996e-04, 2.67041624e-01, 5.42814851e-01,\n",
       "        6.15951186e-03, 1.51073858e-01, 5.15786052e-01, 3.21863294e+00,\n",
       "        5.81576204e+00, 3.41330748e-03, 9.36559588e-02, 2.55836457e-01,\n",
       "        8.38190436e-01, 2.76063055e-01, 4.80062634e-01, 8.42656016e-01,\n",
       "        0.00000000e+00, 4.35735196e-01, 5.80020845e-01, 2.44790888e+00,\n",
       "        1.69332182e+00, 0.00000000e+00, 5.63615739e-01, 7.38949701e-03,\n",
       "        3.67744155e-02, 1.99875727e-01, 1.21551670e-01, 1.61091828e+00,\n",
       "        1.90247849e-01, 5.31447291e-01, 7.81031072e-01, 6.07599437e-01,\n",
       "        4.03901279e-01, 3.57348144e-01, 1.47527325e+00, 8.15608725e-02,\n",
       "        1.68702984e+00, 5.13353527e-01, 1.74075112e-01, 6.94077015e-01,\n",
       "        2.31826589e-01, 1.11669219e+00, 2.60056127e-02, 0.00000000e+00,\n",
       "        9.23631012e-01, 5.60627878e-01, 4.20499849e+00, 5.16289711e-01,\n",
       "        2.14510489e+00, 1.34474151e-02, 1.13045192e+00, 1.23686779e+00,\n",
       "        1.15486078e-01, 3.33835721e-01, 8.35117936e-01, 1.64442614e-01,\n",
       "        5.82127154e-01, 1.21638782e-01, 1.72157693e+00, 4.32603627e-01,\n",
       "        1.19511634e-01, 2.23483467e+00, 2.44199538e+00, 2.43591595e+00,\n",
       "        1.05672061e+00, 0.00000000e+00, 1.86938886e-02, 3.91726851e-01,\n",
       "        6.47945642e-01, 8.27468559e-02, 9.51558650e-02, 1.28240216e+00,\n",
       "        9.83302116e-01, 1.99020982e-01, 0.00000000e+00, 1.14011514e+00,\n",
       "        6.62450075e-01, 1.57890648e-01, 1.07340229e+00, 3.52510400e-02,\n",
       "        1.92241728e+00, 5.76151609e-01, 2.04099607e+00, 1.30981073e-01,\n",
       "        4.47561413e-01, 1.48832202e+00, 5.18691063e-01, 1.22588985e-02,\n",
       "        9.73827779e-01, 1.63133398e-01, 3.31681222e-01, 9.28073600e-02,\n",
       "        4.12162393e-01, 1.20520794e+00, 4.33075130e-02, 1.76614749e+00,\n",
       "        4.08404827e-01, 2.20363784e+00, 0.00000000e+00, 8.08442652e-01,\n",
       "        2.09643677e-01, 6.52197719e-01, 1.78972393e-01, 6.69838488e-01,\n",
       "        6.42968342e-03, 5.49528301e-01, 1.58929490e-02, 2.57235318e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('/Users/aniketsaxena/Documents/p/python/project/deepFakeDetection/df1/organized_frames/real/eudeqjhdfd/features.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f212e139f547b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:00:48.324290Z",
     "start_time": "2024-09-03T04:57:39.433109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied aagfhgtpmv to FAKE category\n",
      "Copied aapnvogymq to FAKE category\n",
      "Copied abarnvbtwb to REAL category\n",
      "Copied abofeumbvv to FAKE category\n",
      "Copied abqwwspghj to FAKE category\n",
      "Copied acifjvzvpm to FAKE category\n",
      "Copied acqfdwsrhi to FAKE category\n",
      "Copied acxnxvbsxk to FAKE category\n",
      "Copied acxwigylke to FAKE category\n",
      "Copied aczrgyricp to FAKE category\n",
      "Copied adhsbajydo to FAKE category\n",
      "Copied adohikbdaz to FAKE category\n",
      "Copied adylbeequz to FAKE category\n",
      "Copied aelfnikyqj to REAL category\n",
      "Copied aelzhcnwgf to FAKE category\n",
      "Copied aettqgevhz to FAKE category\n",
      "Copied aevrfsexku to FAKE category\n",
      "Copied afoovlsmtx to REAL category\n",
      "Copied agdkmztvby to FAKE category\n",
      "Copied agqphdxmwt to FAKE category\n",
      "Copied agrmhtjdlk to REAL category\n",
      "Copied ahbweevwpv to FAKE category\n",
      "Copied ahdbuwqxit to FAKE category\n",
      "Copied ahfazfbntc to FAKE category\n",
      "Copied ahqqqilsxt to REAL category\n",
      "Copied aipfdnwpoo to FAKE category\n",
      "Copied ajqslcypsw to REAL category\n",
      "Copied ajwpjhrbcv to FAKE category\n",
      "Copied aklqzsddfl to FAKE category\n",
      "Copied aknbdpmgua to FAKE category\n",
      "Copied aknmpoonls to FAKE category\n",
      "Copied akvmwkdyuv to FAKE category\n",
      "Copied akxoopqjqz to FAKE category\n",
      "Copied akzbnazxtz to FAKE category\n",
      "Copied aladcziidp to FAKE category\n",
      "Copied alaijyygdv to FAKE category\n",
      "Copied alninxcyhg to FAKE category\n",
      "Copied altziddtxi to FAKE category\n",
      "Copied alvgwypubw to FAKE category\n",
      "Copied amaivqofda to FAKE category\n",
      "Copied amowujxmzc to FAKE category\n",
      "Copied andaxzscny to FAKE category\n",
      "Copied aneclqfpbt to FAKE category\n",
      "Copied anpuvshzoo to REAL category\n",
      "Copied aorjvbyxhw to FAKE category\n",
      "Copied apatcsqejh to FAKE category\n",
      "Copied apgjqzkoma to FAKE category\n",
      "Copied apogckdfrz to FAKE category\n",
      "Copied aqpnvjhuzw to FAKE category\n",
      "Copied arkroixhey to FAKE category\n",
      "Copied arlmiizoob to FAKE category\n",
      "Copied arrhsnjqku to FAKE category\n",
      "Copied asaxgevnnp to REAL category\n",
      "Copied asdpeebotb to FAKE category\n",
      "Copied aslsvlvpth to FAKE category\n",
      "Copied asmpfjfzif to FAKE category\n",
      "Copied asvcrfdpnq to FAKE category\n",
      "Copied atkdltyyen to REAL category\n",
      "Copied atvmxvwyns to REAL category\n",
      "Copied atxvxouljq to FAKE category\n",
      "Copied atyntldecu to FAKE category\n",
      "Copied atzdznmder to FAKE category\n",
      "Copied aufmsmnoye to FAKE category\n",
      "Copied augtsuxpzc to FAKE category\n",
      "Copied avfitoutyn to FAKE category\n",
      "Copied avgiuextiz to FAKE category\n",
      "Copied avibnnhwhp to FAKE category\n",
      "Copied avmjormvsx to REAL category\n",
      "Copied avnqydkqjj to FAKE category\n",
      "Copied avssvvsdhz to FAKE category\n",
      "Copied avtycwsgyb to FAKE category\n",
      "Copied avvdgsennp to FAKE category\n",
      "Copied avywawptfc to FAKE category\n",
      "Copied awhmfnnjih to FAKE category\n",
      "Copied awnwkrqibf to FAKE category\n",
      "Copied awukslzjra to FAKE category\n",
      "Copied axczxisdtb to FAKE category\n",
      "Copied axntxmycwd to REAL category\n",
      "Copied axoygtekut to FAKE category\n",
      "Copied axwgcsyphv to FAKE category\n",
      "Copied axwovszumc to FAKE category\n",
      "Copied aybgughjxh to REAL category\n",
      "Copied aybumesmpk to REAL category\n",
      "Copied ayqvfdhslr to FAKE category\n",
      "Copied aytzyidmgs to REAL category\n",
      "Copied azpuxunqyo to FAKE category\n",
      "Copied azsmewqghg to FAKE category\n",
      "Copied bahdpoesir to FAKE category\n",
      "Copied bbhpvrmbse to FAKE category\n",
      "Copied bbhtdfuqxq to FAKE category\n",
      "Copied bbvgxeczei to FAKE category\n",
      "Copied bchnbulevv to FAKE category\n",
      "Copied bctvsmddgq to FAKE category\n",
      "Copied bdbhekrrwo to FAKE category\n",
      "Copied bddjdhzfze to REAL category\n",
      "Copied bdgipnyobr to FAKE category\n",
      "Copied bdnaqemxmr to REAL category\n",
      "Copied bdxuhamuqx to FAKE category\n",
      "Copied beboztfcme to REAL category\n",
      "Copied bejhvclboh to REAL category\n",
      "Copied benmsfzfaz to FAKE category\n",
      "Copied beyebyhrph to REAL category\n",
      "Copied bffwsjxghk to REAL category\n",
      "Copied bgaogsjehq to FAKE category\n",
      "Copied bggsurpgpr to FAKE category\n",
      "Copied bghphrsfxf to FAKE category\n",
      "Copied bgmlwsoamc to FAKE category\n",
      "Copied bguwlyazau to FAKE category\n",
      "Copied bgvhtpzknn to REAL category\n",
      "Copied bgwmmujlmc to REAL category\n",
      "Copied bhaaboftbc to FAKE category\n",
      "Copied bhbdugnurr to FAKE category\n",
      "Copied bhpwpydzpo to FAKE category\n",
      "Copied bhsluedavd to FAKE category\n",
      "Copied bilnggbxgu to REAL category\n",
      "Copied bjjbwsqjir to FAKE category\n",
      "Copied bjkmjilrxp to FAKE category\n",
      "Copied bjsmaqefoi to FAKE category\n",
      "Copied bkmdzhfzfh to FAKE category\n",
      "Copied bkvetcojbt to FAKE category\n",
      "Copied bkwxhglwct to FAKE category\n",
      "Copied blpchvmhxx to FAKE category\n",
      "Copied blzydqdfem to FAKE category\n",
      "Copied bmbbkwmxqj to FAKE category\n",
      "Copied bmehkyanbj to FAKE category\n",
      "Copied bmhvktyiwp to FAKE category\n",
      "Copied bmioepcpsx to FAKE category\n",
      "Copied bmjmjmbglm to FAKE category\n",
      "Copied bmjzrlszhi to REAL category\n",
      "Copied bnbuonyoje to FAKE category\n",
      "Copied bndybcqhfr to FAKE category\n",
      "Copied bnjcdrfuov to FAKE category\n",
      "Copied bntlodcfeg to FAKE category\n",
      "Copied bofqajtwve to FAKE category\n",
      "Copied boovltmuwi to FAKE category\n",
      "Copied bopqhhalml to FAKE category\n",
      "Copied bourlmzsio to FAKE category\n",
      "Copied bpapbctoao to REAL category\n",
      "Copied bpwzipqtxf to FAKE category\n",
      "Copied bpxckdzddv to FAKE category\n",
      "Copied bqdjzqhcft to FAKE category\n",
      "Copied bqeiblbxtl to FAKE category\n",
      "Copied bqhtpqmmqp to FAKE category\n",
      "Copied bqkdbcqjvb to FAKE category\n",
      "Copied bqnymlsayl to FAKE category\n",
      "Copied bqqpbzjgup to FAKE category\n",
      "Copied bqtuuwzdtr to FAKE category\n",
      "Copied brhalypwoo to FAKE category\n",
      "Copied brvqtabyxj to FAKE category\n",
      "Copied brwrlczjvi to REAL category\n",
      "Copied bseamdrpbj to FAKE category\n",
      "Copied bsfmwclnqy to FAKE category\n",
      "Copied bsqgziaylx to FAKE category\n",
      "Copied btiysiskpf to FAKE category\n",
      "Copied btjlfpzbdu to FAKE category\n",
      "Copied btjwbtsgln to FAKE category\n",
      "Copied btmsngnqhv to FAKE category\n",
      "Copied btohlidmru to FAKE category\n",
      "Copied btugrnoton to FAKE category\n",
      "Copied btunxncpjh to FAKE category\n",
      "Copied btxlttbpkj to FAKE category\n",
      "Copied bulkxhhknf to REAL category\n",
      "Copied bvgwelbeof to FAKE category\n",
      "Copied bvzjkezkms to FAKE category\n",
      "Copied bweezhfpzp to FAKE category\n",
      "Copied bwhlgysghg to REAL category\n",
      "Copied bwipwzzxxu to REAL category\n",
      "Copied bwuwstvsbw to FAKE category\n",
      "Copied bxzakyopjf to REAL category\n",
      "Copied bydaidkpdp to FAKE category\n",
      "Copied byfenovjnf to FAKE category\n",
      "Copied byijojkdba to FAKE category\n",
      "Copied byofowlkki to FAKE category\n",
      "Copied byqzyxifza to FAKE category\n",
      "Copied byunigvnay to FAKE category\n",
      "Copied byyqectxqa to FAKE category\n",
      "Copied bzmdrafeex to FAKE category\n",
      "Copied bzythlfnhq to REAL category\n",
      "Copied caifxvsozs to REAL category\n",
      "Copied caqbrkogkb to FAKE category\n",
      "Copied cbbibzcoih to FAKE category\n",
      "Copied cbltdtxglo to FAKE category\n",
      "Copied ccfoszqabv to REAL category\n",
      "Copied ccmonzqfrz to FAKE category\n",
      "Copied cdaxixbosp to FAKE category\n",
      "Copied cdbsbdymzd to FAKE category\n",
      "Copied cdphtzqrvp to FAKE category\n",
      "Copied cdyakrxkia to FAKE category\n",
      "Copied cepxysienc to FAKE category\n",
      "Copied cettndmvzl to FAKE category\n",
      "Copied ceymbecxnj to FAKE category\n",
      "Copied cferslmfwh to FAKE category\n",
      "Copied cffffbcywc to FAKE category\n",
      "Copied cfxkpiweqt to REAL category\n",
      "Copied cfyduhpbps to FAKE category\n",
      "Copied cglxirfaey to FAKE category\n",
      "Copied cgvrgibpfo to FAKE category\n",
      "Copied chtapglbcj to REAL category\n",
      "Copied chviwxsfhg to REAL category\n",
      "Copied chzieimrwu to FAKE category\n",
      "Copied ciyoudyhly to REAL category\n",
      "Copied cizlkenljw to REAL category\n",
      "Copied ckbdwedgmc to FAKE category\n",
      "Copied ckjaibzfxa to REAL category\n",
      "Copied ckkuyewywx to REAL category\n",
      "Copied cknyxaqouy to FAKE category\n",
      "Copied cksanfsjhc to FAKE category\n",
      "Copied clihsshdkq to FAKE category\n",
      "Copied clrycekyst to REAL category\n",
      "Copied cmbzllswnl to REAL category\n",
      "Copied cmxcfkrjiv to FAKE category\n",
      "Copied cnilkgvfei to FAKE category\n",
      "Copied coadfnerlk to FAKE category\n",
      "Copied cobjrlugvp to REAL category\n",
      "Copied covdcysmbi to FAKE category\n",
      "Copied cpjxareypw to REAL category\n",
      "Copied cppdvdejkc to REAL category\n",
      "Copied cprhtltsjp to REAL category\n",
      "Copied cqfugiqupm to FAKE category\n",
      "Copied cqhngvpgyi to FAKE category\n",
      "Copied cqrskwiqng to FAKE category\n",
      "Copied crezycjqyk to REAL category\n",
      "Copied crktehraph to FAKE category\n",
      "Copied crzfebnfgb to FAKE category\n",
      "Copied cthdnahrkh to FAKE category\n",
      "Copied ctpqeykqdp to FAKE category\n",
      "Copied cttqtsjvgn to FAKE category\n",
      "Copied ctzmavwror to FAKE category\n",
      "Copied curpwogllm to FAKE category\n",
      "Copied cuzrgrbvil to FAKE category\n",
      "Copied cvaksbpssm to FAKE category\n",
      "Copied cwbacdwrzo to FAKE category\n",
      "Copied cwqlvzefpg to FAKE category\n",
      "Copied cwrtyzndpx to FAKE category\n",
      "Copied cwsbspfzck to FAKE category\n",
      "Copied cwwandrkus to FAKE category\n",
      "Copied cxfujlvsuw to FAKE category\n",
      "Copied cxrfacemmq to FAKE category\n",
      "Copied cxttmymlbn to FAKE category\n",
      "Copied cyboodqqyr to FAKE category\n",
      "Copied cycacemkmt to FAKE category\n",
      "Copied cyclgfjdrv to FAKE category\n",
      "Copied cyxlcuyznd to REAL category\n",
      "Copied czfunozvwp to FAKE category\n",
      "Copied czkdanyadc to FAKE category\n",
      "Copied czmqpxrqoh to FAKE category\n",
      "Copied dafhtipaml to FAKE category\n",
      "Copied dakiztgtnw to REAL category\n",
      "Copied dakqwktlbi to FAKE category\n",
      "Copied dbhoxkblzx to FAKE category\n",
      "Copied dbhrpizyeq to FAKE category\n",
      "Copied dbnygxtwek to REAL category\n",
      "Copied dboxtiehng to FAKE category\n",
      "Copied dbtbbhakdv to REAL category\n",
      "Copied dbzcqmxzaj to FAKE category\n",
      "Copied dbzpcjntve to FAKE category\n",
      "Copied dcamvmuors to FAKE category\n",
      "Copied dcuiiorugd to FAKE category\n",
      "Copied ddepeddixj to REAL category\n",
      "Copied ddhfabwpuz to FAKE category\n",
      "Copied ddjggcasdw to FAKE category\n",
      "Copied ddpvuimigj to FAKE category\n",
      "Copied ddqccgmtka to FAKE category\n",
      "Copied degpbqvcay to FAKE category\n",
      "Copied deywhkarol to FAKE category\n",
      "Copied deyyistcrd to FAKE category\n",
      "Copied dfbpceeaox to FAKE category\n",
      "Copied dgmevclvzy to FAKE category\n",
      "Copied dgxrqjdomn to FAKE category\n",
      "Copied dgzklxjmix to FAKE category\n",
      "Copied dhcndnuwta to REAL category\n",
      "Copied dhcselezer to FAKE category\n",
      "Copied dhevettufk to FAKE category\n",
      "Copied dhjmzhrcav to FAKE category\n",
      "Copied dhkwmjxwrn to FAKE category\n",
      "Copied dhoqofwoxa to FAKE category\n",
      "Copied dhxctgyoqj to REAL category\n",
      "Copied diomeixhrg to FAKE category\n",
      "Copied diopzaywor to FAKE category\n",
      "Copied diqraixiov to FAKE category\n",
      "Copied diuzrpqjli to FAKE category\n",
      "Copied djvtbgwdcc to FAKE category\n",
      "Copied djvutyvaio to FAKE category\n",
      "Copied djxdyjopjd to REAL category\n",
      "Copied dkdwxmtpuo to FAKE category\n",
      "Copied dkhlttuvmx to FAKE category\n",
      "Copied dkrvorliqc to FAKE category\n",
      "Copied dkuayagnmc to REAL category\n",
      "Copied dkwjwbwgey to FAKE category\n",
      "Copied dkzvdrzcnr to REAL category\n",
      "Copied dlpoieqvfb to REAL category\n",
      "Copied dlrsbscitn to FAKE category\n",
      "Copied dnexlwbcxq to FAKE category\n",
      "Copied dnhvalzvrt to FAKE category\n",
      "Copied dntkzzzcdh to FAKE category\n",
      "Copied dnyvfblxpm to FAKE category\n",
      "Copied doanjploai to FAKE category\n",
      "Copied dofusvhnib to FAKE category\n",
      "Copied dozyddhild to FAKE category\n",
      "Copied dptbnjnkdg to FAKE category\n",
      "Copied dptrzdvwpg to FAKE category\n",
      "Copied dqnyszdong to FAKE category\n",
      "Copied dqppxmoqdl to FAKE category\n",
      "Copied dqqtjcryjv to FAKE category\n",
      "Copied dqswpjoepo to FAKE category\n",
      "Copied dqzreruvje to FAKE category\n",
      "Copied drcyabprvt to REAL category\n",
      "Copied drgjzlxzxj to FAKE category\n",
      "Copied drsakwyvqv to FAKE category\n",
      "Copied drtbksnpol to FAKE category\n",
      "Copied dsdoseflas to FAKE category\n",
      "Copied dsgpbgsrdm to FAKE category\n",
      "Copied dsjbknkujw to REAL category\n",
      "Copied dsndhujjjb to FAKE category\n",
      "Copied dtbpmdqvao to FAKE category\n",
      "Copied dtocdfbwca to FAKE category\n",
      "Copied dubiroskqn to FAKE category\n",
      "Copied dulanfulol to FAKE category\n",
      "Copied duvyaxbzvp to FAKE category\n",
      "Copied duycddgtrl to REAL category\n",
      "Copied duzuusuajr to FAKE category\n",
      "Copied dvakowbgbt to FAKE category\n",
      "Copied dvumqqhoac to FAKE category\n",
      "Copied dwediigjit to FAKE category\n",
      "Copied dxbqjxrhin to REAL category\n",
      "Copied dxuliowugt to FAKE category\n",
      "Copied dxuplhwvig to FAKE category\n",
      "Copied dzieklokdr to FAKE category\n",
      "Copied dzqwgqewhu to FAKE category\n",
      "Copied dzvyfiarrq to FAKE category\n",
      "Copied dzwkmcwkwl to FAKE category\n",
      "Copied dzyuwjkjui to REAL category\n",
      "Copied eahlqmfvtj to FAKE category\n",
      "Copied eajlrktemq to FAKE category\n",
      "Copied ebchwmwayp to FAKE category\n",
      "Copied ebebgmtlcu to FAKE category\n",
      "Copied ebeknhudxq to FAKE category\n",
      "Copied ebkzwjgjhq to FAKE category\n",
      "Copied ebywfrmhtd to FAKE category\n",
      "Copied eckvhdusax to REAL category\n",
      "Copied ecnihjlfyt to FAKE category\n",
      "Copied ecujsjhscd to REAL category\n",
      "Copied ecuvtoltue to FAKE category\n",
      "Copied ecwaxgutkc to FAKE category\n",
      "Copied eczrseixwq to FAKE category\n",
      "Copied edyncaijwx to REAL category\n",
      "Copied eebrkicpry to FAKE category\n",
      "Copied eebserckhh to FAKE category\n",
      "Copied eejswgycjc to FAKE category\n",
      "Copied eekozbeafq to FAKE category\n",
      "Copied eepezmygaq to FAKE category\n",
      "Copied eeyhxisdfh to FAKE category\n",
      "Copied efdyrflcpg to FAKE category\n",
      "Copied efwfxwwlbw to REAL category\n",
      "Copied egbbcxcuqy to FAKE category\n",
      "Copied eggbjzxnmg to REAL category\n",
      "Copied egghxjjmfg to REAL category\n",
      "Copied ehbnclaukr to FAKE category\n",
      "Copied ehccixxzoe to REAL category\n",
      "Copied ehdkmxgtxh to FAKE category\n",
      "Copied ehevsxtecd to FAKE category\n",
      "Copied ehfiekigla to FAKE category\n",
      "Copied ehieahnhte to FAKE category\n",
      "Copied ehtdtkmmli to REAL category\n",
      "Copied eiriyukqqy to FAKE category\n",
      "Copied eivxffliio to FAKE category\n",
      "Copied eiwopxzjfn to FAKE category\n",
      "Copied eixwxvxbbn to FAKE category\n",
      "Copied ejkqesyvam to FAKE category\n",
      "Copied ekcrtigpab to REAL category\n",
      "Copied ekhacizpah to FAKE category\n",
      "Copied ekkdjkirzq to FAKE category\n",
      "Copied elginszwtk to FAKE category\n",
      "Copied ellavthztb to REAL category\n",
      "Copied elvvackpjh to FAKE category\n",
      "Copied emaalmsonj to FAKE category\n",
      "Copied emfbhytfhc to FAKE category\n",
      "Copied emgjphonqb to FAKE category\n",
      "Copied ensyyivobf to FAKE category\n",
      "Copied eoewqcpbgt to FAKE category\n",
      "Copied eprybmbpba to FAKE category\n",
      "Copied epymyyiblu to FAKE category\n",
      "Copied eqjscdagiv to FAKE category\n",
      "Copied eqnoqyfquo to REAL category\n",
      "Copied eqvuznuwsa to FAKE category\n",
      "Copied erlvuvjsjf to REAL category\n",
      "Copied erqgqacbqe to FAKE category\n",
      "Copied errocgcham to FAKE category\n",
      "Copied esckbnkkvb to FAKE category\n",
      "Copied esgftaficx to FAKE category\n",
      "Copied esnntzzajv to FAKE category\n",
      "Copied esxrvsgpvb to FAKE category\n",
      "Copied esyhwdfnxs to FAKE category\n",
      "Copied esyrimvzsa to FAKE category\n",
      "Copied etdcqxabww to FAKE category\n",
      "Copied etejaapnxh to FAKE category\n",
      "Copied etmcruaihe to FAKE category\n",
      "Copied etohcvnzbj to FAKE category\n",
      "Copied eudeqjhdfd to REAL category\n",
      "Copied eukvucdetx to FAKE category\n",
      "Organization complete!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "input_frames_dir = \"output_frames\"\n",
    "output_dir = \"organized_frames\"\n",
    "metadata_file = \"metadata.json\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(os.path.join(output_dir, \"REAL\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, \"FAKE\"), exist_ok=True)\n",
    "\n",
    "# Read metadata\n",
    "with open(metadata_file, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Process each video\n",
    "for video, info in metadata.items():\n",
    "    label = info[\"label\"]\n",
    "    video_name = os.path.splitext(video)[0]  # Remove the .mp4 extension\n",
    "\n",
    "    # Source and destination paths\n",
    "    src_path = os.path.join(input_frames_dir, video_name)\n",
    "    dst_path = os.path.join(output_dir, label, video_name)\n",
    "\n",
    "    # Check if the source directory exists\n",
    "    if os.path.exists(src_path):\n",
    "        # Copy the frame folder to the appropriate category\n",
    "        shutil.copytree(src_path, dst_path)\n",
    "        print(f\"Copied {video_name} to {label} category\")\n",
    "    else:\n",
    "        print(f\"Warning: Frame folder for {video_name} not found\")\n",
    "\n",
    "print(\"Organization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a3081dfe09c7865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:30:34.171941Z",
     "start_time": "2024-09-03T05:30:34.065433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FAKE videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:00<00:00, 5803.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing REAL videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 5117.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM model...\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76        64\n",
      "           1       0.15      0.19      0.17        16\n",
      "\n",
      "    accuracy                           0.62        80\n",
      "   macro avg       0.47      0.46      0.46        80\n",
      "weighted avg       0.66      0.62      0.64        80\n",
      "\n",
      "SVM Accuracy: 0.62\n",
      "Training KNN model...\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79        64\n",
      "           1       0.13      0.12      0.13        16\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.46      0.46      0.46        80\n",
      "weighted avg       0.65      0.66      0.66        80\n",
      "\n",
      "KNN Accuracy: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames\"\n",
    "categories = [\"FAKE\", \"REAL\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM Model\n",
    "print(\"Training SVM model...\")\n",
    "svm_model = SVC(kernel='linear')  # You can experiment with different kernels like 'rbf'\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# KNN Model\n",
    "print(\"Training KNN model...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)  # You can adjust the number of neighbors\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate KNN\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(f\"KNN Accuracy: {accuracy_score(y_test, y_pred_knn):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc0773e7066c222b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:50:53.041160Z",
     "start_time": "2024-09-03T05:50:52.983629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FAKE videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [00:00<00:00, 12687.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: features.npy not found in organized_frames/FAKE/.DS_Store\n",
      "Processing REAL videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 11884.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: features.npy not found in organized_frames/REAL/.DS_Store\n",
      "Training SVM model...\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        64\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.40      0.50      0.44        80\n",
      "weighted avg       0.64      0.80      0.71        80\n",
      "\n",
      "SVM Accuracy: 0.80\n",
      "Training KNN model...\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        64\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.40      0.50      0.44        80\n",
      "weighted avg       0.64      0.80      0.71        80\n",
      "\n",
      "KNN Accuracy: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames\"\n",
    "categories = [\"FAKE\", \"REAL\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM Model\n",
    "print(\"Training SVM model...\")\n",
    "svm_model = SVC(kernel='sigmoid')  # You can experiment with different kernels like 'rbf'\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# KNN Model\n",
    "print(\"Training KNN model...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=80)  # You can adjust the number of neighbors\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate KNN\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(f\"KNN Accuracy: {accuracy_score(y_test, y_pred_knn):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50ab2074e3481e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:14:49.364107Z",
     "start_time": "2024-09-03T05:14:49.212334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fake videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:00<00:00, 3302.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing real videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 3647.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM model...\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76        64\n",
      "           1       0.15      0.19      0.17        16\n",
      "\n",
      "    accuracy                           0.62        80\n",
      "   macro avg       0.47      0.46      0.46        80\n",
      "weighted avg       0.66      0.62      0.64        80\n",
      "\n",
      "SVM Accuracy: 0.62\n",
      "Training KNN model...\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79        64\n",
      "           1       0.13      0.12      0.13        16\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.46      0.46      0.46        80\n",
      "weighted avg       0.65      0.66      0.66        80\n",
      "\n",
      "KNN Accuracy: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames\"\n",
    "categories = [\"fake\", \"real\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM Model\n",
    "print(\"Training SVM model...\")\n",
    "svm_model = SVC(kernel='linear')  # You can experiment with different kernels like 'rbf'\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# KNN Model\n",
    "print(\"Training KNN model...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)  # You can adjust the number of neighbors\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate KNN\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(f\"KNN Accuracy: {accuracy_score(y_test, y_pred_knn):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a99289f750187e1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:01:41.098032Z",
     "start_time": "2024-09-03T07:01:40.837621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fake videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [00:00<00:00, 1760.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: features.npy not found in organized_frames/fake/.DS_Store\n",
      "Processing real videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/78 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: features.npy not found in organized_frames/real/.DS_Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 1895.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM model...\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        64\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.40      0.50      0.44        80\n",
      "weighted avg       0.64      0.80      0.71        80\n",
      "\n",
      "SVM Accuracy: 0.80\n",
      "Training KNN model...\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89        64\n",
      "           1       0.67      0.12      0.21        16\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.74      0.55      0.55        80\n",
      "weighted avg       0.79      0.81      0.76        80\n",
      "\n",
      "KNN Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames\"\n",
    "categories = [\"fake\", \"real\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM Model\n",
    "print(\"Training SVM model...\")\n",
    "svm_model = SVC(kernel='sigmoid')  # You can experiment with different kernels like 'rbf'\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# KNN Model\n",
    "print(\"Training KNN model...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=4)  # You can adjust the number of neighbors\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate KNN\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(f\"KNN Accuracy: {accuracy_score(y_test, y_pred_knn):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c589f69b03184b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T05:13:19.976955Z",
     "start_time": "2024-09-03T05:13:19.915225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fake videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:00<00:00, 12719.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing real videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 11563.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM model...\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        64\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.40      0.50      0.44        80\n",
      "weighted avg       0.64      0.80      0.71        80\n",
      "\n",
      "SVM Accuracy: 0.80\n",
      "Training KNN model...\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89        64\n",
      "           1       0.67      0.12      0.21        16\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.74      0.55      0.55        80\n",
      "weighted avg       0.79      0.81      0.76        80\n",
      "\n",
      "KNN Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames\"\n",
    "categories = [\"fake\", \"real\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM Model\n",
    "print(\"Training SVM model...\")\n",
    "svm_model = SVC(kernel='poly')  # You can experiment with different kernels like 'rbf'\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# KNN Model\n",
    "print(\"Training KNN model...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=10)  # You can adjust the number of neighbors\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate KNN\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(f\"KNN Accuracy: {accuracy_score(y_test, y_pred_knn):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f217f4dfb85d5676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

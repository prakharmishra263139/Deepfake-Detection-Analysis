{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change to code to  save the storage space .Earlier it used to calculate frames for all the video and then after storing it .It used to give all the frame for each video to get features.npy for each video. frame for 400 video of 2.1GB tool 76GB of space .hence it will not be  feasible use for larger dataset of 1000 or 10k video\n",
    "\n",
    "# hence instead of doing ela for all video and giving input to CNN we Instead of processing multiple ELA images, we now only process the 'error_level_plot.png' for each video folder.We extract features from this single image and save them as 'features.npy'.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T09:51:47.412171Z",
     "start_time": "2024-10-11T09:51:01.729828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def resize_frame(frame, scale_factor=0.5):\n",
    "    height, width = frame.shape[:2]\n",
    "    new_size = (int(width * scale_factor), int(height * scale_factor))\n",
    "    resized_frame = cv2.resize(frame, new_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "    return resized_frame\n",
    "\n",
    "def apply_ela(image_path, scale_factor=0.5):\n",
    "    original = Image.open(image_path)\n",
    "    original = original.convert(\"RGB\")\n",
    "\n",
    "    resized = original.resize((int(original.width * scale_factor), int(original.height * scale_factor)), Image.Resampling.LANCZOS)\n",
    "\n",
    "    original_np = np.array(original)\n",
    "    resized_np = np.array(resized)\n",
    "\n",
    "    error_level = ImageChops.difference(Image.fromarray(original_np), Image.fromarray(resized_np))\n",
    "\n",
    "    error_level_np = np.array(error_level)\n",
    "\n",
    "    mean_error = np.mean(error_level_np)\n",
    "\n",
    "    return mean_error\n",
    "\n",
    "def process_videos(video_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    video_files = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
    "        video_output_folder = os.path.join(output_folder, video_name)\n",
    "        if not os.path.exists(video_output_folder):\n",
    "            os.makedirs(video_output_folder)\n",
    "\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video file {video_file}\")\n",
    "            continue\n",
    "\n",
    "        frame_number = 0\n",
    "        mean_errors = []\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            resized_frame = resize_frame(frame)\n",
    "\n",
    "            frame_filename = os.path.join(video_output_folder, f\"frame_{frame_number}.png\")\n",
    "            cv2.imwrite(frame_filename, resized_frame)\n",
    "\n",
    "            mean_error = apply_ela(frame_filename)\n",
    "            mean_errors.append(mean_error)\n",
    "\n",
    "            os.remove(frame_filename)  # Delete the frame image after processing\n",
    "\n",
    "            frame_number += 1\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"Processing complete for {video_file}\")\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(mean_errors, label=f'Error Level - {video_name}')\n",
    "        plt.xlabel('Frame Number')\n",
    "        plt.ylabel('Mean Error Level')\n",
    "        plt.title(f'Mean Error Level Across Frames for {video_name}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(video_output_folder, 'error_level_plot.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # Save mean_errors as a numpy array\n",
    "        np.save(os.path.join(video_output_folder, 'mean_errors.npy'), np.array(mean_errors))\n",
    "\n",
    "# Example usage\n",
    "video_folder = \"train_sample_videos\"\n",
    "output_folder = \"output_frames\"\n",
    "\n",
    "process_videos(video_folder, output_folder)"
   ],
   "id": "c5ee3c471a51dd19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete for train_sample_videos/cdaxixbosp.mp4\n",
      "Processing complete for train_sample_videos/btiysiskpf.mp4\n",
      "Processing complete for train_sample_videos/clihsshdkq.mp4\n",
      "Processing complete for train_sample_videos/alvgwypubw.mp4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 88\u001B[0m\n\u001B[1;32m     85\u001B[0m video_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_sample_videos\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     86\u001B[0m output_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_frames\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 88\u001B[0m \u001B[43mprocess_videos\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvideo_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_folder\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[27], line 61\u001B[0m, in \u001B[0;36mprocess_videos\u001B[0;34m(video_folder, output_folder)\u001B[0m\n\u001B[1;32m     58\u001B[0m frame_filename \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(video_output_folder, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mframe_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mframe_number\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.png\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     59\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimwrite(frame_filename, resized_frame)\n\u001B[0;32m---> 61\u001B[0m mean_error \u001B[38;5;241m=\u001B[39m \u001B[43mapply_ela\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe_filename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m mean_errors\u001B[38;5;241m.\u001B[39mappend(mean_error)\n\u001B[1;32m     64\u001B[0m os\u001B[38;5;241m.\u001B[39mremove(frame_filename)  \u001B[38;5;66;03m# Delete the frame image after processing\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[27], line 17\u001B[0m, in \u001B[0;36mapply_ela\u001B[0;34m(image_path, scale_factor)\u001B[0m\n\u001B[1;32m     14\u001B[0m original \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(image_path)\n\u001B[1;32m     15\u001B[0m original \u001B[38;5;241m=\u001B[39m original\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 17\u001B[0m resized \u001B[38;5;241m=\u001B[39m \u001B[43moriginal\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moriginal\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwidth\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mscale_factor\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moriginal\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheight\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mscale_factor\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mResampling\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLANCZOS\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m original_np \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(original)\n\u001B[1;32m     20\u001B[0m resized_np \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(resized)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/PIL/Image.py:2328\u001B[0m, in \u001B[0;36mImage.resize\u001B[0;34m(self, size, resample, box, reducing_gap)\u001B[0m\n\u001B[1;32m   2316\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   2317\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduce(factor, box\u001B[38;5;241m=\u001B[39mreduce_box)\n\u001B[1;32m   2318\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduce)\n\u001B[1;32m   2319\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m Image\u001B[38;5;241m.\u001B[39mreduce(\u001B[38;5;28mself\u001B[39m, factor, box\u001B[38;5;241m=\u001B[39mreduce_box)\n\u001B[1;32m   2320\u001B[0m         )\n\u001B[1;32m   2321\u001B[0m         box \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   2322\u001B[0m             (box[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m-\u001B[39m reduce_box[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m/\u001B[39m factor_x,\n\u001B[1;32m   2323\u001B[0m             (box[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m-\u001B[39m reduce_box[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m/\u001B[39m factor_y,\n\u001B[1;32m   2324\u001B[0m             (box[\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m-\u001B[39m reduce_box[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m/\u001B[39m factor_x,\n\u001B[1;32m   2325\u001B[0m             (box[\u001B[38;5;241m3\u001B[39m] \u001B[38;5;241m-\u001B[39m reduce_box[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m/\u001B[39m factor_y,\n\u001B[1;32m   2326\u001B[0m         )\n\u001B[0;32m-> 2328\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_new(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbox\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T06:41:05.947437Z",
     "start_time": "2024-10-11T06:41:05.940467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# modified above code to skip the file which has already been processed\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def resize_frame(frame, scale_factor=0.5):\n",
    "    height, width = frame.shape[:2]\n",
    "    new_size = (int(width * scale_factor), int(height * scale_factor))\n",
    "    resized_frame = cv2.resize(frame, new_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "    return resized_frame\n",
    "\n",
    "def apply_ela(image_path, scale_factor=0.5):\n",
    "    original = Image.open(image_path)\n",
    "    original = original.convert(\"RGB\")#L FOR TRANSLATING COLOR IMAGE TO GREYSCALE\n",
    "\n",
    "    resized = original.resize((int(original.width * scale_factor), int(original.height * scale_factor)), Image.Resampling.LANCZOS)\n",
    "\n",
    "    original_np = np.array(original)\n",
    "    resized_np = np.array(resized)\n",
    "\n",
    "    error_level = ImageChops.difference(Image.fromarray(original_np), Image.fromarray(resized_np))\n",
    "\n",
    "    error_level_np = np.array(error_level)\n",
    "\n",
    "    mean_error = np.mean(error_level_np)\n",
    "\n",
    "    return mean_error\n",
    "\n",
    "def process_videos(video_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    video_files = [os.path.join(video_folder, f) for f in os.listdir(video_folder) if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
    "        video_output_folder = os.path.join(output_folder, video_name)\n",
    "\n",
    "        # Skip processing if mean_errors.npy already exists\n",
    "        if os.path.exists(os.path.join(video_output_folder, 'mean_errors.npy')):\n",
    "            print(f\"Skipping {video_file} as it has already been processed.\")\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists(video_output_folder):\n",
    "            os.makedirs(video_output_folder)\n",
    "\n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video file {video_file}\")\n",
    "            continue\n",
    "\n",
    "        frame_number = 0\n",
    "        mean_errors = []\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            resized_frame = resize_frame(frame)\n",
    "\n",
    "            frame_filename = os.path.join(video_output_folder, f\"frame_{frame_number}.png\")\n",
    "            cv2.imwrite(frame_filename, resized_frame)\n",
    "\n",
    "            mean_error = apply_ela(frame_filename)\n",
    "            mean_errors.append(mean_error)\n",
    "\n",
    "            os.remove(frame_filename)  # Delete the frame image after processing\n",
    "\n",
    "            frame_number += 1\n",
    "\n",
    "        cap.release()\n",
    "        print(f\"Processing complete for {video_file}\")\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(mean_errors, label=f'Error Level - {video_name}')\n",
    "        plt.xlabel('Frame Number')\n",
    "        plt.ylabel('Mean Error Level')\n",
    "        plt.title(f'Mean Error Level Across Frames for {video_name}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(video_output_folder, 'error_level_plot.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # Save mean_errors as a numpy array\n",
    "        np.save(os.path.join(video_output_folder, 'mean_errors.npy'), np.array(mean_errors))\n",
    "\n",
    "# Example usage\n",
    "video_folder = \"train_sample_videos\"\n",
    "output_folder = \"output_frames\"\n",
    "\n",
    "process_videos(video_folder, output_folder)\n"
   ],
   "id": "d89db71ffe0cb33b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping train_sample_videos/cdaxixbosp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/btiysiskpf.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/clihsshdkq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/alvgwypubw.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eqvuznuwsa.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eudeqjhdfd.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eeyhxisdfh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cizlkenljw.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bndybcqhfr.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cuzrgrbvil.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/atyntldecu.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bggsurpgpr.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eckvhdusax.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dvakowbgbt.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dqqtjcryjv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/djvutyvaio.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dzwkmcwkwl.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bpapbctoao.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aettqgevhz.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bbhtdfuqxq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/caifxvsozs.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bgaogsjehq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/agqphdxmwt.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ebywfrmhtd.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bsqgziaylx.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ciyoudyhly.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bxzakyopjf.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cknyxaqouy.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/avnqydkqjj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dakiztgtnw.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/acifjvzvpm.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dofusvhnib.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ahqqqilsxt.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/avtycwsgyb.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cvaksbpssm.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/brwrlczjvi.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bgwmmujlmc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dhkwmjxwrn.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bmjmjmbglm.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/emgjphonqb.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bzmdrafeex.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dsgpbgsrdm.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/afoovlsmtx.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ebeknhudxq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ccfoszqabv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dnexlwbcxq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ensyyivobf.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/apgjqzkoma.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bqeiblbxtl.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eqjscdagiv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ejkqesyvam.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bilnggbxgu.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bulkxhhknf.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cdphtzqrvp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cmxcfkrjiv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cwsbspfzck.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bsfmwclnqy.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ajqslcypsw.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eebrkicpry.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aklqzsddfl.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aqpnvjhuzw.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bvzjkezkms.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bmhvktyiwp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/acxnxvbsxk.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cyboodqqyr.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/czkdanyadc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/esgftaficx.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aagfhgtpmv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bmbbkwmxqj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dqnyszdong.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/btunxncpjh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bnbuonyoje.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bhpwpydzpo.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bbvgxeczei.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/apogckdfrz.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/esnntzzajv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/chzieimrwu.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dhcndnuwta.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/awukslzjra.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/amowujxmzc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dbhoxkblzx.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/akvmwkdyuv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bqnymlsayl.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aevrfsexku.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/abqwwspghj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/byofowlkki.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cycacemkmt.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/arkroixhey.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/asmpfjfzif.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eprybmbpba.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/btugrnoton.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bwipwzzxxu.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cwwandrkus.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/emaalmsonj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bqkdbcqjvb.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aytzyidmgs.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/avssvvsdhz.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/avibnnhwhp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bchnbulevv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/btohlidmru.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/elginszwtk.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/augtsuxpzc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/andaxzscny.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dulanfulol.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/crktehraph.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/alninxcyhg.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ecujsjhscd.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bwuwstvsbw.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/doanjploai.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aelzhcnwgf.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/efdyrflcpg.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aknbdpmgua.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/agrmhtjdlk.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aapnvogymq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/edyncaijwx.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bweezhfpzp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/avywawptfc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/brvqtabyxj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cpjxareypw.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cobjrlugvp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ehtdtkmmli.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eajlrktemq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aknmpoonls.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ceymbecxnj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/agdkmztvby.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aczrgyricp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ebebgmtlcu.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/btmsngnqhv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/btjlfpzbdu.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/crzfebnfgb.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dcamvmuors.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bntlodcfeg.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/abofeumbvv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dcuiiorugd.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/axczxisdtb.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cwrtyzndpx.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/anpuvshzoo.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/czfunozvwp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bmehkyanbj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eukvucdetx.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cqhngvpgyi.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cwbacdwrzo.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bguwlyazau.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/byyqectxqa.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bahdpoesir.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dgxrqjdomn.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ctzmavwror.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dkrvorliqc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/etejaapnxh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/caqbrkogkb.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bkvetcojbt.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bdxuhamuqx.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bqtuuwzdtr.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bhsluedavd.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cttqtsjvgn.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/covdcysmbi.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cthdnahrkh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/btjwbtsgln.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/axwovszumc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/brhalypwoo.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cffffbcywc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dzqwgqewhu.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/adohikbdaz.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/adylbeequz.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eqnoqyfquo.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dhevettufk.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ebkzwjgjhq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cqrskwiqng.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eejswgycjc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/boovltmuwi.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cwqlvzefpg.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aorjvbyxhw.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ecnihjlfyt.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/avfitoutyn.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eahlqmfvtj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/adhsbajydo.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ehfiekigla.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bdnaqemxmr.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/asvcrfdpnq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/chtapglbcj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bourlmzsio.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/etmcruaihe.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/acxwigylke.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/atkdltyyen.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dbhrpizyeq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ccmonzqfrz.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ahbweevwpv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dntkzzzcdh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bbhpvrmbse.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dakqwktlbi.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/benmsfzfaz.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/etdcqxabww.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/atxvxouljq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cgvrgibpfo.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bghphrsfxf.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/blzydqdfem.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/etohcvnzbj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cmbzllswnl.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cnilkgvfei.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/duzuusuajr.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/asaxgevnnp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/egghxjjmfg.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bdgipnyobr.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eepezmygaq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/curpwogllm.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/diopzaywor.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/chviwxsfhg.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bmjzrlszhi.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dwediigjit.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cyclgfjdrv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cettndmvzl.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ddhfabwpuz.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/drgjzlxzxj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dbtbbhakdv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bjjbwsqjir.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dsdoseflas.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dsjbknkujw.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dhjmzhrcav.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dptbnjnkdg.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ddpvuimigj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/byfenovjnf.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/asdpeebotb.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dptrzdvwpg.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ehieahnhte.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/awnwkrqibf.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/axoygtekut.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/esxrvsgpvb.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bpxckdzddv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dzieklokdr.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dkdwxmtpuo.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ckkuyewywx.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/abarnvbtwb.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bydaidkpdp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/byijojkdba.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cglxirfaey.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cxfujlvsuw.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dkuayagnmc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/duycddgtrl.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ekcrtigpab.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/amaivqofda.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ehdkmxgtxh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/byqzyxifza.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/diomeixhrg.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dxbqjxrhin.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/beboztfcme.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/coadfnerlk.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/drsakwyvqv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/errocgcham.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/clrycekyst.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bffwsjxghk.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/arrhsnjqku.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/emfbhytfhc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aladcziidp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bmioepcpsx.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bqhtpqmmqp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bopqhhalml.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ctpqeykqdp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ayqvfdhslr.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dxuplhwvig.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eekozbeafq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bkmdzhfzfh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ecwaxgutkc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cppdvdejkc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dqzreruvje.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/avgiuextiz.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/arlmiizoob.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cxttmymlbn.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ahdbuwqxit.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cferslmfwh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dlpoieqvfb.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/akxoopqjqz.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dsndhujjjb.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/axntxmycwd.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dbzpcjntve.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ckjaibzfxa.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bseamdrpbj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dnhvalzvrt.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/deywhkarol.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cdyakrxkia.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dhoqofwoxa.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eiriyukqqy.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/deyyistcrd.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/awhmfnnjih.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dvumqqhoac.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cfxkpiweqt.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eivxffliio.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dfbpceeaox.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dtocdfbwca.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/diuzrpqjli.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dbzcqmxzaj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bjkmjilrxp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/czmqpxrqoh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aelfnikyqj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cqfugiqupm.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bejhvclboh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bddjdhzfze.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bctvsmddgq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/degpbqvcay.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/duvyaxbzvp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bqqpbzjgup.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ehbnclaukr.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ddjggcasdw.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cepxysienc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/btxlttbpkj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bofqajtwve.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aybumesmpk.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/axwgcsyphv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cfyduhpbps.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ckbdwedgmc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/crezycjqyk.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dboxtiehng.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ekhacizpah.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cprhtltsjp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bzythlfnhq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/elvvackpjh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ebchwmwayp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bjsmaqefoi.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aufmsmnoye.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/esyhwdfnxs.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dzvyfiarrq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cdbsbdymzd.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bpwzipqtxf.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bnjcdrfuov.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ajwpjhrbcv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aybgughjxh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/efwfxwwlbw.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bwhlgysghg.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/akzbnazxtz.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/azpuxunqyo.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cksanfsjhc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bgmlwsoamc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cxrfacemmq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eggbjzxnmg.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eoewqcpbgt.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/drtbksnpol.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dqppxmoqdl.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dhcselezer.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bvgwelbeof.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bqdjzqhcft.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aslsvlvpth.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ddqccgmtka.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dgmevclvzy.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/altziddtxi.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dhxctgyoqj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ahfazfbntc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/djvtbgwdcc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dgzklxjmix.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/alaijyygdv.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eebserckhh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/erqgqacbqe.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/avvdgsennp.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dkzvdrzcnr.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ekkdjkirzq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/apatcsqejh.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/djxdyjopjd.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bhaaboftbc.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/blpchvmhxx.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bhbdugnurr.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aipfdnwpoo.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/drcyabprvt.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bdbhekrrwo.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ehccixxzoe.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eixwxvxbbn.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/atvmxvwyns.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cyxlcuyznd.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dozyddhild.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bgvhtpzknn.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cbbibzcoih.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/atzdznmder.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eiwopxzjfn.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/esyrimvzsa.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/cbltdtxglo.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dbnygxtwek.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dubiroskqn.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/bkwxhglwct.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/azsmewqghg.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/aneclqfpbt.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ehevsxtecd.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dnyvfblxpm.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dkhlttuvmx.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/erlvuvjsjf.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dtbpmdqvao.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/beyebyhrph.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/epymyyiblu.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dzyuwjkjui.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dxuliowugt.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ecuvtoltue.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dqswpjoepo.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/acqfdwsrhi.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/diqraixiov.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ellavthztb.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/avmjormvsx.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/egbbcxcuqy.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/byunigvnay.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/ddepeddixj.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dkwjwbwgey.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/esckbnkkvb.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/eczrseixwq.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dlrsbscitn.mp4 as it has already been processed.\n",
      "Skipping train_sample_videos/dafhtipaml.mp4 as it has already been processed.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T09:54:42.614594Z",
     "start_time": "2024-10-11T09:54:37.354208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# USE PRETRAINED MODEL RESNET18 TO EXTRACT FEATURE\n",
    "import os\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "model.eval()\n",
    "\n",
    "def extract_features(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "        print(f\"Processing image: {image_path}\")\n",
    "        print(f\"Image tensor shape: {image_tensor.shape}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = model(image_tensor)\n",
    "            print(f\"Extracted features shape: {features.shape}\")\n",
    "\n",
    "        features = features.squeeze().numpy()\n",
    "        print(f\"Squeezed features shape: {features.shape}\")\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_video_folders(base_folder):\n",
    "    for video_folder in os.listdir(base_folder):\n",
    "        video_folder_path = os.path.join(base_folder, video_folder)\n",
    "        if not os.path.isdir(video_folder_path):\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing video folder: {video_folder}\")\n",
    "\n",
    "        error_level_plot = os.path.join(video_folder_path, 'error_level_plot.png')\n",
    "\n",
    "        if os.path.exists(error_level_plot):\n",
    "            features = extract_features(error_level_plot)\n",
    "            if features is not None and features.size > 0:\n",
    "                features_output_path = os.path.join(video_folder_path, 'features.npy')\n",
    "                np.save(features_output_path, features)\n",
    "                print(f\"Features saved for {video_folder}\")\n",
    "            else:\n",
    "                print(f\"No features were extracted for {video_folder}\")\n",
    "        else:\n",
    "            print(f\"Error level plot not found for {video_folder}\")\n",
    "\n",
    "# Example usage\n",
    "base_folder = \"output_frames\"\n",
    "process_video_folders(base_folder)"
   ],
   "id": "4f9f6286b96125ed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video folder: ahqqqilsxt\n",
      "Processing image: output_frames/ahqqqilsxt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ahqqqilsxt\n",
      "Processing video folder: djvtbgwdcc\n",
      "Processing image: output_frames/djvtbgwdcc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for djvtbgwdcc\n",
      "Processing video folder: atzdznmder\n",
      "Processing image: output_frames/atzdznmder/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for atzdznmder\n",
      "Processing video folder: esyrimvzsa\n",
      "Processing image: output_frames/esyrimvzsa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for esyrimvzsa\n",
      "Processing video folder: dptrzdvwpg\n",
      "Processing image: output_frames/dptrzdvwpg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dptrzdvwpg\n",
      "Processing video folder: bjkmjilrxp\n",
      "Processing image: output_frames/bjkmjilrxp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bjkmjilrxp\n",
      "Processing video folder: dbhrpizyeq\n",
      "Processing image: output_frames/dbhrpizyeq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dbhrpizyeq\n",
      "Processing video folder: cffffbcywc\n",
      "Processing image: output_frames/cffffbcywc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cffffbcywc\n",
      "Processing video folder: caifxvsozs\n",
      "Processing image: output_frames/caifxvsozs/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for caifxvsozs\n",
      "Processing video folder: dzqwgqewhu\n",
      "Processing image: output_frames/dzqwgqewhu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dzqwgqewhu\n",
      "Processing video folder: bpwzipqtxf\n",
      "Processing image: output_frames/bpwzipqtxf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bpwzipqtxf\n",
      "Processing video folder: dbzpcjntve\n",
      "Processing image: output_frames/dbzpcjntve/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dbzpcjntve\n",
      "Processing video folder: chviwxsfhg\n",
      "Processing image: output_frames/chviwxsfhg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for chviwxsfhg\n",
      "Processing video folder: aettqgevhz\n",
      "Processing image: output_frames/aettqgevhz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aettqgevhz\n",
      "Processing video folder: ekkdjkirzq\n",
      "Processing image: output_frames/ekkdjkirzq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ekkdjkirzq\n",
      "Processing video folder: esckbnkkvb\n",
      "Processing image: output_frames/esckbnkkvb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for esckbnkkvb\n",
      "Processing video folder: coadfnerlk\n",
      "Processing image: output_frames/coadfnerlk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for coadfnerlk\n",
      "Processing video folder: diqraixiov\n",
      "Processing image: output_frames/diqraixiov/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for diqraixiov\n",
      "Processing video folder: ddepeddixj\n",
      "Processing image: output_frames/ddepeddixj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ddepeddixj\n",
      "Processing video folder: cxfujlvsuw\n",
      "Processing image: output_frames/cxfujlvsuw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cxfujlvsuw\n",
      "Processing video folder: diomeixhrg\n",
      "Processing image: output_frames/diomeixhrg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for diomeixhrg\n",
      "Processing video folder: bffwsjxghk\n",
      "Processing image: output_frames/bffwsjxghk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bffwsjxghk\n",
      "Processing video folder: bvgwelbeof\n",
      "Processing image: output_frames/bvgwelbeof/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bvgwelbeof\n",
      "Processing video folder: ebchwmwayp\n",
      "Processing image: output_frames/ebchwmwayp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ebchwmwayp\n",
      "Processing video folder: brhalypwoo\n",
      "Processing image: output_frames/brhalypwoo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for brhalypwoo\n",
      "Processing video folder: alvgwypubw\n",
      "Processing image: output_frames/alvgwypubw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for alvgwypubw\n",
      "Processing video folder: bsfmwclnqy\n",
      "Processing image: output_frames/bsfmwclnqy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bsfmwclnqy\n",
      "Processing video folder: deywhkarol\n",
      "Processing image: output_frames/deywhkarol/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for deywhkarol\n",
      "Processing video folder: dakqwktlbi\n",
      "Processing image: output_frames/dakqwktlbi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dakqwktlbi\n",
      "Processing video folder: bwhlgysghg\n",
      "Processing image: output_frames/bwhlgysghg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bwhlgysghg\n",
      "Processing video folder: cyboodqqyr\n",
      "Processing image: output_frames/cyboodqqyr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cyboodqqyr\n",
      "Processing video folder: bmbbkwmxqj\n",
      "Processing image: output_frames/bmbbkwmxqj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bmbbkwmxqj\n",
      "Processing video folder: acxnxvbsxk\n",
      "Processing image: output_frames/acxnxvbsxk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for acxnxvbsxk\n",
      "Processing video folder: eivxffliio\n",
      "Processing image: output_frames/eivxffliio/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eivxffliio\n",
      "Processing video folder: djvutyvaio\n",
      "Processing image: output_frames/djvutyvaio/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for djvutyvaio\n",
      "Processing video folder: eudeqjhdfd\n",
      "Processing image: output_frames/eudeqjhdfd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eudeqjhdfd\n",
      "Processing video folder: ecwaxgutkc\n",
      "Processing image: output_frames/ecwaxgutkc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ecwaxgutkc\n",
      "Processing video folder: dcuiiorugd\n",
      "Processing image: output_frames/dcuiiorugd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dcuiiorugd\n",
      "Processing video folder: cwwandrkus\n",
      "Processing image: output_frames/cwwandrkus/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cwwandrkus\n",
      "Processing video folder: avmjormvsx\n",
      "Processing image: output_frames/avmjormvsx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avmjormvsx\n",
      "Processing video folder: ciyoudyhly\n",
      "Processing image: output_frames/ciyoudyhly/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ciyoudyhly\n",
      "Processing video folder: bggsurpgpr\n",
      "Processing image: output_frames/bggsurpgpr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bggsurpgpr\n",
      "Processing video folder: avnqydkqjj\n",
      "Processing image: output_frames/avnqydkqjj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avnqydkqjj\n",
      "Processing video folder: edyncaijwx\n",
      "Processing image: output_frames/edyncaijwx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for edyncaijwx\n",
      "Processing video folder: drsakwyvqv\n",
      "Processing image: output_frames/drsakwyvqv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for drsakwyvqv\n",
      "Processing video folder: benmsfzfaz\n",
      "Processing image: output_frames/benmsfzfaz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for benmsfzfaz\n",
      "Processing video folder: ckjaibzfxa\n",
      "Processing image: output_frames/ckjaibzfxa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ckjaibzfxa\n",
      "Processing video folder: eqnoqyfquo\n",
      "Processing image: output_frames/eqnoqyfquo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eqnoqyfquo\n",
      "Processing video folder: ddpvuimigj\n",
      "Processing image: output_frames/ddpvuimigj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ddpvuimigj\n",
      "Processing video folder: bctvsmddgq\n",
      "Processing image: output_frames/bctvsmddgq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bctvsmddgq\n",
      "Processing video folder: dvakowbgbt\n",
      "Processing image: output_frames/dvakowbgbt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dvakowbgbt\n",
      "Processing video folder: ahfazfbntc\n",
      "Processing image: output_frames/ahfazfbntc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ahfazfbntc\n",
      "Processing video folder: ekhacizpah\n",
      "Processing image: output_frames/ekhacizpah/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ekhacizpah\n",
      "Processing video folder: bwuwstvsbw\n",
      "Processing image: output_frames/bwuwstvsbw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bwuwstvsbw\n",
      "Processing video folder: abqwwspghj\n",
      "Processing image: output_frames/abqwwspghj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for abqwwspghj\n",
      "Processing video folder: bhpwpydzpo\n",
      "Processing image: output_frames/bhpwpydzpo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bhpwpydzpo\n",
      "Processing video folder: dsndhujjjb\n",
      "Processing image: output_frames/dsndhujjjb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dsndhujjjb\n",
      "Processing video folder: cdyakrxkia\n",
      "Processing image: output_frames/cdyakrxkia/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cdyakrxkia\n",
      "Processing video folder: bpapbctoao\n",
      "Processing image: output_frames/bpapbctoao/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bpapbctoao\n",
      "Processing video folder: bnjcdrfuov\n",
      "Processing image: output_frames/bnjcdrfuov/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bnjcdrfuov\n",
      "Processing video folder: dgxrqjdomn\n",
      "Processing image: output_frames/dgxrqjdomn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dgxrqjdomn\n",
      "Processing video folder: axwgcsyphv\n",
      "Processing image: output_frames/axwgcsyphv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for axwgcsyphv\n",
      "Processing video folder: dtbpmdqvao\n",
      "Processing image: output_frames/dtbpmdqvao/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dtbpmdqvao\n",
      "Processing video folder: dntkzzzcdh\n",
      "Processing image: output_frames/dntkzzzcdh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dntkzzzcdh\n",
      "Processing video folder: ayqvfdhslr\n",
      "Processing image: output_frames/ayqvfdhslr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ayqvfdhslr\n",
      "Processing video folder: ehfiekigla\n",
      "Processing image: output_frames/ehfiekigla/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ehfiekigla\n",
      "Processing video folder: byyqectxqa\n",
      "Processing image: output_frames/byyqectxqa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for byyqectxqa\n",
      "Processing video folder: drcyabprvt\n",
      "Processing image: output_frames/drcyabprvt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for drcyabprvt\n",
      "Processing video folder: dsjbknkujw\n",
      "Processing image: output_frames/dsjbknkujw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dsjbknkujw\n",
      "Processing video folder: avywawptfc\n",
      "Processing image: output_frames/avywawptfc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avywawptfc\n",
      "Processing video folder: avssvvsdhz\n",
      "Processing image: output_frames/avssvvsdhz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avssvvsdhz\n",
      "Processing video folder: aybgughjxh\n",
      "Processing image: output_frames/aybgughjxh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aybgughjxh\n",
      "Processing video folder: egghxjjmfg\n",
      "Processing image: output_frames/egghxjjmfg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for egghxjjmfg\n",
      "Processing video folder: curpwogllm\n",
      "Processing image: output_frames/curpwogllm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for curpwogllm\n",
      "Processing video folder: cbltdtxglo\n",
      "Processing image: output_frames/cbltdtxglo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cbltdtxglo\n",
      "Processing video folder: dhcndnuwta\n",
      "Processing image: output_frames/dhcndnuwta/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dhcndnuwta\n",
      "Processing video folder: dvumqqhoac\n",
      "Processing image: output_frames/dvumqqhoac/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dvumqqhoac\n",
      "Processing video folder: dqzreruvje\n",
      "Processing image: output_frames/dqzreruvje/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dqzreruvje\n",
      "Processing video folder: bdbhekrrwo\n",
      "Processing image: output_frames/bdbhekrrwo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bdbhekrrwo\n",
      "Processing video folder: awukslzjra\n",
      "Processing image: output_frames/awukslzjra/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for awukslzjra\n",
      "Processing video folder: czkdanyadc\n",
      "Processing image: output_frames/czkdanyadc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for czkdanyadc\n",
      "Processing video folder: aslsvlvpth\n",
      "Processing image: output_frames/aslsvlvpth/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aslsvlvpth\n",
      "Processing video folder: dozyddhild\n",
      "Processing image: output_frames/dozyddhild/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dozyddhild\n",
      "Processing video folder: dqnyszdong\n",
      "Processing image: output_frames/dqnyszdong/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dqnyszdong\n",
      "Processing video folder: bqkdbcqjvb\n",
      "Processing image: output_frames/bqkdbcqjvb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bqkdbcqjvb\n",
      "Processing video folder: bvzjkezkms\n",
      "Processing image: output_frames/bvzjkezkms/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bvzjkezkms\n",
      "Processing video folder: ensyyivobf\n",
      "Processing image: output_frames/ensyyivobf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ensyyivobf\n",
      "Processing video folder: cuzrgrbvil\n",
      "Processing image: output_frames/cuzrgrbvil/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cuzrgrbvil\n",
      "Processing video folder: dzyuwjkjui\n",
      "Processing image: output_frames/dzyuwjkjui/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dzyuwjkjui\n",
      "Processing video folder: dafhtipaml\n",
      "Processing image: output_frames/dafhtipaml/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dafhtipaml\n",
      "Processing video folder: dqswpjoepo\n",
      "Processing image: output_frames/dqswpjoepo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dqswpjoepo\n",
      "Processing video folder: etdcqxabww\n",
      "Processing image: output_frames/etdcqxabww/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for etdcqxabww\n",
      "Processing video folder: bgwmmujlmc\n",
      "Processing image: output_frames/bgwmmujlmc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bgwmmujlmc\n",
      "Processing video folder: esyhwdfnxs\n",
      "Processing image: output_frames/esyhwdfnxs/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for esyhwdfnxs\n",
      "Processing video folder: bndybcqhfr\n",
      "Processing image: output_frames/bndybcqhfr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bndybcqhfr\n",
      "Processing video folder: cnilkgvfei\n",
      "Processing image: output_frames/cnilkgvfei/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cnilkgvfei\n",
      "Processing video folder: djxdyjopjd\n",
      "Processing image: output_frames/djxdyjopjd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for djxdyjopjd\n",
      "Processing video folder: dkwjwbwgey\n",
      "Processing image: output_frames/dkwjwbwgey/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dkwjwbwgey\n",
      "Processing video folder: dqqtjcryjv\n",
      "Processing image: output_frames/dqqtjcryjv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dqqtjcryjv\n",
      "Processing video folder: eepezmygaq\n",
      "Processing image: output_frames/eepezmygaq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eepezmygaq\n",
      "Processing video folder: bkvetcojbt\n",
      "Processing image: output_frames/bkvetcojbt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bkvetcojbt\n",
      "Processing video folder: cyxlcuyznd\n",
      "Processing image: output_frames/cyxlcuyznd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cyxlcuyznd\n",
      "Processing video folder: bseamdrpbj\n",
      "Processing image: output_frames/bseamdrpbj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bseamdrpbj\n",
      "Processing video folder: bchnbulevv\n",
      "Processing image: output_frames/bchnbulevv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bchnbulevv\n",
      "Processing video folder: cqrskwiqng\n",
      "Processing image: output_frames/cqrskwiqng/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cqrskwiqng\n",
      "Processing video folder: atyntldecu\n",
      "Processing image: output_frames/atyntldecu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for atyntldecu\n",
      "Processing video folder: cthdnahrkh\n",
      "Processing image: output_frames/cthdnahrkh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cthdnahrkh\n",
      "Processing video folder: eqvuznuwsa\n",
      "Processing image: output_frames/eqvuznuwsa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eqvuznuwsa\n",
      "Processing video folder: aytzyidmgs\n",
      "Processing image: output_frames/aytzyidmgs/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aytzyidmgs\n",
      "Processing video folder: egbbcxcuqy\n",
      "Processing image: output_frames/egbbcxcuqy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for egbbcxcuqy\n",
      "Processing video folder: emfbhytfhc\n",
      "Processing image: output_frames/emfbhytfhc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for emfbhytfhc\n",
      "Processing video folder: amowujxmzc\n",
      "Processing image: output_frames/amowujxmzc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for amowujxmzc\n",
      "Processing video folder: ekcrtigpab\n",
      "Processing image: output_frames/ekcrtigpab/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ekcrtigpab\n",
      "Processing video folder: dhjmzhrcav\n",
      "Processing image: output_frames/dhjmzhrcav/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dhjmzhrcav\n",
      "Processing video folder: bqdjzqhcft\n",
      "Processing image: output_frames/bqdjzqhcft/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bqdjzqhcft\n",
      "Processing video folder: erlvuvjsjf\n",
      "Processing image: output_frames/erlvuvjsjf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for erlvuvjsjf\n",
      "Processing video folder: efwfxwwlbw\n",
      "Processing image: output_frames/efwfxwwlbw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for efwfxwwlbw\n",
      "Processing video folder: eggbjzxnmg\n",
      "Processing image: output_frames/eggbjzxnmg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eggbjzxnmg\n",
      "Processing video folder: asmpfjfzif\n",
      "Processing image: output_frames/asmpfjfzif/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for asmpfjfzif\n",
      "Processing video folder: btxlttbpkj\n",
      "Processing image: output_frames/btxlttbpkj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btxlttbpkj\n",
      "Processing video folder: ehtdtkmmli\n",
      "Processing image: output_frames/ehtdtkmmli/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ehtdtkmmli\n",
      "Processing video folder: arlmiizoob\n",
      "Processing image: output_frames/arlmiizoob/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for arlmiizoob\n",
      "Processing video folder: etejaapnxh\n",
      "Processing image: output_frames/etejaapnxh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for etejaapnxh\n",
      "Processing video folder: eekozbeafq\n",
      "Processing image: output_frames/eekozbeafq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eekozbeafq\n",
      "Processing video folder: apgjqzkoma\n",
      "Processing image: output_frames/apgjqzkoma/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for apgjqzkoma\n",
      "Processing video folder: epymyyiblu\n",
      "Processing image: output_frames/epymyyiblu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for epymyyiblu\n",
      "Processing video folder: adylbeequz\n",
      "Processing image: output_frames/adylbeequz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for adylbeequz\n",
      "Processing video folder: deyyistcrd\n",
      "Processing image: output_frames/deyyistcrd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for deyyistcrd\n",
      "Processing video folder: dlrsbscitn\n",
      "Processing image: output_frames/dlrsbscitn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dlrsbscitn\n",
      "Processing video folder: dxuliowugt\n",
      "Processing image: output_frames/dxuliowugt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dxuliowugt\n",
      "Processing video folder: cferslmfwh\n",
      "Processing image: output_frames/cferslmfwh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cferslmfwh\n",
      "Processing video folder: aapnvogymq\n",
      "Processing image: output_frames/aapnvogymq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aapnvogymq\n",
      "Processing video folder: efdyrflcpg\n",
      "Processing image: output_frames/efdyrflcpg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for efdyrflcpg\n",
      "Processing video folder: bwipwzzxxu\n",
      "Processing image: output_frames/bwipwzzxxu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bwipwzzxxu\n",
      "Processing video folder: drgjzlxzxj\n",
      "Processing image: output_frames/drgjzlxzxj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for drgjzlxzxj\n",
      "Processing video folder: aknmpoonls\n",
      "Processing image: output_frames/aknmpoonls/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aknmpoonls\n",
      "Processing video folder: dulanfulol\n",
      "Processing image: output_frames/dulanfulol/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dulanfulol\n",
      "Processing video folder: cobjrlugvp\n",
      "Processing image: output_frames/cobjrlugvp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cobjrlugvp\n",
      "Processing video folder: aknbdpmgua\n",
      "Processing image: output_frames/aknbdpmgua/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aknbdpmgua\n",
      "Processing video folder: bdnaqemxmr\n",
      "Processing image: output_frames/bdnaqemxmr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bdnaqemxmr\n",
      "Processing video folder: eukvucdetx\n",
      "Processing image: output_frames/eukvucdetx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eukvucdetx\n",
      "Processing video folder: awhmfnnjih\n",
      "Processing image: output_frames/awhmfnnjih/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for awhmfnnjih\n",
      "Processing video folder: duycddgtrl\n",
      "Processing image: output_frames/duycddgtrl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for duycddgtrl\n",
      "Processing video folder: duzuusuajr\n",
      "Processing image: output_frames/duzuusuajr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for duzuusuajr\n",
      "Processing video folder: bahdpoesir\n",
      "Processing image: output_frames/bahdpoesir/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bahdpoesir\n",
      "Processing video folder: etmcruaihe\n",
      "Processing image: output_frames/etmcruaihe/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for etmcruaihe\n",
      "Processing video folder: eajlrktemq\n",
      "Processing image: output_frames/eajlrktemq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eajlrktemq\n",
      "Processing video folder: bxzakyopjf\n",
      "Processing image: output_frames/bxzakyopjf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bxzakyopjf\n",
      "Processing video folder: blzydqdfem\n",
      "Processing image: output_frames/blzydqdfem/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for blzydqdfem\n",
      "Processing video folder: btohlidmru\n",
      "Processing image: output_frames/btohlidmru/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btohlidmru\n",
      "Processing video folder: aladcziidp\n",
      "Processing image: output_frames/aladcziidp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aladcziidp\n",
      "Processing video folder: czfunozvwp\n",
      "Processing image: output_frames/czfunozvwp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for czfunozvwp\n",
      "Processing video folder: axwovszumc\n",
      "Processing image: output_frames/axwovszumc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for axwovszumc\n",
      "Processing video folder: bweezhfpzp\n",
      "Processing image: output_frames/bweezhfpzp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bweezhfpzp\n",
      "Processing video folder: btjwbtsgln\n",
      "Processing image: output_frames/btjwbtsgln/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btjwbtsgln\n",
      "Processing video folder: aybumesmpk\n",
      "Processing image: output_frames/aybumesmpk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aybumesmpk\n",
      "Processing video folder: cdphtzqrvp\n",
      "Processing image: output_frames/cdphtzqrvp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cdphtzqrvp\n",
      "Processing video folder: elvvackpjh\n",
      "Processing image: output_frames/elvvackpjh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for elvvackpjh\n",
      "Processing video folder: bbvgxeczei\n",
      "Processing image: output_frames/bbvgxeczei/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bbvgxeczei\n",
      "Processing video folder: diopzaywor\n",
      "Processing image: output_frames/diopzaywor/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for diopzaywor\n",
      "Processing video folder: cttqtsjvgn\n",
      "Processing image: output_frames/cttqtsjvgn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cttqtsjvgn\n",
      "Processing video folder: beboztfcme\n",
      "Processing image: output_frames/beboztfcme/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for beboztfcme\n",
      "Processing video folder: cdbsbdymzd\n",
      "Processing image: output_frames/cdbsbdymzd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cdbsbdymzd\n",
      "Processing video folder: bdxuhamuqx\n",
      "Processing image: output_frames/bdxuhamuqx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bdxuhamuqx\n",
      "Processing video folder: dboxtiehng\n",
      "Processing image: output_frames/dboxtiehng/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dboxtiehng\n",
      "Processing video folder: ehieahnhte\n",
      "Processing image: output_frames/ehieahnhte/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ehieahnhte\n",
      "Processing video folder: ckkuyewywx\n",
      "Processing image: output_frames/ckkuyewywx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ckkuyewywx\n",
      "Processing video folder: cbbibzcoih\n",
      "Processing image: output_frames/cbbibzcoih/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cbbibzcoih\n",
      "Processing video folder: btjlfpzbdu\n",
      "Processing image: output_frames/btjlfpzbdu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btjlfpzbdu\n",
      "Processing video folder: acifjvzvpm\n",
      "Processing image: output_frames/acifjvzvpm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for acifjvzvpm\n",
      "Processing video folder: cfxkpiweqt\n",
      "Processing image: output_frames/cfxkpiweqt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cfxkpiweqt\n",
      "Processing video folder: cmxcfkrjiv\n",
      "Processing image: output_frames/cmxcfkrjiv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cmxcfkrjiv\n",
      "Processing video folder: bqhtpqmmqp\n",
      "Processing image: output_frames/bqhtpqmmqp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bqhtpqmmqp\n",
      "Processing video folder: apatcsqejh\n",
      "Processing image: output_frames/apatcsqejh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for apatcsqejh\n",
      "Processing video folder: dkhlttuvmx\n",
      "Processing image: output_frames/dkhlttuvmx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dkhlttuvmx\n",
      "Processing video folder: aipfdnwpoo\n",
      "Processing image: output_frames/aipfdnwpoo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aipfdnwpoo\n",
      "Processing video folder: btmsngnqhv\n",
      "Processing image: output_frames/btmsngnqhv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btmsngnqhv\n",
      "Processing video folder: brvqtabyxj\n",
      "Processing image: output_frames/brvqtabyxj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for brvqtabyxj\n",
      "Processing video folder: chzieimrwu\n",
      "Processing image: output_frames/chzieimrwu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for chzieimrwu\n",
      "Processing video folder: cizlkenljw\n",
      "Processing image: output_frames/cizlkenljw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cizlkenljw\n",
      "Processing video folder: dbnygxtwek\n",
      "Processing image: output_frames/dbnygxtwek/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dbnygxtwek\n",
      "Processing video folder: dsdoseflas\n",
      "Processing image: output_frames/dsdoseflas/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dsdoseflas\n",
      "Processing video folder: crktehraph\n",
      "Processing image: output_frames/crktehraph/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for crktehraph\n",
      "Processing video folder: ddjggcasdw\n",
      "Processing image: output_frames/ddjggcasdw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ddjggcasdw\n",
      "Processing video folder: emaalmsonj\n",
      "Processing image: output_frames/emaalmsonj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for emaalmsonj\n",
      "Processing video folder: eixwxvxbbn\n",
      "Processing image: output_frames/eixwxvxbbn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eixwxvxbbn\n",
      "Processing video folder: dkuayagnmc\n",
      "Processing image: output_frames/dkuayagnmc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dkuayagnmc\n",
      "Processing video folder: eckvhdusax\n",
      "Processing image: output_frames/eckvhdusax/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eckvhdusax\n",
      "Processing video folder: dkzvdrzcnr\n",
      "Processing image: output_frames/dkzvdrzcnr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dkzvdrzcnr\n",
      "Processing video folder: aklqzsddfl\n",
      "Processing image: output_frames/aklqzsddfl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aklqzsddfl\n",
      "Processing video folder: dsgpbgsrdm\n",
      "Processing image: output_frames/dsgpbgsrdm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dsgpbgsrdm\n",
      "Processing video folder: diuzrpqjli\n",
      "Processing image: output_frames/diuzrpqjli/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for diuzrpqjli\n",
      "Processing video folder: cknyxaqouy\n",
      "Processing image: output_frames/cknyxaqouy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cknyxaqouy\n",
      "Processing video folder: arkroixhey\n",
      "Processing image: output_frames/arkroixhey/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for arkroixhey\n",
      "Processing video folder: eeyhxisdfh\n",
      "Processing image: output_frames/eeyhxisdfh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eeyhxisdfh\n",
      "Processing video folder: dzvyfiarrq\n",
      "Processing image: output_frames/dzvyfiarrq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dzvyfiarrq\n",
      "Processing video folder: bsqgziaylx\n",
      "Processing image: output_frames/bsqgziaylx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bsqgziaylx\n",
      "Processing video folder: dbzcqmxzaj\n",
      "Processing image: output_frames/dbzcqmxzaj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dbzcqmxzaj\n",
      "Processing video folder: boovltmuwi\n",
      "Processing image: output_frames/boovltmuwi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for boovltmuwi\n",
      "Processing video folder: blpchvmhxx\n",
      "Processing image: output_frames/blpchvmhxx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for blpchvmhxx\n",
      "Processing video folder: bpxckdzddv\n",
      "Processing image: output_frames/bpxckdzddv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bpxckdzddv\n",
      "Processing video folder: bhaaboftbc\n",
      "Processing image: output_frames/bhaaboftbc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bhaaboftbc\n",
      "Processing video folder: dubiroskqn\n",
      "Processing image: output_frames/dubiroskqn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dubiroskqn\n",
      "Processing video folder: agdkmztvby\n",
      "Processing image: output_frames/agdkmztvby/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for agdkmztvby\n",
      "Processing video folder: cycacemkmt\n",
      "Processing image: output_frames/cycacemkmt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cycacemkmt\n",
      "Processing video folder: bdgipnyobr\n",
      "Processing image: output_frames/bdgipnyobr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bdgipnyobr\n",
      "Processing video folder: ejkqesyvam\n",
      "Processing image: output_frames/ejkqesyvam/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ejkqesyvam\n",
      "Processing video folder: errocgcham\n",
      "Processing image: output_frames/errocgcham/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for errocgcham\n",
      "Processing video folder: byfenovjnf\n",
      "Processing image: output_frames/byfenovjnf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for byfenovjnf\n",
      "Processing video folder: anpuvshzoo\n",
      "Processing image: output_frames/anpuvshzoo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for anpuvshzoo\n",
      "Processing video folder: btunxncpjh\n",
      "Processing image: output_frames/btunxncpjh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btunxncpjh\n",
      "Processing video folder: bqnymlsayl\n",
      "Processing image: output_frames/bqnymlsayl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bqnymlsayl\n",
      "Processing video folder: azsmewqghg\n",
      "Processing image: output_frames/azsmewqghg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for azsmewqghg\n",
      "Processing video folder: atvmxvwyns\n",
      "Processing image: output_frames/atvmxvwyns/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for atvmxvwyns\n",
      "Processing video folder: adhsbajydo\n",
      "Processing image: output_frames/adhsbajydo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for adhsbajydo\n",
      "Processing video folder: arrhsnjqku\n",
      "Processing image: output_frames/arrhsnjqku/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for arrhsnjqku\n",
      "Processing video folder: ddqccgmtka\n",
      "Processing image: output_frames/ddqccgmtka/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ddqccgmtka\n",
      "Processing video folder: elginszwtk\n",
      "Processing image: output_frames/elginszwtk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for elginszwtk\n",
      "Processing video folder: avibnnhwhp\n",
      "Processing image: output_frames/avibnnhwhp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for avibnnhwhp\n",
      "Processing video folder: bilnggbxgu\n",
      "Processing image: output_frames/bilnggbxgu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bilnggbxgu\n",
      "Processing video folder: eebserckhh\n",
      "Processing image: output_frames/eebserckhh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for eebserckhh\n",
      "Processing video folder: axczxisdtb\n",
      "Processing image: output_frames/axczxisdtb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for axczxisdtb\n",
      "Processing video folder: alninxcyhg\n",
      "Processing image: output_frames/alninxcyhg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for alninxcyhg\n",
      "Processing video folder: byunigvnay\n",
      "Processing image: output_frames/byunigvnay/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for byunigvnay\n",
      "Processing video folder: bnbuonyoje\n",
      "Processing image: output_frames/bnbuonyoje/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bnbuonyoje\n",
      "Processing video folder: bbhpvrmbse\n",
      "Processing image: output_frames/bbhpvrmbse/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bbhpvrmbse\n",
      "Processing video folder: ecuvtoltue\n",
      "Processing image: output_frames/ecuvtoltue/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ecuvtoltue\n",
      "Processing video folder: dtocdfbwca\n",
      "Processing image: output_frames/dtocdfbwca/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dtocdfbwca\n",
      "Processing video folder: dxbqjxrhin\n",
      "Processing image: output_frames/dxbqjxrhin/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dxbqjxrhin\n",
      "Processing video folder: amaivqofda\n",
      "Processing image: output_frames/amaivqofda/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for amaivqofda\n",
      "Processing video folder: bmhvktyiwp\n",
      "Processing image: output_frames/bmhvktyiwp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bmhvktyiwp\n",
      "Processing video folder: cwsbspfzck\n",
      "Processing image: output_frames/cwsbspfzck/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cwsbspfzck\n",
      "Processing video folder: clrycekyst\n",
      "Processing image: output_frames/clrycekyst/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for clrycekyst\n",
      "Processing video folder: ehbnclaukr\n",
      "Processing image: output_frames/ehbnclaukr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ehbnclaukr\n",
      "Processing video folder: akxoopqjqz\n",
      "Processing image: output_frames/akxoopqjqz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for akxoopqjqz\n",
      "Processing video folder: dnhvalzvrt\n",
      "Processing image: output_frames/dnhvalzvrt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dnhvalzvrt\n",
      "Processing video folder: atkdltyyen\n",
      "Processing image: output_frames/atkdltyyen/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for atkdltyyen\n",
      "Processing video folder: ckbdwedgmc\n",
      "Processing image: output_frames/ckbdwedgmc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ckbdwedgmc\n",
      "Processing video folder: aneclqfpbt\n",
      "Processing image: output_frames/aneclqfpbt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aneclqfpbt\n",
      "Processing video folder: cqhngvpgyi\n",
      "Processing image: output_frames/cqhngvpgyi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cqhngvpgyi\n",
      "Processing video folder: bddjdhzfze\n",
      "Processing image: output_frames/bddjdhzfze/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for bddjdhzfze\n",
      "Processing video folder: cvaksbpssm\n",
      "Processing image: output_frames/cvaksbpssm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cvaksbpssm\n",
      "Processing video folder: aufmsmnoye\n",
      "Processing image: output_frames/aufmsmnoye/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for aufmsmnoye\n",
      "Processing video folder: dbhoxkblzx\n",
      "Processing image: output_frames/dbhoxkblzx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dbhoxkblzx\n",
      "Processing video folder: ctpqeykqdp\n",
      "Processing image: output_frames/ctpqeykqdp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ctpqeykqdp\n",
      "Processing video folder: ellavthztb\n",
      "Processing image: output_frames/ellavthztb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for ellavthztb\n",
      "Processing video folder: duvyaxbzvp\n",
      "Processing image: output_frames/duvyaxbzvp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for duvyaxbzvp\n",
      "Processing video folder: cmbzllswnl\n",
      "Processing image: output_frames/cmbzllswnl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cmbzllswnl\n",
      "Processing video folder: cppdvdejkc\n",
      "Processing image: output_frames/cppdvdejkc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for cppdvdejkc\n",
      "Processing video folder: btiysiskpf\n",
      "Processing image: output_frames/btiysiskpf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for btiysiskpf\n",
      "Processing video folder: dgzklxjmix\n",
      "Processing image: output_frames/dgzklxjmix/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features shape: torch.Size([1, 512, 1, 1])\n",
      "Squeezed features shape: (512,)\n",
      "Features saved for dgzklxjmix\n",
      "Processing video folder: erqgqacbqe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 61\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;66;03m# Example usage\u001B[39;00m\n\u001B[1;32m     60\u001B[0m base_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_frames\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 61\u001B[0m \u001B[43mprocess_video_folders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_folder\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[28], line 49\u001B[0m, in \u001B[0;36mprocess_video_folders\u001B[0;34m(base_folder)\u001B[0m\n\u001B[1;32m     46\u001B[0m error_level_plot \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(video_folder_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124merror_level_plot.png\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(error_level_plot):\n\u001B[0;32m---> 49\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[43mextract_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43merror_level_plot\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m features \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m features\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     51\u001B[0m         features_output_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(video_folder_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeatures.npy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[28], line 21\u001B[0m, in \u001B[0;36mextract_features\u001B[0;34m(image_path)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract_features\u001B[39m(image_path):\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 21\u001B[0m         image \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_path\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mRGB\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m         image_tensor \u001B[38;5;241m=\u001B[39m transform(image)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     24\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProcessing image: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimage_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/PIL/Image.py:995\u001B[0m, in \u001B[0;36mImage.convert\u001B[0;34m(self, mode, matrix, dither, palette, colors)\u001B[0m\n\u001B[1;32m    992\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBGR;15\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBGR;16\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBGR;24\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    993\u001B[0m     deprecate(mode, \u001B[38;5;241m12\u001B[39m)\n\u001B[0;32m--> 995\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    997\u001B[0m has_transparency \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransparency\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\n\u001B[1;32m    998\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mode \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mP\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    999\u001B[0m     \u001B[38;5;66;03m# determine default mode\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/PIL/ImageFile.py:293\u001B[0m, in \u001B[0;36mImageFile.load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    290\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(msg)\n\u001B[1;32m    292\u001B[0m b \u001B[38;5;241m=\u001B[39m b \u001B[38;5;241m+\u001B[39m s\n\u001B[0;32m--> 293\u001B[0m n, err_code \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    295\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "14ce1cb75356295e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T06:41:17.881782Z",
     "start_time": "2024-10-11T06:41:17.626679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ORAGANIZED THE FEATURES.NPY OF EACH VIDEO ACCORDING TO THERE LABEL FROM METADATA.JSON FILE \n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "input_frames_dir = \"output_frames\"\n",
    "output_dir = \"organized_frames\"\n",
    "metadata_file = \"metadata.json\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(os.path.join(output_dir, \"REAL\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, \"FAKE\"), exist_ok=True)\n",
    "\n",
    "# Read metadata\n",
    "with open(metadata_file, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Process each video\n",
    "for video, info in metadata.items():\n",
    "    label = info[\"label\"]\n",
    "    video_name = os.path.splitext(video)[0]  # Remove the .mp4 extension\n",
    "\n",
    "    # Source and destination paths\n",
    "    src_path = os.path.join(input_frames_dir, video_name)\n",
    "    dst_path = os.path.join(output_dir, label, video_name)\n",
    "\n",
    "    # Check if the source directory exists\n",
    "    if os.path.exists(src_path):\n",
    "        # Copy the frame folder to the appropriate category\n",
    "        shutil.copytree(src_path, dst_path)\n",
    "        print(f\"Copied {video_name} to {label} category\")\n",
    "    else:\n",
    "        print(f\"Warning: Frame folder for {video_name} not found\")\n",
    "\n",
    "print(\"Organization complete!\")"
   ],
   "id": "ca821ed4376148ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied aagfhgtpmv to FAKE category\n",
      "Copied aapnvogymq to FAKE category\n",
      "Copied abarnvbtwb to REAL category\n",
      "Copied abofeumbvv to FAKE category\n",
      "Copied abqwwspghj to FAKE category\n",
      "Copied acifjvzvpm to FAKE category\n",
      "Copied acqfdwsrhi to FAKE category\n",
      "Copied acxnxvbsxk to FAKE category\n",
      "Copied acxwigylke to FAKE category\n",
      "Copied aczrgyricp to FAKE category\n",
      "Copied adhsbajydo to FAKE category\n",
      "Copied adohikbdaz to FAKE category\n",
      "Copied adylbeequz to FAKE category\n",
      "Copied aelfnikyqj to REAL category\n",
      "Copied aelzhcnwgf to FAKE category\n",
      "Copied aettqgevhz to FAKE category\n",
      "Copied aevrfsexku to FAKE category\n",
      "Copied afoovlsmtx to REAL category\n",
      "Copied agdkmztvby to FAKE category\n",
      "Copied agqphdxmwt to FAKE category\n",
      "Copied agrmhtjdlk to REAL category\n",
      "Copied ahbweevwpv to FAKE category\n",
      "Copied ahdbuwqxit to FAKE category\n",
      "Copied ahfazfbntc to FAKE category\n",
      "Copied ahqqqilsxt to REAL category\n",
      "Copied aipfdnwpoo to FAKE category\n",
      "Copied ajqslcypsw to REAL category\n",
      "Copied ajwpjhrbcv to FAKE category\n",
      "Copied aklqzsddfl to FAKE category\n",
      "Copied aknbdpmgua to FAKE category\n",
      "Copied aknmpoonls to FAKE category\n",
      "Copied akvmwkdyuv to FAKE category\n",
      "Copied akxoopqjqz to FAKE category\n",
      "Copied akzbnazxtz to FAKE category\n",
      "Copied aladcziidp to FAKE category\n",
      "Copied alaijyygdv to FAKE category\n",
      "Copied alninxcyhg to FAKE category\n",
      "Copied altziddtxi to FAKE category\n",
      "Copied alvgwypubw to FAKE category\n",
      "Copied amaivqofda to FAKE category\n",
      "Copied amowujxmzc to FAKE category\n",
      "Copied andaxzscny to FAKE category\n",
      "Copied aneclqfpbt to FAKE category\n",
      "Copied anpuvshzoo to REAL category\n",
      "Copied aorjvbyxhw to FAKE category\n",
      "Copied apatcsqejh to FAKE category\n",
      "Copied apgjqzkoma to FAKE category\n",
      "Copied apogckdfrz to FAKE category\n",
      "Copied aqpnvjhuzw to FAKE category\n",
      "Copied arkroixhey to FAKE category\n",
      "Copied arlmiizoob to FAKE category\n",
      "Copied arrhsnjqku to FAKE category\n",
      "Copied asaxgevnnp to REAL category\n",
      "Copied asdpeebotb to FAKE category\n",
      "Copied aslsvlvpth to FAKE category\n",
      "Copied asmpfjfzif to FAKE category\n",
      "Copied asvcrfdpnq to FAKE category\n",
      "Copied atkdltyyen to REAL category\n",
      "Copied atvmxvwyns to REAL category\n",
      "Copied atxvxouljq to FAKE category\n",
      "Copied atyntldecu to FAKE category\n",
      "Copied atzdznmder to FAKE category\n",
      "Copied aufmsmnoye to FAKE category\n",
      "Copied augtsuxpzc to FAKE category\n",
      "Copied avfitoutyn to FAKE category\n",
      "Copied avgiuextiz to FAKE category\n",
      "Copied avibnnhwhp to FAKE category\n",
      "Copied avmjormvsx to REAL category\n",
      "Copied avnqydkqjj to FAKE category\n",
      "Copied avssvvsdhz to FAKE category\n",
      "Copied avtycwsgyb to FAKE category\n",
      "Copied avvdgsennp to FAKE category\n",
      "Copied avywawptfc to FAKE category\n",
      "Copied awhmfnnjih to FAKE category\n",
      "Copied awnwkrqibf to FAKE category\n",
      "Copied awukslzjra to FAKE category\n",
      "Copied axczxisdtb to FAKE category\n",
      "Copied axntxmycwd to REAL category\n",
      "Copied axoygtekut to FAKE category\n",
      "Copied axwgcsyphv to FAKE category\n",
      "Copied axwovszumc to FAKE category\n",
      "Copied aybgughjxh to REAL category\n",
      "Copied aybumesmpk to REAL category\n",
      "Copied ayqvfdhslr to FAKE category\n",
      "Copied aytzyidmgs to REAL category\n",
      "Copied azpuxunqyo to FAKE category\n",
      "Copied azsmewqghg to FAKE category\n",
      "Copied bahdpoesir to FAKE category\n",
      "Copied bbhpvrmbse to FAKE category\n",
      "Copied bbhtdfuqxq to FAKE category\n",
      "Copied bbvgxeczei to FAKE category\n",
      "Copied bchnbulevv to FAKE category\n",
      "Copied bctvsmddgq to FAKE category\n",
      "Copied bdbhekrrwo to FAKE category\n",
      "Copied bddjdhzfze to REAL category\n",
      "Copied bdgipnyobr to FAKE category\n",
      "Copied bdnaqemxmr to REAL category\n",
      "Copied bdxuhamuqx to FAKE category\n",
      "Copied beboztfcme to REAL category\n",
      "Copied bejhvclboh to REAL category\n",
      "Copied benmsfzfaz to FAKE category\n",
      "Copied beyebyhrph to REAL category\n",
      "Copied bffwsjxghk to REAL category\n",
      "Copied bgaogsjehq to FAKE category\n",
      "Copied bggsurpgpr to FAKE category\n",
      "Copied bghphrsfxf to FAKE category\n",
      "Copied bgmlwsoamc to FAKE category\n",
      "Copied bguwlyazau to FAKE category\n",
      "Copied bgvhtpzknn to REAL category\n",
      "Copied bgwmmujlmc to REAL category\n",
      "Copied bhaaboftbc to FAKE category\n",
      "Copied bhbdugnurr to FAKE category\n",
      "Copied bhpwpydzpo to FAKE category\n",
      "Copied bhsluedavd to FAKE category\n",
      "Copied bilnggbxgu to REAL category\n",
      "Copied bjjbwsqjir to FAKE category\n",
      "Copied bjkmjilrxp to FAKE category\n",
      "Copied bjsmaqefoi to FAKE category\n",
      "Copied bkmdzhfzfh to FAKE category\n",
      "Copied bkvetcojbt to FAKE category\n",
      "Copied bkwxhglwct to FAKE category\n",
      "Copied blpchvmhxx to FAKE category\n",
      "Copied blzydqdfem to FAKE category\n",
      "Copied bmbbkwmxqj to FAKE category\n",
      "Copied bmehkyanbj to FAKE category\n",
      "Copied bmhvktyiwp to FAKE category\n",
      "Copied bmioepcpsx to FAKE category\n",
      "Copied bmjmjmbglm to FAKE category\n",
      "Copied bmjzrlszhi to REAL category\n",
      "Copied bnbuonyoje to FAKE category\n",
      "Copied bndybcqhfr to FAKE category\n",
      "Copied bnjcdrfuov to FAKE category\n",
      "Copied bntlodcfeg to FAKE category\n",
      "Copied bofqajtwve to FAKE category\n",
      "Copied boovltmuwi to FAKE category\n",
      "Copied bopqhhalml to FAKE category\n",
      "Copied bourlmzsio to FAKE category\n",
      "Copied bpapbctoao to REAL category\n",
      "Copied bpwzipqtxf to FAKE category\n",
      "Copied bpxckdzddv to FAKE category\n",
      "Copied bqdjzqhcft to FAKE category\n",
      "Copied bqeiblbxtl to FAKE category\n",
      "Copied bqhtpqmmqp to FAKE category\n",
      "Copied bqkdbcqjvb to FAKE category\n",
      "Copied bqnymlsayl to FAKE category\n",
      "Copied bqqpbzjgup to FAKE category\n",
      "Copied bqtuuwzdtr to FAKE category\n",
      "Copied brhalypwoo to FAKE category\n",
      "Copied brvqtabyxj to FAKE category\n",
      "Copied brwrlczjvi to REAL category\n",
      "Copied bseamdrpbj to FAKE category\n",
      "Copied bsfmwclnqy to FAKE category\n",
      "Copied bsqgziaylx to FAKE category\n",
      "Copied btiysiskpf to FAKE category\n",
      "Copied btjlfpzbdu to FAKE category\n",
      "Copied btjwbtsgln to FAKE category\n",
      "Copied btmsngnqhv to FAKE category\n",
      "Copied btohlidmru to FAKE category\n",
      "Copied btugrnoton to FAKE category\n",
      "Copied btunxncpjh to FAKE category\n",
      "Copied btxlttbpkj to FAKE category\n",
      "Copied bulkxhhknf to REAL category\n",
      "Copied bvgwelbeof to FAKE category\n",
      "Copied bvzjkezkms to FAKE category\n",
      "Copied bweezhfpzp to FAKE category\n",
      "Copied bwhlgysghg to REAL category\n",
      "Copied bwipwzzxxu to REAL category\n",
      "Copied bwuwstvsbw to FAKE category\n",
      "Copied bxzakyopjf to REAL category\n",
      "Copied bydaidkpdp to FAKE category\n",
      "Copied byfenovjnf to FAKE category\n",
      "Copied byijojkdba to FAKE category\n",
      "Copied byofowlkki to FAKE category\n",
      "Copied byqzyxifza to FAKE category\n",
      "Copied byunigvnay to FAKE category\n",
      "Copied byyqectxqa to FAKE category\n",
      "Copied bzmdrafeex to FAKE category\n",
      "Copied bzythlfnhq to REAL category\n",
      "Copied caifxvsozs to REAL category\n",
      "Copied caqbrkogkb to FAKE category\n",
      "Copied cbbibzcoih to FAKE category\n",
      "Copied cbltdtxglo to FAKE category\n",
      "Copied ccfoszqabv to REAL category\n",
      "Copied ccmonzqfrz to FAKE category\n",
      "Copied cdaxixbosp to FAKE category\n",
      "Copied cdbsbdymzd to FAKE category\n",
      "Copied cdphtzqrvp to FAKE category\n",
      "Copied cdyakrxkia to FAKE category\n",
      "Copied cepxysienc to FAKE category\n",
      "Copied cettndmvzl to FAKE category\n",
      "Copied ceymbecxnj to FAKE category\n",
      "Copied cferslmfwh to FAKE category\n",
      "Copied cffffbcywc to FAKE category\n",
      "Copied cfxkpiweqt to REAL category\n",
      "Copied cfyduhpbps to FAKE category\n",
      "Copied cglxirfaey to FAKE category\n",
      "Copied cgvrgibpfo to FAKE category\n",
      "Copied chtapglbcj to REAL category\n",
      "Copied chviwxsfhg to REAL category\n",
      "Copied chzieimrwu to FAKE category\n",
      "Copied ciyoudyhly to REAL category\n",
      "Copied cizlkenljw to REAL category\n",
      "Copied ckbdwedgmc to FAKE category\n",
      "Copied ckjaibzfxa to REAL category\n",
      "Copied ckkuyewywx to REAL category\n",
      "Copied cknyxaqouy to FAKE category\n",
      "Copied cksanfsjhc to FAKE category\n",
      "Copied clihsshdkq to FAKE category\n",
      "Copied clrycekyst to REAL category\n",
      "Copied cmbzllswnl to REAL category\n",
      "Copied cmxcfkrjiv to FAKE category\n",
      "Copied cnilkgvfei to FAKE category\n",
      "Copied coadfnerlk to FAKE category\n",
      "Copied cobjrlugvp to REAL category\n",
      "Copied covdcysmbi to FAKE category\n",
      "Copied cpjxareypw to REAL category\n",
      "Copied cppdvdejkc to REAL category\n",
      "Copied cprhtltsjp to REAL category\n",
      "Copied cqfugiqupm to FAKE category\n",
      "Copied cqhngvpgyi to FAKE category\n",
      "Copied cqrskwiqng to FAKE category\n",
      "Copied crezycjqyk to REAL category\n",
      "Copied crktehraph to FAKE category\n",
      "Copied crzfebnfgb to FAKE category\n",
      "Copied cthdnahrkh to FAKE category\n",
      "Copied ctpqeykqdp to FAKE category\n",
      "Copied cttqtsjvgn to FAKE category\n",
      "Copied ctzmavwror to FAKE category\n",
      "Copied curpwogllm to FAKE category\n",
      "Copied cuzrgrbvil to FAKE category\n",
      "Copied cvaksbpssm to FAKE category\n",
      "Copied cwbacdwrzo to FAKE category\n",
      "Copied cwqlvzefpg to FAKE category\n",
      "Copied cwrtyzndpx to FAKE category\n",
      "Copied cwsbspfzck to FAKE category\n",
      "Copied cwwandrkus to FAKE category\n",
      "Copied cxfujlvsuw to FAKE category\n",
      "Copied cxrfacemmq to FAKE category\n",
      "Copied cxttmymlbn to FAKE category\n",
      "Copied cyboodqqyr to FAKE category\n",
      "Copied cycacemkmt to FAKE category\n",
      "Copied cyclgfjdrv to FAKE category\n",
      "Copied cyxlcuyznd to REAL category\n",
      "Copied czfunozvwp to FAKE category\n",
      "Copied czkdanyadc to FAKE category\n",
      "Copied czmqpxrqoh to FAKE category\n",
      "Copied dafhtipaml to FAKE category\n",
      "Copied dakiztgtnw to REAL category\n",
      "Copied dakqwktlbi to FAKE category\n",
      "Copied dbhoxkblzx to FAKE category\n",
      "Copied dbhrpizyeq to FAKE category\n",
      "Copied dbnygxtwek to REAL category\n",
      "Copied dboxtiehng to FAKE category\n",
      "Copied dbtbbhakdv to REAL category\n",
      "Copied dbzcqmxzaj to FAKE category\n",
      "Copied dbzpcjntve to FAKE category\n",
      "Copied dcamvmuors to FAKE category\n",
      "Copied dcuiiorugd to FAKE category\n",
      "Copied ddepeddixj to REAL category\n",
      "Copied ddhfabwpuz to FAKE category\n",
      "Copied ddjggcasdw to FAKE category\n",
      "Copied ddpvuimigj to FAKE category\n",
      "Copied ddqccgmtka to FAKE category\n",
      "Copied degpbqvcay to FAKE category\n",
      "Copied deywhkarol to FAKE category\n",
      "Copied deyyistcrd to FAKE category\n",
      "Copied dfbpceeaox to FAKE category\n",
      "Copied dgmevclvzy to FAKE category\n",
      "Copied dgxrqjdomn to FAKE category\n",
      "Copied dgzklxjmix to FAKE category\n",
      "Copied dhcndnuwta to REAL category\n",
      "Copied dhcselezer to FAKE category\n",
      "Copied dhevettufk to FAKE category\n",
      "Copied dhjmzhrcav to FAKE category\n",
      "Copied dhkwmjxwrn to FAKE category\n",
      "Copied dhoqofwoxa to FAKE category\n",
      "Copied dhxctgyoqj to REAL category\n",
      "Copied diomeixhrg to FAKE category\n",
      "Copied diopzaywor to FAKE category\n",
      "Copied diqraixiov to FAKE category\n",
      "Copied diuzrpqjli to FAKE category\n",
      "Copied djvtbgwdcc to FAKE category\n",
      "Copied djvutyvaio to FAKE category\n",
      "Copied djxdyjopjd to REAL category\n",
      "Copied dkdwxmtpuo to FAKE category\n",
      "Copied dkhlttuvmx to FAKE category\n",
      "Copied dkrvorliqc to FAKE category\n",
      "Copied dkuayagnmc to REAL category\n",
      "Copied dkwjwbwgey to FAKE category\n",
      "Copied dkzvdrzcnr to REAL category\n",
      "Copied dlpoieqvfb to REAL category\n",
      "Copied dlrsbscitn to FAKE category\n",
      "Copied dnexlwbcxq to FAKE category\n",
      "Copied dnhvalzvrt to FAKE category\n",
      "Copied dntkzzzcdh to FAKE category\n",
      "Copied dnyvfblxpm to FAKE category\n",
      "Copied doanjploai to FAKE category\n",
      "Copied dofusvhnib to FAKE category\n",
      "Copied dozyddhild to FAKE category\n",
      "Copied dptbnjnkdg to FAKE category\n",
      "Copied dptrzdvwpg to FAKE category\n",
      "Copied dqnyszdong to FAKE category\n",
      "Copied dqppxmoqdl to FAKE category\n",
      "Copied dqqtjcryjv to FAKE category\n",
      "Copied dqswpjoepo to FAKE category\n",
      "Copied dqzreruvje to FAKE category\n",
      "Copied drcyabprvt to REAL category\n",
      "Copied drgjzlxzxj to FAKE category\n",
      "Copied drsakwyvqv to FAKE category\n",
      "Copied drtbksnpol to FAKE category\n",
      "Copied dsdoseflas to FAKE category\n",
      "Copied dsgpbgsrdm to FAKE category\n",
      "Copied dsjbknkujw to REAL category\n",
      "Copied dsndhujjjb to FAKE category\n",
      "Copied dtbpmdqvao to FAKE category\n",
      "Copied dtocdfbwca to FAKE category\n",
      "Copied dubiroskqn to FAKE category\n",
      "Copied dulanfulol to FAKE category\n",
      "Copied duvyaxbzvp to FAKE category\n",
      "Copied duycddgtrl to REAL category\n",
      "Copied duzuusuajr to FAKE category\n",
      "Copied dvakowbgbt to FAKE category\n",
      "Copied dvumqqhoac to FAKE category\n",
      "Copied dwediigjit to FAKE category\n",
      "Copied dxbqjxrhin to REAL category\n",
      "Copied dxuliowugt to FAKE category\n",
      "Copied dxuplhwvig to FAKE category\n",
      "Copied dzieklokdr to FAKE category\n",
      "Copied dzqwgqewhu to FAKE category\n",
      "Copied dzvyfiarrq to FAKE category\n",
      "Copied dzwkmcwkwl to FAKE category\n",
      "Copied dzyuwjkjui to REAL category\n",
      "Copied eahlqmfvtj to FAKE category\n",
      "Copied eajlrktemq to FAKE category\n",
      "Copied ebchwmwayp to FAKE category\n",
      "Copied ebebgmtlcu to FAKE category\n",
      "Copied ebeknhudxq to FAKE category\n",
      "Copied ebkzwjgjhq to FAKE category\n",
      "Copied ebywfrmhtd to FAKE category\n",
      "Copied eckvhdusax to REAL category\n",
      "Copied ecnihjlfyt to FAKE category\n",
      "Copied ecujsjhscd to REAL category\n",
      "Copied ecuvtoltue to FAKE category\n",
      "Copied ecwaxgutkc to FAKE category\n",
      "Copied eczrseixwq to FAKE category\n",
      "Copied edyncaijwx to REAL category\n",
      "Copied eebrkicpry to FAKE category\n",
      "Copied eebserckhh to FAKE category\n",
      "Copied eejswgycjc to FAKE category\n",
      "Copied eekozbeafq to FAKE category\n",
      "Copied eepezmygaq to FAKE category\n",
      "Copied eeyhxisdfh to FAKE category\n",
      "Copied efdyrflcpg to FAKE category\n",
      "Copied efwfxwwlbw to REAL category\n",
      "Copied egbbcxcuqy to FAKE category\n",
      "Copied eggbjzxnmg to REAL category\n",
      "Copied egghxjjmfg to REAL category\n",
      "Copied ehbnclaukr to FAKE category\n",
      "Copied ehccixxzoe to REAL category\n",
      "Copied ehdkmxgtxh to FAKE category\n",
      "Copied ehevsxtecd to FAKE category\n",
      "Copied ehfiekigla to FAKE category\n",
      "Copied ehieahnhte to FAKE category\n",
      "Copied ehtdtkmmli to REAL category\n",
      "Copied eiriyukqqy to FAKE category\n",
      "Copied eivxffliio to FAKE category\n",
      "Copied eiwopxzjfn to FAKE category\n",
      "Copied eixwxvxbbn to FAKE category\n",
      "Copied ejkqesyvam to FAKE category\n",
      "Copied ekcrtigpab to REAL category\n",
      "Copied ekhacizpah to FAKE category\n",
      "Copied ekkdjkirzq to FAKE category\n",
      "Copied elginszwtk to FAKE category\n",
      "Copied ellavthztb to REAL category\n",
      "Copied elvvackpjh to FAKE category\n",
      "Copied emaalmsonj to FAKE category\n",
      "Copied emfbhytfhc to FAKE category\n",
      "Copied emgjphonqb to FAKE category\n",
      "Copied ensyyivobf to FAKE category\n",
      "Copied eoewqcpbgt to FAKE category\n",
      "Copied eprybmbpba to FAKE category\n",
      "Copied epymyyiblu to FAKE category\n",
      "Copied eqjscdagiv to FAKE category\n",
      "Copied eqnoqyfquo to REAL category\n",
      "Copied eqvuznuwsa to FAKE category\n",
      "Copied erlvuvjsjf to REAL category\n",
      "Copied erqgqacbqe to FAKE category\n",
      "Copied errocgcham to FAKE category\n",
      "Copied esckbnkkvb to FAKE category\n",
      "Copied esgftaficx to FAKE category\n",
      "Copied esnntzzajv to FAKE category\n",
      "Copied esxrvsgpvb to FAKE category\n",
      "Copied esyhwdfnxs to FAKE category\n",
      "Copied esyrimvzsa to FAKE category\n",
      "Copied etdcqxabww to FAKE category\n",
      "Copied etejaapnxh to FAKE category\n",
      "Copied etmcruaihe to FAKE category\n",
      "Copied etohcvnzbj to FAKE category\n",
      "Copied eudeqjhdfd to REAL category\n",
      "Copied eukvucdetx to FAKE category\n",
      "Organization complete!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T06:52:39.116176Z",
     "start_time": "2024-10-11T06:52:38.885546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DID CLASSIFICATION USING SVM AND KNN\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames\"\n",
    "categories = [\"FAKE\", \"REAL\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM Model\n",
    "print(\"Training SVM model...\")\n",
    "svm_model = SVC(kernel='sigmoid')  # You can experiment with different kernels like 'rbf'\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# KNN Model\n",
    "print(\"Training KNN model...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=4)  # You can adjust the number of neighbors\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate KNN\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(f\"KNN Accuracy: {accuracy_score(y_test, y_pred_knn):.2f}\")"
   ],
   "id": "79234608713308b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FAKE videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:00<00:00, 5803.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing REAL videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 5472.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM model...\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        64\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.40      0.50      0.44        80\n",
      "weighted avg       0.64      0.80      0.71        80\n",
      "\n",
      "SVM Accuracy: 0.80\n",
      "Training KNN model...\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89        64\n",
      "           1       0.67      0.12      0.21        16\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.74      0.55      0.55        80\n",
      "weighted avg       0.79      0.81      0.76        80\n",
      "\n",
      "KNN Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T08:17:06.724781Z",
     "start_time": "2024-10-11T08:16:47.985105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# USE PRETRAINED MODEL INCEPTIONV3 TO EXTRACT FEATURE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Load the Inception model\n",
    "inception_model = models.inception_v3(pretrained=True)\n",
    "\n",
    "# Switch the model to evaluation mode\n",
    "inception_model.eval()\n",
    "\n",
    "# Define the transformation for Inception\n",
    "inception_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to load and process an image for Inception\n",
    "def process_image_inception(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img = inception_transform(img)\n",
    "        img = img.unsqueeze(0)  # Add batch dimension\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract features using Inception\n",
    "def extract_features_inception(image_tensor):\n",
    "    try:\n",
    "        if image_tensor is not None and len(image_tensor.shape) == 4:\n",
    "            with torch.no_grad():\n",
    "                features = inception_model(image_tensor)\n",
    "                return features\n",
    "        else:\n",
    "            print(f\"Error: Invalid input tensor size {image_tensor.shape if image_tensor is not None else None}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image tensor: {e}\")\n",
    "    return None\n",
    "\n",
    "# Directory where the images are stored\n",
    "input_directory = \"output_frames_inception\"\n",
    "\n",
    "# Iterate through each video folder\n",
    "for video_folder in os.listdir(input_directory):\n",
    "    folder_path = os.path.join(input_directory, video_folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(f\"Processing video folder: {video_folder}\")\n",
    "\n",
    "        for img_file in os.listdir(folder_path):\n",
    "            if img_file.endswith('.png'):\n",
    "                img_path = os.path.join(folder_path, img_file)\n",
    "                print(f\"Processing image: {img_path}\")\n",
    "\n",
    "                # Load and transform image for Inception\n",
    "                image_tensor = process_image_inception(img_path)\n",
    "\n",
    "                # Check the shape of the tensor\n",
    "                if image_tensor is not None:\n",
    "                    print(f\"Image tensor shape: {image_tensor.shape}\")\n",
    "\n",
    "                # Extract features using Inception\n",
    "                features = extract_features_inception(image_tensor)\n",
    "                if features is not None:\n",
    "                    print(f\"Extracted features for {img_file}\")\n",
    "                else:\n",
    "                    print(f\"No features were extracted for {img_file}\")\n"
   ],
   "id": "b700462ea573b90b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video folder: ahqqqilsxt\n",
      "Processing image: output_frames_inception/ahqqqilsxt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: djvtbgwdcc\n",
      "Processing image: output_frames_inception/djvtbgwdcc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: atzdznmder\n",
      "Processing image: output_frames_inception/atzdznmder/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: esyrimvzsa\n",
      "Processing image: output_frames_inception/esyrimvzsa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dptrzdvwpg\n",
      "Processing image: output_frames_inception/dptrzdvwpg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bjkmjilrxp\n",
      "Processing image: output_frames_inception/bjkmjilrxp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dbhrpizyeq\n",
      "Processing image: output_frames_inception/dbhrpizyeq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cffffbcywc\n",
      "Processing image: output_frames_inception/cffffbcywc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: caifxvsozs\n",
      "Processing image: output_frames_inception/caifxvsozs/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dzqwgqewhu\n",
      "Processing image: output_frames_inception/dzqwgqewhu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bpwzipqtxf\n",
      "Processing image: output_frames_inception/bpwzipqtxf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dbzpcjntve\n",
      "Processing image: output_frames_inception/dbzpcjntve/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: chviwxsfhg\n",
      "Processing image: output_frames_inception/chviwxsfhg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aettqgevhz\n",
      "Processing image: output_frames_inception/aettqgevhz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ekkdjkirzq\n",
      "Processing image: output_frames_inception/ekkdjkirzq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: esckbnkkvb\n",
      "Processing image: output_frames_inception/esckbnkkvb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: coadfnerlk\n",
      "Processing image: output_frames_inception/coadfnerlk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: diqraixiov\n",
      "Processing image: output_frames_inception/diqraixiov/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ddepeddixj\n",
      "Processing image: output_frames_inception/ddepeddixj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cxfujlvsuw\n",
      "Processing image: output_frames_inception/cxfujlvsuw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: diomeixhrg\n",
      "Processing image: output_frames_inception/diomeixhrg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bffwsjxghk\n",
      "Processing image: output_frames_inception/bffwsjxghk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bvgwelbeof\n",
      "Processing image: output_frames_inception/bvgwelbeof/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ebchwmwayp\n",
      "Processing image: output_frames_inception/ebchwmwayp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: brhalypwoo\n",
      "Processing image: output_frames_inception/brhalypwoo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: alvgwypubw\n",
      "Processing image: output_frames_inception/alvgwypubw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bsfmwclnqy\n",
      "Processing image: output_frames_inception/bsfmwclnqy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: deywhkarol\n",
      "Processing image: output_frames_inception/deywhkarol/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dakqwktlbi\n",
      "Processing image: output_frames_inception/dakqwktlbi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bwhlgysghg\n",
      "Processing image: output_frames_inception/bwhlgysghg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cyboodqqyr\n",
      "Processing image: output_frames_inception/cyboodqqyr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bmbbkwmxqj\n",
      "Processing image: output_frames_inception/bmbbkwmxqj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: acxnxvbsxk\n",
      "Processing image: output_frames_inception/acxnxvbsxk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eivxffliio\n",
      "Processing image: output_frames_inception/eivxffliio/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: djvutyvaio\n",
      "Processing image: output_frames_inception/djvutyvaio/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eudeqjhdfd\n",
      "Processing image: output_frames_inception/eudeqjhdfd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ecwaxgutkc\n",
      "Processing image: output_frames_inception/ecwaxgutkc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dcuiiorugd\n",
      "Processing image: output_frames_inception/dcuiiorugd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cwwandrkus\n",
      "Processing image: output_frames_inception/cwwandrkus/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avmjormvsx\n",
      "Processing image: output_frames_inception/avmjormvsx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ciyoudyhly\n",
      "Processing image: output_frames_inception/ciyoudyhly/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bggsurpgpr\n",
      "Processing image: output_frames_inception/bggsurpgpr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avnqydkqjj\n",
      "Processing image: output_frames_inception/avnqydkqjj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: edyncaijwx\n",
      "Processing image: output_frames_inception/edyncaijwx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: drsakwyvqv\n",
      "Processing image: output_frames_inception/drsakwyvqv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: benmsfzfaz\n",
      "Processing image: output_frames_inception/benmsfzfaz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ckjaibzfxa\n",
      "Processing image: output_frames_inception/ckjaibzfxa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eqnoqyfquo\n",
      "Processing image: output_frames_inception/eqnoqyfquo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ddpvuimigj\n",
      "Processing image: output_frames_inception/ddpvuimigj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bctvsmddgq\n",
      "Processing image: output_frames_inception/bctvsmddgq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dvakowbgbt\n",
      "Processing image: output_frames_inception/dvakowbgbt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ahfazfbntc\n",
      "Processing image: output_frames_inception/ahfazfbntc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ekhacizpah\n",
      "Processing image: output_frames_inception/ekhacizpah/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bwuwstvsbw\n",
      "Processing image: output_frames_inception/bwuwstvsbw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: abqwwspghj\n",
      "Processing image: output_frames_inception/abqwwspghj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bhpwpydzpo\n",
      "Processing image: output_frames_inception/bhpwpydzpo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dsndhujjjb\n",
      "Processing image: output_frames_inception/dsndhujjjb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cdyakrxkia\n",
      "Processing image: output_frames_inception/cdyakrxkia/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bpapbctoao\n",
      "Processing image: output_frames_inception/bpapbctoao/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bnjcdrfuov\n",
      "Processing image: output_frames_inception/bnjcdrfuov/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dgxrqjdomn\n",
      "Processing image: output_frames_inception/dgxrqjdomn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: axwgcsyphv\n",
      "Processing image: output_frames_inception/axwgcsyphv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dtbpmdqvao\n",
      "Processing image: output_frames_inception/dtbpmdqvao/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dntkzzzcdh\n",
      "Processing image: output_frames_inception/dntkzzzcdh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ayqvfdhslr\n",
      "Processing image: output_frames_inception/ayqvfdhslr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehfiekigla\n",
      "Processing image: output_frames_inception/ehfiekigla/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: byyqectxqa\n",
      "Processing image: output_frames_inception/byyqectxqa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: drcyabprvt\n",
      "Processing image: output_frames_inception/drcyabprvt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dsjbknkujw\n",
      "Processing image: output_frames_inception/dsjbknkujw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avywawptfc\n",
      "Processing image: output_frames_inception/avywawptfc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avssvvsdhz\n",
      "Processing image: output_frames_inception/avssvvsdhz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aybgughjxh\n",
      "Processing image: output_frames_inception/aybgughjxh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: egghxjjmfg\n",
      "Processing image: output_frames_inception/egghxjjmfg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: curpwogllm\n",
      "Processing image: output_frames_inception/curpwogllm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cbltdtxglo\n",
      "Processing image: output_frames_inception/cbltdtxglo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhcndnuwta\n",
      "Processing image: output_frames_inception/dhcndnuwta/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dvumqqhoac\n",
      "Processing image: output_frames_inception/dvumqqhoac/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dqzreruvje\n",
      "Processing image: output_frames_inception/dqzreruvje/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bdbhekrrwo\n",
      "Processing image: output_frames_inception/bdbhekrrwo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: awukslzjra\n",
      "Processing image: output_frames_inception/awukslzjra/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: czkdanyadc\n",
      "Processing image: output_frames_inception/czkdanyadc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aslsvlvpth\n",
      "Processing image: output_frames_inception/aslsvlvpth/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dozyddhild\n",
      "Processing image: output_frames_inception/dozyddhild/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dqnyszdong\n",
      "Processing image: output_frames_inception/dqnyszdong/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqkdbcqjvb\n",
      "Processing image: output_frames_inception/bqkdbcqjvb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bvzjkezkms\n",
      "Processing image: output_frames_inception/bvzjkezkms/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ensyyivobf\n",
      "Processing image: output_frames_inception/ensyyivobf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cuzrgrbvil\n",
      "Processing image: output_frames_inception/cuzrgrbvil/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dzyuwjkjui\n",
      "Processing image: output_frames_inception/dzyuwjkjui/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dafhtipaml\n",
      "Processing image: output_frames_inception/dafhtipaml/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dqswpjoepo\n",
      "Processing image: output_frames_inception/dqswpjoepo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: etdcqxabww\n",
      "Processing image: output_frames_inception/etdcqxabww/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bgwmmujlmc\n",
      "Processing image: output_frames_inception/bgwmmujlmc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: esyhwdfnxs\n",
      "Processing image: output_frames_inception/esyhwdfnxs/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bndybcqhfr\n",
      "Processing image: output_frames_inception/bndybcqhfr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cnilkgvfei\n",
      "Processing image: output_frames_inception/cnilkgvfei/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: djxdyjopjd\n",
      "Processing image: output_frames_inception/djxdyjopjd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dkwjwbwgey\n",
      "Processing image: output_frames_inception/dkwjwbwgey/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dqqtjcryjv\n",
      "Processing image: output_frames_inception/dqqtjcryjv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eepezmygaq\n",
      "Processing image: output_frames_inception/eepezmygaq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bkvetcojbt\n",
      "Processing image: output_frames_inception/bkvetcojbt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cyxlcuyznd\n",
      "Processing image: output_frames_inception/cyxlcuyznd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bseamdrpbj\n",
      "Processing image: output_frames_inception/bseamdrpbj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bchnbulevv\n",
      "Processing image: output_frames_inception/bchnbulevv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cqrskwiqng\n",
      "Processing image: output_frames_inception/cqrskwiqng/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: atyntldecu\n",
      "Processing image: output_frames_inception/atyntldecu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cthdnahrkh\n",
      "Processing image: output_frames_inception/cthdnahrkh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eqvuznuwsa\n",
      "Processing image: output_frames_inception/eqvuznuwsa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aytzyidmgs\n",
      "Processing image: output_frames_inception/aytzyidmgs/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: egbbcxcuqy\n",
      "Processing image: output_frames_inception/egbbcxcuqy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: emfbhytfhc\n",
      "Processing image: output_frames_inception/emfbhytfhc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: amowujxmzc\n",
      "Processing image: output_frames_inception/amowujxmzc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ekcrtigpab\n",
      "Processing image: output_frames_inception/ekcrtigpab/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhjmzhrcav\n",
      "Processing image: output_frames_inception/dhjmzhrcav/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqdjzqhcft\n",
      "Processing image: output_frames_inception/bqdjzqhcft/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: erlvuvjsjf\n",
      "Processing image: output_frames_inception/erlvuvjsjf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: efwfxwwlbw\n",
      "Processing image: output_frames_inception/efwfxwwlbw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eggbjzxnmg\n",
      "Processing image: output_frames_inception/eggbjzxnmg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: asmpfjfzif\n",
      "Processing image: output_frames_inception/asmpfjfzif/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btxlttbpkj\n",
      "Processing image: output_frames_inception/btxlttbpkj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehtdtkmmli\n",
      "Processing image: output_frames_inception/ehtdtkmmli/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: arlmiizoob\n",
      "Processing image: output_frames_inception/arlmiizoob/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: etejaapnxh\n",
      "Processing image: output_frames_inception/etejaapnxh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eekozbeafq\n",
      "Processing image: output_frames_inception/eekozbeafq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: apgjqzkoma\n",
      "Processing image: output_frames_inception/apgjqzkoma/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: epymyyiblu\n",
      "Processing image: output_frames_inception/epymyyiblu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: adylbeequz\n",
      "Processing image: output_frames_inception/adylbeequz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: deyyistcrd\n",
      "Processing image: output_frames_inception/deyyistcrd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dlrsbscitn\n",
      "Processing image: output_frames_inception/dlrsbscitn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dxuliowugt\n",
      "Processing image: output_frames_inception/dxuliowugt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cferslmfwh\n",
      "Processing image: output_frames_inception/cferslmfwh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aapnvogymq\n",
      "Processing image: output_frames_inception/aapnvogymq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: efdyrflcpg\n",
      "Processing image: output_frames_inception/efdyrflcpg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bwipwzzxxu\n",
      "Processing image: output_frames_inception/bwipwzzxxu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: drgjzlxzxj\n",
      "Processing image: output_frames_inception/drgjzlxzxj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aknmpoonls\n",
      "Processing image: output_frames_inception/aknmpoonls/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dulanfulol\n",
      "Processing image: output_frames_inception/dulanfulol/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cobjrlugvp\n",
      "Processing image: output_frames_inception/cobjrlugvp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aknbdpmgua\n",
      "Processing image: output_frames_inception/aknbdpmgua/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bdnaqemxmr\n",
      "Processing image: output_frames_inception/bdnaqemxmr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eukvucdetx\n",
      "Processing image: output_frames_inception/eukvucdetx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: awhmfnnjih\n",
      "Processing image: output_frames_inception/awhmfnnjih/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: duycddgtrl\n",
      "Processing image: output_frames_inception/duycddgtrl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: duzuusuajr\n",
      "Processing image: output_frames_inception/duzuusuajr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bahdpoesir\n",
      "Processing image: output_frames_inception/bahdpoesir/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: etmcruaihe\n",
      "Processing image: output_frames_inception/etmcruaihe/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eajlrktemq\n",
      "Processing image: output_frames_inception/eajlrktemq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bxzakyopjf\n",
      "Processing image: output_frames_inception/bxzakyopjf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: blzydqdfem\n",
      "Processing image: output_frames_inception/blzydqdfem/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btohlidmru\n",
      "Processing image: output_frames_inception/btohlidmru/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aladcziidp\n",
      "Processing image: output_frames_inception/aladcziidp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: czfunozvwp\n",
      "Processing image: output_frames_inception/czfunozvwp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: axwovszumc\n",
      "Processing image: output_frames_inception/axwovszumc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bweezhfpzp\n",
      "Processing image: output_frames_inception/bweezhfpzp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btjwbtsgln\n",
      "Processing image: output_frames_inception/btjwbtsgln/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aybumesmpk\n",
      "Processing image: output_frames_inception/aybumesmpk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cdphtzqrvp\n",
      "Processing image: output_frames_inception/cdphtzqrvp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: elvvackpjh\n",
      "Processing image: output_frames_inception/elvvackpjh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bbvgxeczei\n",
      "Processing image: output_frames_inception/bbvgxeczei/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: diopzaywor\n",
      "Processing image: output_frames_inception/diopzaywor/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cttqtsjvgn\n",
      "Processing image: output_frames_inception/cttqtsjvgn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: beboztfcme\n",
      "Processing image: output_frames_inception/beboztfcme/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cdbsbdymzd\n",
      "Processing image: output_frames_inception/cdbsbdymzd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bdxuhamuqx\n",
      "Processing image: output_frames_inception/bdxuhamuqx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dboxtiehng\n",
      "Processing image: output_frames_inception/dboxtiehng/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehieahnhte\n",
      "Processing image: output_frames_inception/ehieahnhte/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ckkuyewywx\n",
      "Processing image: output_frames_inception/ckkuyewywx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cbbibzcoih\n",
      "Processing image: output_frames_inception/cbbibzcoih/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btjlfpzbdu\n",
      "Processing image: output_frames_inception/btjlfpzbdu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: acifjvzvpm\n",
      "Processing image: output_frames_inception/acifjvzvpm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cfxkpiweqt\n",
      "Processing image: output_frames_inception/cfxkpiweqt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cmxcfkrjiv\n",
      "Processing image: output_frames_inception/cmxcfkrjiv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqhtpqmmqp\n",
      "Processing image: output_frames_inception/bqhtpqmmqp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: apatcsqejh\n",
      "Processing image: output_frames_inception/apatcsqejh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dkhlttuvmx\n",
      "Processing image: output_frames_inception/dkhlttuvmx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aipfdnwpoo\n",
      "Processing image: output_frames_inception/aipfdnwpoo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btmsngnqhv\n",
      "Processing image: output_frames_inception/btmsngnqhv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: brvqtabyxj\n",
      "Processing image: output_frames_inception/brvqtabyxj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: chzieimrwu\n",
      "Processing image: output_frames_inception/chzieimrwu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cizlkenljw\n",
      "Processing image: output_frames_inception/cizlkenljw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dbnygxtwek\n",
      "Processing image: output_frames_inception/dbnygxtwek/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dsdoseflas\n",
      "Processing image: output_frames_inception/dsdoseflas/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: crktehraph\n",
      "Processing image: output_frames_inception/crktehraph/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ddjggcasdw\n",
      "Processing image: output_frames_inception/ddjggcasdw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: emaalmsonj\n",
      "Processing image: output_frames_inception/emaalmsonj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eixwxvxbbn\n",
      "Processing image: output_frames_inception/eixwxvxbbn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dkuayagnmc\n",
      "Processing image: output_frames_inception/dkuayagnmc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eckvhdusax\n",
      "Processing image: output_frames_inception/eckvhdusax/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dkzvdrzcnr\n",
      "Processing image: output_frames_inception/dkzvdrzcnr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aklqzsddfl\n",
      "Processing image: output_frames_inception/aklqzsddfl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dsgpbgsrdm\n",
      "Processing image: output_frames_inception/dsgpbgsrdm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: diuzrpqjli\n",
      "Processing image: output_frames_inception/diuzrpqjli/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cknyxaqouy\n",
      "Processing image: output_frames_inception/cknyxaqouy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: arkroixhey\n",
      "Processing image: output_frames_inception/arkroixhey/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eeyhxisdfh\n",
      "Processing image: output_frames_inception/eeyhxisdfh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dzvyfiarrq\n",
      "Processing image: output_frames_inception/dzvyfiarrq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bsqgziaylx\n",
      "Processing image: output_frames_inception/bsqgziaylx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dbzcqmxzaj\n",
      "Processing image: output_frames_inception/dbzcqmxzaj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: boovltmuwi\n",
      "Processing image: output_frames_inception/boovltmuwi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: blpchvmhxx\n",
      "Processing image: output_frames_inception/blpchvmhxx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bpxckdzddv\n",
      "Processing image: output_frames_inception/bpxckdzddv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bhaaboftbc\n",
      "Processing image: output_frames_inception/bhaaboftbc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dubiroskqn\n",
      "Processing image: output_frames_inception/dubiroskqn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: agdkmztvby\n",
      "Processing image: output_frames_inception/agdkmztvby/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cycacemkmt\n",
      "Processing image: output_frames_inception/cycacemkmt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bdgipnyobr\n",
      "Processing image: output_frames_inception/bdgipnyobr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ejkqesyvam\n",
      "Processing image: output_frames_inception/ejkqesyvam/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: errocgcham\n",
      "Processing image: output_frames_inception/errocgcham/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: byfenovjnf\n",
      "Processing image: output_frames_inception/byfenovjnf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: anpuvshzoo\n",
      "Processing image: output_frames_inception/anpuvshzoo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btunxncpjh\n",
      "Processing image: output_frames_inception/btunxncpjh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqnymlsayl\n",
      "Processing image: output_frames_inception/bqnymlsayl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: azsmewqghg\n",
      "Processing image: output_frames_inception/azsmewqghg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: atvmxvwyns\n",
      "Processing image: output_frames_inception/atvmxvwyns/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: adhsbajydo\n",
      "Processing image: output_frames_inception/adhsbajydo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: arrhsnjqku\n",
      "Processing image: output_frames_inception/arrhsnjqku/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ddqccgmtka\n",
      "Processing image: output_frames_inception/ddqccgmtka/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: elginszwtk\n",
      "Processing image: output_frames_inception/elginszwtk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avibnnhwhp\n",
      "Processing image: output_frames_inception/avibnnhwhp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bilnggbxgu\n",
      "Processing image: output_frames_inception/bilnggbxgu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eebserckhh\n",
      "Processing image: output_frames_inception/eebserckhh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: axczxisdtb\n",
      "Processing image: output_frames_inception/axczxisdtb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: alninxcyhg\n",
      "Processing image: output_frames_inception/alninxcyhg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: byunigvnay\n",
      "Processing image: output_frames_inception/byunigvnay/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bnbuonyoje\n",
      "Processing image: output_frames_inception/bnbuonyoje/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bbhpvrmbse\n",
      "Processing image: output_frames_inception/bbhpvrmbse/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ecuvtoltue\n",
      "Processing image: output_frames_inception/ecuvtoltue/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dtocdfbwca\n",
      "Processing image: output_frames_inception/dtocdfbwca/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dxbqjxrhin\n",
      "Processing image: output_frames_inception/dxbqjxrhin/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: amaivqofda\n",
      "Processing image: output_frames_inception/amaivqofda/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bmhvktyiwp\n",
      "Processing image: output_frames_inception/bmhvktyiwp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cwsbspfzck\n",
      "Processing image: output_frames_inception/cwsbspfzck/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: clrycekyst\n",
      "Processing image: output_frames_inception/clrycekyst/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehbnclaukr\n",
      "Processing image: output_frames_inception/ehbnclaukr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: akxoopqjqz\n",
      "Processing image: output_frames_inception/akxoopqjqz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dnhvalzvrt\n",
      "Processing image: output_frames_inception/dnhvalzvrt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: atkdltyyen\n",
      "Processing image: output_frames_inception/atkdltyyen/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ckbdwedgmc\n",
      "Processing image: output_frames_inception/ckbdwedgmc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aneclqfpbt\n",
      "Processing image: output_frames_inception/aneclqfpbt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cqhngvpgyi\n",
      "Processing image: output_frames_inception/cqhngvpgyi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bddjdhzfze\n",
      "Processing image: output_frames_inception/bddjdhzfze/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cvaksbpssm\n",
      "Processing image: output_frames_inception/cvaksbpssm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aufmsmnoye\n",
      "Processing image: output_frames_inception/aufmsmnoye/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dbhoxkblzx\n",
      "Processing image: output_frames_inception/dbhoxkblzx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ctpqeykqdp\n",
      "Processing image: output_frames_inception/ctpqeykqdp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ellavthztb\n",
      "Processing image: output_frames_inception/ellavthztb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: duvyaxbzvp\n",
      "Processing image: output_frames_inception/duvyaxbzvp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cmbzllswnl\n",
      "Processing image: output_frames_inception/cmbzllswnl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cppdvdejkc\n",
      "Processing image: output_frames_inception/cppdvdejkc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btiysiskpf\n",
      "Processing image: output_frames_inception/btiysiskpf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dgzklxjmix\n",
      "Processing image: output_frames_inception/dgzklxjmix/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: erqgqacbqe\n",
      "Processing image: output_frames_inception/erqgqacbqe/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dkdwxmtpuo\n",
      "Processing image: output_frames_inception/dkdwxmtpuo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bhsluedavd\n",
      "Processing image: output_frames_inception/bhsluedavd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: brwrlczjvi\n",
      "Processing image: output_frames_inception/brwrlczjvi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: asaxgevnnp\n",
      "Processing image: output_frames_inception/asaxgevnnp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: caqbrkogkb\n",
      "Processing image: output_frames_inception/caqbrkogkb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dofusvhnib\n",
      "Processing image: output_frames_inception/dofusvhnib/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ahbweevwpv\n",
      "Processing image: output_frames_inception/ahbweevwpv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bmehkyanbj\n",
      "Processing image: output_frames_inception/bmehkyanbj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: byofowlkki\n",
      "Processing image: output_frames_inception/byofowlkki/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dxuplhwvig\n",
      "Processing image: output_frames_inception/dxuplhwvig/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avfitoutyn\n",
      "Processing image: output_frames_inception/avfitoutyn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eoewqcpbgt\n",
      "Processing image: output_frames_inception/eoewqcpbgt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avgiuextiz\n",
      "Processing image: output_frames_inception/avgiuextiz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aagfhgtpmv\n",
      "Processing image: output_frames_inception/aagfhgtpmv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: axoygtekut\n",
      "Processing image: output_frames_inception/axoygtekut/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eqjscdagiv\n",
      "Processing image: output_frames_inception/eqjscdagiv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ajwpjhrbcv\n",
      "Processing image: output_frames_inception/ajwpjhrbcv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bmjmjmbglm\n",
      "Processing image: output_frames_inception/bmjmjmbglm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: crzfebnfgb\n",
      "Processing image: output_frames_inception/crzfebnfgb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehdkmxgtxh\n",
      "Processing image: output_frames_inception/ehdkmxgtxh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: czmqpxrqoh\n",
      "Processing image: output_frames_inception/czmqpxrqoh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ecnihjlfyt\n",
      "Processing image: output_frames_inception/ecnihjlfyt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ceymbecxnj\n",
      "Processing image: output_frames_inception/ceymbecxnj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bjsmaqefoi\n",
      "Processing image: output_frames_inception/bjsmaqefoi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: andaxzscny\n",
      "Processing image: output_frames_inception/andaxzscny/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bghphrsfxf\n",
      "Processing image: output_frames_inception/bghphrsfxf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: esgftaficx\n",
      "Processing image: output_frames_inception/esgftaficx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aorjvbyxhw\n",
      "Processing image: output_frames_inception/aorjvbyxhw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: emgjphonqb\n",
      "Processing image: output_frames_inception/emgjphonqb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cksanfsjhc\n",
      "Processing image: output_frames_inception/cksanfsjhc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cwqlvzefpg\n",
      "Processing image: output_frames_inception/cwqlvzefpg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: afoovlsmtx\n",
      "Processing image: output_frames_inception/afoovlsmtx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ajqslcypsw\n",
      "Processing image: output_frames_inception/ajqslcypsw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btugrnoton\n",
      "Processing image: output_frames_inception/btugrnoton/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: abofeumbvv\n",
      "Processing image: output_frames_inception/abofeumbvv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: agqphdxmwt\n",
      "Processing image: output_frames_inception/agqphdxmwt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ebywfrmhtd\n",
      "Processing image: output_frames_inception/ebywfrmhtd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cfyduhpbps\n",
      "Processing image: output_frames_inception/cfyduhpbps/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bgaogsjehq\n",
      "Processing image: output_frames_inception/bgaogsjehq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bhbdugnurr\n",
      "Processing image: output_frames_inception/bhbdugnurr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: altziddtxi\n",
      "Processing image: output_frames_inception/altziddtxi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: agrmhtjdlk\n",
      "Processing image: output_frames_inception/agrmhtjdlk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bkmdzhfzfh\n",
      "Processing image: output_frames_inception/bkmdzhfzfh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: esxrvsgpvb\n",
      "Processing image: output_frames_inception/esxrvsgpvb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bopqhhalml\n",
      "Processing image: output_frames_inception/bopqhhalml/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ccfoszqabv\n",
      "Processing image: output_frames_inception/ccfoszqabv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dgmevclvzy\n",
      "Processing image: output_frames_inception/dgmevclvzy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dzieklokdr\n",
      "Processing image: output_frames_inception/dzieklokdr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cyclgfjdrv\n",
      "Processing image: output_frames_inception/cyclgfjdrv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ecujsjhscd\n",
      "Processing image: output_frames_inception/ecujsjhscd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dbtbbhakdv\n",
      "Processing image: output_frames_inception/dbtbbhakdv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: apogckdfrz\n",
      "Processing image: output_frames_inception/apogckdfrz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eiriyukqqy\n",
      "Processing image: output_frames_inception/eiriyukqqy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eejswgycjc\n",
      "Processing image: output_frames_inception/eejswgycjc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bejhvclboh\n",
      "Processing image: output_frames_inception/bejhvclboh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cxrfacemmq\n",
      "Processing image: output_frames_inception/cxrfacemmq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cdaxixbosp\n",
      "Processing image: output_frames_inception/cdaxixbosp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bmioepcpsx\n",
      "Processing image: output_frames_inception/bmioepcpsx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: acqfdwsrhi\n",
      "Processing image: output_frames_inception/acqfdwsrhi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ebkzwjgjhq\n",
      "Processing image: output_frames_inception/ebkzwjgjhq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bgvhtpzknn\n",
      "Processing image: output_frames_inception/bgvhtpzknn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avvdgsennp\n",
      "Processing image: output_frames_inception/avvdgsennp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dnyvfblxpm\n",
      "Processing image: output_frames_inception/dnyvfblxpm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cpjxareypw\n",
      "Processing image: output_frames_inception/cpjxareypw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dptbnjnkdg\n",
      "Processing image: output_frames_inception/dptbnjnkdg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: asvcrfdpnq\n",
      "Processing image: output_frames_inception/asvcrfdpnq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: alaijyygdv\n",
      "Processing image: output_frames_inception/alaijyygdv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhoqofwoxa\n",
      "Processing image: output_frames_inception/dhoqofwoxa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bguwlyazau\n",
      "Processing image: output_frames_inception/bguwlyazau/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cxttmymlbn\n",
      "Processing image: output_frames_inception/cxttmymlbn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eiwopxzjfn\n",
      "Processing image: output_frames_inception/eiwopxzjfn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eprybmbpba\n",
      "Processing image: output_frames_inception/eprybmbpba/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: doanjploai\n",
      "Processing image: output_frames_inception/doanjploai/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cgvrgibpfo\n",
      "Processing image: output_frames_inception/cgvrgibpfo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dnexlwbcxq\n",
      "Processing image: output_frames_inception/dnexlwbcxq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehevsxtecd\n",
      "Processing image: output_frames_inception/ehevsxtecd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: byijojkdba\n",
      "Processing image: output_frames_inception/byijojkdba/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: chtapglbcj\n",
      "Processing image: output_frames_inception/chtapglbcj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bbhtdfuqxq\n",
      "Processing image: output_frames_inception/bbhtdfuqxq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: covdcysmbi\n",
      "Processing image: output_frames_inception/covdcysmbi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ahdbuwqxit\n",
      "Processing image: output_frames_inception/ahdbuwqxit/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bzmdrafeex\n",
      "Processing image: output_frames_inception/bzmdrafeex/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eebrkicpry\n",
      "Processing image: output_frames_inception/eebrkicpry/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bourlmzsio\n",
      "Processing image: output_frames_inception/bourlmzsio/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cettndmvzl\n",
      "Processing image: output_frames_inception/cettndmvzl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: akvmwkdyuv\n",
      "Processing image: output_frames_inception/akvmwkdyuv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bydaidkpdp\n",
      "Processing image: output_frames_inception/bydaidkpdp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhcselezer\n",
      "Processing image: output_frames_inception/dhcselezer/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bmjzrlszhi\n",
      "Processing image: output_frames_inception/bmjzrlszhi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aevrfsexku\n",
      "Processing image: output_frames_inception/aevrfsexku/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: augtsuxpzc\n",
      "Processing image: output_frames_inception/augtsuxpzc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cwrtyzndpx\n",
      "Processing image: output_frames_inception/cwrtyzndpx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: akzbnazxtz\n",
      "Processing image: output_frames_inception/akzbnazxtz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dqppxmoqdl\n",
      "Processing image: output_frames_inception/dqppxmoqdl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avtycwsgyb\n",
      "Processing image: output_frames_inception/avtycwsgyb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: axntxmycwd\n",
      "Processing image: output_frames_inception/axntxmycwd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bofqajtwve\n",
      "Processing image: output_frames_inception/bofqajtwve/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ebebgmtlcu\n",
      "Processing image: output_frames_inception/ebebgmtlcu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eahlqmfvtj\n",
      "Processing image: output_frames_inception/eahlqmfvtj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cepxysienc\n",
      "Processing image: output_frames_inception/cepxysienc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aqpnvjhuzw\n",
      "Processing image: output_frames_inception/aqpnvjhuzw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ebeknhudxq\n",
      "Processing image: output_frames_inception/ebeknhudxq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dzwkmcwkwl\n",
      "Processing image: output_frames_inception/dzwkmcwkwl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cglxirfaey\n",
      "Processing image: output_frames_inception/cglxirfaey/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: abarnvbtwb\n",
      "Processing image: output_frames_inception/abarnvbtwb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: atxvxouljq\n",
      "Processing image: output_frames_inception/atxvxouljq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: esnntzzajv\n",
      "Processing image: output_frames_inception/esnntzzajv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bgmlwsoamc\n",
      "Processing image: output_frames_inception/bgmlwsoamc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: acxwigylke\n",
      "Processing image: output_frames_inception/acxwigylke/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eczrseixwq\n",
      "Processing image: output_frames_inception/eczrseixwq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bjjbwsqjir\n",
      "Processing image: output_frames_inception/bjjbwsqjir/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dcamvmuors\n",
      "Processing image: output_frames_inception/dcamvmuors/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhkwmjxwrn\n",
      "Processing image: output_frames_inception/dhkwmjxwrn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bkwxhglwct\n",
      "Processing image: output_frames_inception/bkwxhglwct/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: awnwkrqibf\n",
      "Processing image: output_frames_inception/awnwkrqibf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ccmonzqfrz\n",
      "Processing image: output_frames_inception/ccmonzqfrz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: crezycjqyk\n",
      "Processing image: output_frames_inception/crezycjqyk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aelfnikyqj\n",
      "Processing image: output_frames_inception/aelfnikyqj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: drtbksnpol\n",
      "Processing image: output_frames_inception/drtbksnpol/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: degpbqvcay\n",
      "Processing image: output_frames_inception/degpbqvcay/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dwediigjit\n",
      "Processing image: output_frames_inception/dwediigjit/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ddhfabwpuz\n",
      "Processing image: output_frames_inception/ddhfabwpuz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cwbacdwrzo\n",
      "Processing image: output_frames_inception/cwbacdwrzo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dlpoieqvfb\n",
      "Processing image: output_frames_inception/dlpoieqvfb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aczrgyricp\n",
      "Processing image: output_frames_inception/aczrgyricp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: clihsshdkq\n",
      "Processing image: output_frames_inception/clihsshdkq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: byqzyxifza\n",
      "Processing image: output_frames_inception/byqzyxifza/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehccixxzoe\n",
      "Processing image: output_frames_inception/ehccixxzoe/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqtuuwzdtr\n",
      "Processing image: output_frames_inception/bqtuuwzdtr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: asdpeebotb\n",
      "Processing image: output_frames_inception/asdpeebotb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: beyebyhrph\n",
      "Processing image: output_frames_inception/beyebyhrph/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bntlodcfeg\n",
      "Processing image: output_frames_inception/bntlodcfeg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: azpuxunqyo\n",
      "Processing image: output_frames_inception/azpuxunqyo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bzythlfnhq\n",
      "Processing image: output_frames_inception/bzythlfnhq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqqpbzjgup\n",
      "Processing image: output_frames_inception/bqqpbzjgup/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aelzhcnwgf\n",
      "Processing image: output_frames_inception/aelzhcnwgf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cprhtltsjp\n",
      "Processing image: output_frames_inception/cprhtltsjp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dkrvorliqc\n",
      "Processing image: output_frames_inception/dkrvorliqc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhevettufk\n",
      "Processing image: output_frames_inception/dhevettufk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ctzmavwror\n",
      "Processing image: output_frames_inception/ctzmavwror/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqeiblbxtl\n",
      "Processing image: output_frames_inception/bqeiblbxtl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: etohcvnzbj\n",
      "Processing image: output_frames_inception/etohcvnzbj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhxctgyoqj\n",
      "Processing image: output_frames_inception/dhxctgyoqj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bulkxhhknf\n",
      "Processing image: output_frames_inception/bulkxhhknf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dakiztgtnw\n",
      "Processing image: output_frames_inception/dakiztgtnw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: adohikbdaz\n",
      "Processing image: output_frames_inception/adohikbdaz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cqfugiqupm\n",
      "Processing image: output_frames_inception/cqfugiqupm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dfbpceeaox\n",
      "Processing image: output_frames_inception/dfbpceeaox/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 299, 299])\n",
      "Extracted features for error_level_plot.png\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T08:18:52.740407Z",
     "start_time": "2024-10-11T08:18:44.674846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Load the SqueezeNet model\n",
    "squeezenet_model = models.squeezenet1_1(pretrained=True)\n",
    "\n",
    "# Switch the model to evaluation mode\n",
    "squeezenet_model.eval()\n",
    "\n",
    "# Define the transformation for SqueezeNet\n",
    "squeezenet_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to load and process an image for SqueezeNet\n",
    "def process_image_squeezenet(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img = squeezenet_transform(img)\n",
    "        img = img.unsqueeze(0)  # Add batch dimension\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract features using SqueezeNet\n",
    "def extract_features_squeezenet(image_tensor):\n",
    "    try:\n",
    "        if image_tensor is not None and len(image_tensor.shape) == 4:\n",
    "            with torch.no_grad():\n",
    "                features = squeezenet_model(image_tensor)\n",
    "                return features\n",
    "        else:\n",
    "            print(f\"Error: Invalid input tensor size {image_tensor.shape if image_tensor is not None else None}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image tensor: {e}\")\n",
    "    return None\n",
    "\n",
    "# Directory where the images are stored\n",
    "input_directory = \"output_frames_squeezenet\"\n",
    "\n",
    "# Iterate through each video folder\n",
    "for video_folder in os.listdir(input_directory):\n",
    "    folder_path = os.path.join(input_directory, video_folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(f\"Processing video folder: {video_folder}\")\n",
    "\n",
    "        for img_file in os.listdir(folder_path):\n",
    "            if img_file.endswith('.png'):\n",
    "                img_path = os.path.join(folder_path, img_file)\n",
    "                print(f\"Processing image: {img_path}\")\n",
    "\n",
    "                # Load and transform image for SqueezeNet\n",
    "                image_tensor = process_image_squeezenet(img_path)\n",
    "\n",
    "                # Check the shape of the tensor\n",
    "                if image_tensor is not None:\n",
    "                    print(f\"Image tensor shape: {image_tensor.shape}\")\n",
    "\n",
    "                # Extract features using SqueezeNet\n",
    "                features = extract_features_squeezenet(image_tensor)\n",
    "                if features is not None:\n",
    "                    print(f\"Extracted features for {img_file}\")\n",
    "                else:\n",
    "                    print(f\"No features were extracted for {img_file}\")\n"
   ],
   "id": "7dc6c525bf2b9368",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-b8a52dc0.pth\" to /Users/aniketsaxena/.cache/torch/hub/checkpoints/squeezenet1_1-b8a52dc0.pth\n",
      "100%|██████████| 4.73M/4.73M [00:02<00:00, 2.41MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video folder: ahqqqilsxt\n",
      "Processing image: output_frames_squeezenet/ahqqqilsxt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: djvtbgwdcc\n",
      "Processing image: output_frames_squeezenet/djvtbgwdcc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: atzdznmder\n",
      "Processing image: output_frames_squeezenet/atzdznmder/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: esyrimvzsa\n",
      "Processing image: output_frames_squeezenet/esyrimvzsa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dptrzdvwpg\n",
      "Processing image: output_frames_squeezenet/dptrzdvwpg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bjkmjilrxp\n",
      "Processing image: output_frames_squeezenet/bjkmjilrxp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dbhrpizyeq\n",
      "Processing image: output_frames_squeezenet/dbhrpizyeq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cffffbcywc\n",
      "Processing image: output_frames_squeezenet/cffffbcywc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: caifxvsozs\n",
      "Processing image: output_frames_squeezenet/caifxvsozs/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dzqwgqewhu\n",
      "Processing image: output_frames_squeezenet/dzqwgqewhu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bpwzipqtxf\n",
      "Processing image: output_frames_squeezenet/bpwzipqtxf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dbzpcjntve\n",
      "Processing image: output_frames_squeezenet/dbzpcjntve/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: chviwxsfhg\n",
      "Processing image: output_frames_squeezenet/chviwxsfhg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aettqgevhz\n",
      "Processing image: output_frames_squeezenet/aettqgevhz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ekkdjkirzq\n",
      "Processing image: output_frames_squeezenet/ekkdjkirzq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: esckbnkkvb\n",
      "Processing image: output_frames_squeezenet/esckbnkkvb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: coadfnerlk\n",
      "Processing image: output_frames_squeezenet/coadfnerlk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: diqraixiov\n",
      "Processing image: output_frames_squeezenet/diqraixiov/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ddepeddixj\n",
      "Processing image: output_frames_squeezenet/ddepeddixj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cxfujlvsuw\n",
      "Processing image: output_frames_squeezenet/cxfujlvsuw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: diomeixhrg\n",
      "Processing image: output_frames_squeezenet/diomeixhrg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bffwsjxghk\n",
      "Processing image: output_frames_squeezenet/bffwsjxghk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bvgwelbeof\n",
      "Processing image: output_frames_squeezenet/bvgwelbeof/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ebchwmwayp\n",
      "Processing image: output_frames_squeezenet/ebchwmwayp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: brhalypwoo\n",
      "Processing image: output_frames_squeezenet/brhalypwoo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: alvgwypubw\n",
      "Processing image: output_frames_squeezenet/alvgwypubw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bsfmwclnqy\n",
      "Processing image: output_frames_squeezenet/bsfmwclnqy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: deywhkarol\n",
      "Processing image: output_frames_squeezenet/deywhkarol/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dakqwktlbi\n",
      "Processing image: output_frames_squeezenet/dakqwktlbi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bwhlgysghg\n",
      "Processing image: output_frames_squeezenet/bwhlgysghg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cyboodqqyr\n",
      "Processing image: output_frames_squeezenet/cyboodqqyr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bmbbkwmxqj\n",
      "Processing image: output_frames_squeezenet/bmbbkwmxqj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: acxnxvbsxk\n",
      "Processing image: output_frames_squeezenet/acxnxvbsxk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eivxffliio\n",
      "Processing image: output_frames_squeezenet/eivxffliio/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: djvutyvaio\n",
      "Processing image: output_frames_squeezenet/djvutyvaio/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eudeqjhdfd\n",
      "Processing image: output_frames_squeezenet/eudeqjhdfd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ecwaxgutkc\n",
      "Processing image: output_frames_squeezenet/ecwaxgutkc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dcuiiorugd\n",
      "Processing image: output_frames_squeezenet/dcuiiorugd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cwwandrkus\n",
      "Processing image: output_frames_squeezenet/cwwandrkus/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avmjormvsx\n",
      "Processing image: output_frames_squeezenet/avmjormvsx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ciyoudyhly\n",
      "Processing image: output_frames_squeezenet/ciyoudyhly/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bggsurpgpr\n",
      "Processing image: output_frames_squeezenet/bggsurpgpr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avnqydkqjj\n",
      "Processing image: output_frames_squeezenet/avnqydkqjj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: edyncaijwx\n",
      "Processing image: output_frames_squeezenet/edyncaijwx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: drsakwyvqv\n",
      "Processing image: output_frames_squeezenet/drsakwyvqv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: benmsfzfaz\n",
      "Processing image: output_frames_squeezenet/benmsfzfaz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ckjaibzfxa\n",
      "Processing image: output_frames_squeezenet/ckjaibzfxa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eqnoqyfquo\n",
      "Processing image: output_frames_squeezenet/eqnoqyfquo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ddpvuimigj\n",
      "Processing image: output_frames_squeezenet/ddpvuimigj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bctvsmddgq\n",
      "Processing image: output_frames_squeezenet/bctvsmddgq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dvakowbgbt\n",
      "Processing image: output_frames_squeezenet/dvakowbgbt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ahfazfbntc\n",
      "Processing image: output_frames_squeezenet/ahfazfbntc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ekhacizpah\n",
      "Processing image: output_frames_squeezenet/ekhacizpah/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bwuwstvsbw\n",
      "Processing image: output_frames_squeezenet/bwuwstvsbw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: abqwwspghj\n",
      "Processing image: output_frames_squeezenet/abqwwspghj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bhpwpydzpo\n",
      "Processing image: output_frames_squeezenet/bhpwpydzpo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dsndhujjjb\n",
      "Processing image: output_frames_squeezenet/dsndhujjjb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cdyakrxkia\n",
      "Processing image: output_frames_squeezenet/cdyakrxkia/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bpapbctoao\n",
      "Processing image: output_frames_squeezenet/bpapbctoao/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bnjcdrfuov\n",
      "Processing image: output_frames_squeezenet/bnjcdrfuov/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dgxrqjdomn\n",
      "Processing image: output_frames_squeezenet/dgxrqjdomn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: axwgcsyphv\n",
      "Processing image: output_frames_squeezenet/axwgcsyphv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dtbpmdqvao\n",
      "Processing image: output_frames_squeezenet/dtbpmdqvao/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dntkzzzcdh\n",
      "Processing image: output_frames_squeezenet/dntkzzzcdh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ayqvfdhslr\n",
      "Processing image: output_frames_squeezenet/ayqvfdhslr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehfiekigla\n",
      "Processing image: output_frames_squeezenet/ehfiekigla/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: byyqectxqa\n",
      "Processing image: output_frames_squeezenet/byyqectxqa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: drcyabprvt\n",
      "Processing image: output_frames_squeezenet/drcyabprvt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dsjbknkujw\n",
      "Processing image: output_frames_squeezenet/dsjbknkujw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avywawptfc\n",
      "Processing image: output_frames_squeezenet/avywawptfc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avssvvsdhz\n",
      "Processing image: output_frames_squeezenet/avssvvsdhz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aybgughjxh\n",
      "Processing image: output_frames_squeezenet/aybgughjxh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: egghxjjmfg\n",
      "Processing image: output_frames_squeezenet/egghxjjmfg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: curpwogllm\n",
      "Processing image: output_frames_squeezenet/curpwogllm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cbltdtxglo\n",
      "Processing image: output_frames_squeezenet/cbltdtxglo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhcndnuwta\n",
      "Processing image: output_frames_squeezenet/dhcndnuwta/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dvumqqhoac\n",
      "Processing image: output_frames_squeezenet/dvumqqhoac/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dqzreruvje\n",
      "Processing image: output_frames_squeezenet/dqzreruvje/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bdbhekrrwo\n",
      "Processing image: output_frames_squeezenet/bdbhekrrwo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: awukslzjra\n",
      "Processing image: output_frames_squeezenet/awukslzjra/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: czkdanyadc\n",
      "Processing image: output_frames_squeezenet/czkdanyadc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aslsvlvpth\n",
      "Processing image: output_frames_squeezenet/aslsvlvpth/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dozyddhild\n",
      "Processing image: output_frames_squeezenet/dozyddhild/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dqnyszdong\n",
      "Processing image: output_frames_squeezenet/dqnyszdong/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqkdbcqjvb\n",
      "Processing image: output_frames_squeezenet/bqkdbcqjvb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bvzjkezkms\n",
      "Processing image: output_frames_squeezenet/bvzjkezkms/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ensyyivobf\n",
      "Processing image: output_frames_squeezenet/ensyyivobf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cuzrgrbvil\n",
      "Processing image: output_frames_squeezenet/cuzrgrbvil/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dzyuwjkjui\n",
      "Processing image: output_frames_squeezenet/dzyuwjkjui/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dafhtipaml\n",
      "Processing image: output_frames_squeezenet/dafhtipaml/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dqswpjoepo\n",
      "Processing image: output_frames_squeezenet/dqswpjoepo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: etdcqxabww\n",
      "Processing image: output_frames_squeezenet/etdcqxabww/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bgwmmujlmc\n",
      "Processing image: output_frames_squeezenet/bgwmmujlmc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: esyhwdfnxs\n",
      "Processing image: output_frames_squeezenet/esyhwdfnxs/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bndybcqhfr\n",
      "Processing image: output_frames_squeezenet/bndybcqhfr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cnilkgvfei\n",
      "Processing image: output_frames_squeezenet/cnilkgvfei/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: djxdyjopjd\n",
      "Processing image: output_frames_squeezenet/djxdyjopjd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dkwjwbwgey\n",
      "Processing image: output_frames_squeezenet/dkwjwbwgey/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dqqtjcryjv\n",
      "Processing image: output_frames_squeezenet/dqqtjcryjv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eepezmygaq\n",
      "Processing image: output_frames_squeezenet/eepezmygaq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bkvetcojbt\n",
      "Processing image: output_frames_squeezenet/bkvetcojbt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cyxlcuyznd\n",
      "Processing image: output_frames_squeezenet/cyxlcuyznd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bseamdrpbj\n",
      "Processing image: output_frames_squeezenet/bseamdrpbj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bchnbulevv\n",
      "Processing image: output_frames_squeezenet/bchnbulevv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cqrskwiqng\n",
      "Processing image: output_frames_squeezenet/cqrskwiqng/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: atyntldecu\n",
      "Processing image: output_frames_squeezenet/atyntldecu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cthdnahrkh\n",
      "Processing image: output_frames_squeezenet/cthdnahrkh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eqvuznuwsa\n",
      "Processing image: output_frames_squeezenet/eqvuznuwsa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aytzyidmgs\n",
      "Processing image: output_frames_squeezenet/aytzyidmgs/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: egbbcxcuqy\n",
      "Processing image: output_frames_squeezenet/egbbcxcuqy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: emfbhytfhc\n",
      "Processing image: output_frames_squeezenet/emfbhytfhc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: amowujxmzc\n",
      "Processing image: output_frames_squeezenet/amowujxmzc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ekcrtigpab\n",
      "Processing image: output_frames_squeezenet/ekcrtigpab/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhjmzhrcav\n",
      "Processing image: output_frames_squeezenet/dhjmzhrcav/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqdjzqhcft\n",
      "Processing image: output_frames_squeezenet/bqdjzqhcft/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: erlvuvjsjf\n",
      "Processing image: output_frames_squeezenet/erlvuvjsjf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: efwfxwwlbw\n",
      "Processing image: output_frames_squeezenet/efwfxwwlbw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eggbjzxnmg\n",
      "Processing image: output_frames_squeezenet/eggbjzxnmg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: asmpfjfzif\n",
      "Processing image: output_frames_squeezenet/asmpfjfzif/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btxlttbpkj\n",
      "Processing image: output_frames_squeezenet/btxlttbpkj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehtdtkmmli\n",
      "Processing image: output_frames_squeezenet/ehtdtkmmli/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: arlmiizoob\n",
      "Processing image: output_frames_squeezenet/arlmiizoob/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: etejaapnxh\n",
      "Processing image: output_frames_squeezenet/etejaapnxh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eekozbeafq\n",
      "Processing image: output_frames_squeezenet/eekozbeafq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: apgjqzkoma\n",
      "Processing image: output_frames_squeezenet/apgjqzkoma/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: epymyyiblu\n",
      "Processing image: output_frames_squeezenet/epymyyiblu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: adylbeequz\n",
      "Processing image: output_frames_squeezenet/adylbeequz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: deyyistcrd\n",
      "Processing image: output_frames_squeezenet/deyyistcrd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dlrsbscitn\n",
      "Processing image: output_frames_squeezenet/dlrsbscitn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dxuliowugt\n",
      "Processing image: output_frames_squeezenet/dxuliowugt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cferslmfwh\n",
      "Processing image: output_frames_squeezenet/cferslmfwh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aapnvogymq\n",
      "Processing image: output_frames_squeezenet/aapnvogymq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: efdyrflcpg\n",
      "Processing image: output_frames_squeezenet/efdyrflcpg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bwipwzzxxu\n",
      "Processing image: output_frames_squeezenet/bwipwzzxxu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: drgjzlxzxj\n",
      "Processing image: output_frames_squeezenet/drgjzlxzxj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aknmpoonls\n",
      "Processing image: output_frames_squeezenet/aknmpoonls/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dulanfulol\n",
      "Processing image: output_frames_squeezenet/dulanfulol/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cobjrlugvp\n",
      "Processing image: output_frames_squeezenet/cobjrlugvp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aknbdpmgua\n",
      "Processing image: output_frames_squeezenet/aknbdpmgua/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bdnaqemxmr\n",
      "Processing image: output_frames_squeezenet/bdnaqemxmr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eukvucdetx\n",
      "Processing image: output_frames_squeezenet/eukvucdetx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: awhmfnnjih\n",
      "Processing image: output_frames_squeezenet/awhmfnnjih/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: duycddgtrl\n",
      "Processing image: output_frames_squeezenet/duycddgtrl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: duzuusuajr\n",
      "Processing image: output_frames_squeezenet/duzuusuajr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bahdpoesir\n",
      "Processing image: output_frames_squeezenet/bahdpoesir/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: etmcruaihe\n",
      "Processing image: output_frames_squeezenet/etmcruaihe/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eajlrktemq\n",
      "Processing image: output_frames_squeezenet/eajlrktemq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bxzakyopjf\n",
      "Processing image: output_frames_squeezenet/bxzakyopjf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: blzydqdfem\n",
      "Processing image: output_frames_squeezenet/blzydqdfem/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btohlidmru\n",
      "Processing image: output_frames_squeezenet/btohlidmru/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aladcziidp\n",
      "Processing image: output_frames_squeezenet/aladcziidp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: czfunozvwp\n",
      "Processing image: output_frames_squeezenet/czfunozvwp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: axwovszumc\n",
      "Processing image: output_frames_squeezenet/axwovszumc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bweezhfpzp\n",
      "Processing image: output_frames_squeezenet/bweezhfpzp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btjwbtsgln\n",
      "Processing image: output_frames_squeezenet/btjwbtsgln/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aybumesmpk\n",
      "Processing image: output_frames_squeezenet/aybumesmpk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cdphtzqrvp\n",
      "Processing image: output_frames_squeezenet/cdphtzqrvp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: elvvackpjh\n",
      "Processing image: output_frames_squeezenet/elvvackpjh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bbvgxeczei\n",
      "Processing image: output_frames_squeezenet/bbvgxeczei/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: diopzaywor\n",
      "Processing image: output_frames_squeezenet/diopzaywor/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cttqtsjvgn\n",
      "Processing image: output_frames_squeezenet/cttqtsjvgn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: beboztfcme\n",
      "Processing image: output_frames_squeezenet/beboztfcme/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cdbsbdymzd\n",
      "Processing image: output_frames_squeezenet/cdbsbdymzd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bdxuhamuqx\n",
      "Processing image: output_frames_squeezenet/bdxuhamuqx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dboxtiehng\n",
      "Processing image: output_frames_squeezenet/dboxtiehng/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehieahnhte\n",
      "Processing image: output_frames_squeezenet/ehieahnhte/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ckkuyewywx\n",
      "Processing image: output_frames_squeezenet/ckkuyewywx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cbbibzcoih\n",
      "Processing image: output_frames_squeezenet/cbbibzcoih/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btjlfpzbdu\n",
      "Processing image: output_frames_squeezenet/btjlfpzbdu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: acifjvzvpm\n",
      "Processing image: output_frames_squeezenet/acifjvzvpm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cfxkpiweqt\n",
      "Processing image: output_frames_squeezenet/cfxkpiweqt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cmxcfkrjiv\n",
      "Processing image: output_frames_squeezenet/cmxcfkrjiv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqhtpqmmqp\n",
      "Processing image: output_frames_squeezenet/bqhtpqmmqp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: apatcsqejh\n",
      "Processing image: output_frames_squeezenet/apatcsqejh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dkhlttuvmx\n",
      "Processing image: output_frames_squeezenet/dkhlttuvmx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aipfdnwpoo\n",
      "Processing image: output_frames_squeezenet/aipfdnwpoo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btmsngnqhv\n",
      "Processing image: output_frames_squeezenet/btmsngnqhv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: brvqtabyxj\n",
      "Processing image: output_frames_squeezenet/brvqtabyxj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: chzieimrwu\n",
      "Processing image: output_frames_squeezenet/chzieimrwu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cizlkenljw\n",
      "Processing image: output_frames_squeezenet/cizlkenljw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dbnygxtwek\n",
      "Processing image: output_frames_squeezenet/dbnygxtwek/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dsdoseflas\n",
      "Processing image: output_frames_squeezenet/dsdoseflas/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: crktehraph\n",
      "Processing image: output_frames_squeezenet/crktehraph/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ddjggcasdw\n",
      "Processing image: output_frames_squeezenet/ddjggcasdw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: emaalmsonj\n",
      "Processing image: output_frames_squeezenet/emaalmsonj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eixwxvxbbn\n",
      "Processing image: output_frames_squeezenet/eixwxvxbbn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dkuayagnmc\n",
      "Processing image: output_frames_squeezenet/dkuayagnmc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eckvhdusax\n",
      "Processing image: output_frames_squeezenet/eckvhdusax/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dkzvdrzcnr\n",
      "Processing image: output_frames_squeezenet/dkzvdrzcnr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aklqzsddfl\n",
      "Processing image: output_frames_squeezenet/aklqzsddfl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dsgpbgsrdm\n",
      "Processing image: output_frames_squeezenet/dsgpbgsrdm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: diuzrpqjli\n",
      "Processing image: output_frames_squeezenet/diuzrpqjli/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cknyxaqouy\n",
      "Processing image: output_frames_squeezenet/cknyxaqouy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: arkroixhey\n",
      "Processing image: output_frames_squeezenet/arkroixhey/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eeyhxisdfh\n",
      "Processing image: output_frames_squeezenet/eeyhxisdfh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dzvyfiarrq\n",
      "Processing image: output_frames_squeezenet/dzvyfiarrq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bsqgziaylx\n",
      "Processing image: output_frames_squeezenet/bsqgziaylx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dbzcqmxzaj\n",
      "Processing image: output_frames_squeezenet/dbzcqmxzaj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: boovltmuwi\n",
      "Processing image: output_frames_squeezenet/boovltmuwi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: blpchvmhxx\n",
      "Processing image: output_frames_squeezenet/blpchvmhxx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bpxckdzddv\n",
      "Processing image: output_frames_squeezenet/bpxckdzddv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bhaaboftbc\n",
      "Processing image: output_frames_squeezenet/bhaaboftbc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dubiroskqn\n",
      "Processing image: output_frames_squeezenet/dubiroskqn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: agdkmztvby\n",
      "Processing image: output_frames_squeezenet/agdkmztvby/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cycacemkmt\n",
      "Processing image: output_frames_squeezenet/cycacemkmt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bdgipnyobr\n",
      "Processing image: output_frames_squeezenet/bdgipnyobr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ejkqesyvam\n",
      "Processing image: output_frames_squeezenet/ejkqesyvam/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: errocgcham\n",
      "Processing image: output_frames_squeezenet/errocgcham/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: byfenovjnf\n",
      "Processing image: output_frames_squeezenet/byfenovjnf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: anpuvshzoo\n",
      "Processing image: output_frames_squeezenet/anpuvshzoo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btunxncpjh\n",
      "Processing image: output_frames_squeezenet/btunxncpjh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqnymlsayl\n",
      "Processing image: output_frames_squeezenet/bqnymlsayl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: azsmewqghg\n",
      "Processing image: output_frames_squeezenet/azsmewqghg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: atvmxvwyns\n",
      "Processing image: output_frames_squeezenet/atvmxvwyns/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: adhsbajydo\n",
      "Processing image: output_frames_squeezenet/adhsbajydo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: arrhsnjqku\n",
      "Processing image: output_frames_squeezenet/arrhsnjqku/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ddqccgmtka\n",
      "Processing image: output_frames_squeezenet/ddqccgmtka/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: elginszwtk\n",
      "Processing image: output_frames_squeezenet/elginszwtk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avibnnhwhp\n",
      "Processing image: output_frames_squeezenet/avibnnhwhp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bilnggbxgu\n",
      "Processing image: output_frames_squeezenet/bilnggbxgu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eebserckhh\n",
      "Processing image: output_frames_squeezenet/eebserckhh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: axczxisdtb\n",
      "Processing image: output_frames_squeezenet/axczxisdtb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: alninxcyhg\n",
      "Processing image: output_frames_squeezenet/alninxcyhg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: byunigvnay\n",
      "Processing image: output_frames_squeezenet/byunigvnay/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bnbuonyoje\n",
      "Processing image: output_frames_squeezenet/bnbuonyoje/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bbhpvrmbse\n",
      "Processing image: output_frames_squeezenet/bbhpvrmbse/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ecuvtoltue\n",
      "Processing image: output_frames_squeezenet/ecuvtoltue/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dtocdfbwca\n",
      "Processing image: output_frames_squeezenet/dtocdfbwca/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dxbqjxrhin\n",
      "Processing image: output_frames_squeezenet/dxbqjxrhin/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: amaivqofda\n",
      "Processing image: output_frames_squeezenet/amaivqofda/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bmhvktyiwp\n",
      "Processing image: output_frames_squeezenet/bmhvktyiwp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cwsbspfzck\n",
      "Processing image: output_frames_squeezenet/cwsbspfzck/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: clrycekyst\n",
      "Processing image: output_frames_squeezenet/clrycekyst/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehbnclaukr\n",
      "Processing image: output_frames_squeezenet/ehbnclaukr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: akxoopqjqz\n",
      "Processing image: output_frames_squeezenet/akxoopqjqz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dnhvalzvrt\n",
      "Processing image: output_frames_squeezenet/dnhvalzvrt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: atkdltyyen\n",
      "Processing image: output_frames_squeezenet/atkdltyyen/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ckbdwedgmc\n",
      "Processing image: output_frames_squeezenet/ckbdwedgmc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aneclqfpbt\n",
      "Processing image: output_frames_squeezenet/aneclqfpbt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cqhngvpgyi\n",
      "Processing image: output_frames_squeezenet/cqhngvpgyi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bddjdhzfze\n",
      "Processing image: output_frames_squeezenet/bddjdhzfze/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cvaksbpssm\n",
      "Processing image: output_frames_squeezenet/cvaksbpssm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aufmsmnoye\n",
      "Processing image: output_frames_squeezenet/aufmsmnoye/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dbhoxkblzx\n",
      "Processing image: output_frames_squeezenet/dbhoxkblzx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ctpqeykqdp\n",
      "Processing image: output_frames_squeezenet/ctpqeykqdp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ellavthztb\n",
      "Processing image: output_frames_squeezenet/ellavthztb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: duvyaxbzvp\n",
      "Processing image: output_frames_squeezenet/duvyaxbzvp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cmbzllswnl\n",
      "Processing image: output_frames_squeezenet/cmbzllswnl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cppdvdejkc\n",
      "Processing image: output_frames_squeezenet/cppdvdejkc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btiysiskpf\n",
      "Processing image: output_frames_squeezenet/btiysiskpf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dgzklxjmix\n",
      "Processing image: output_frames_squeezenet/dgzklxjmix/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: erqgqacbqe\n",
      "Processing image: output_frames_squeezenet/erqgqacbqe/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dkdwxmtpuo\n",
      "Processing image: output_frames_squeezenet/dkdwxmtpuo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bhsluedavd\n",
      "Processing image: output_frames_squeezenet/bhsluedavd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: brwrlczjvi\n",
      "Processing image: output_frames_squeezenet/brwrlczjvi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: asaxgevnnp\n",
      "Processing image: output_frames_squeezenet/asaxgevnnp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: caqbrkogkb\n",
      "Processing image: output_frames_squeezenet/caqbrkogkb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dofusvhnib\n",
      "Processing image: output_frames_squeezenet/dofusvhnib/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ahbweevwpv\n",
      "Processing image: output_frames_squeezenet/ahbweevwpv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bmehkyanbj\n",
      "Processing image: output_frames_squeezenet/bmehkyanbj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: byofowlkki\n",
      "Processing image: output_frames_squeezenet/byofowlkki/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dxuplhwvig\n",
      "Processing image: output_frames_squeezenet/dxuplhwvig/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avfitoutyn\n",
      "Processing image: output_frames_squeezenet/avfitoutyn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eoewqcpbgt\n",
      "Processing image: output_frames_squeezenet/eoewqcpbgt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avgiuextiz\n",
      "Processing image: output_frames_squeezenet/avgiuextiz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aagfhgtpmv\n",
      "Processing image: output_frames_squeezenet/aagfhgtpmv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: axoygtekut\n",
      "Processing image: output_frames_squeezenet/axoygtekut/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eqjscdagiv\n",
      "Processing image: output_frames_squeezenet/eqjscdagiv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ajwpjhrbcv\n",
      "Processing image: output_frames_squeezenet/ajwpjhrbcv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bmjmjmbglm\n",
      "Processing image: output_frames_squeezenet/bmjmjmbglm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: crzfebnfgb\n",
      "Processing image: output_frames_squeezenet/crzfebnfgb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehdkmxgtxh\n",
      "Processing image: output_frames_squeezenet/ehdkmxgtxh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: czmqpxrqoh\n",
      "Processing image: output_frames_squeezenet/czmqpxrqoh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ecnihjlfyt\n",
      "Processing image: output_frames_squeezenet/ecnihjlfyt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ceymbecxnj\n",
      "Processing image: output_frames_squeezenet/ceymbecxnj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bjsmaqefoi\n",
      "Processing image: output_frames_squeezenet/bjsmaqefoi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: andaxzscny\n",
      "Processing image: output_frames_squeezenet/andaxzscny/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bghphrsfxf\n",
      "Processing image: output_frames_squeezenet/bghphrsfxf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: esgftaficx\n",
      "Processing image: output_frames_squeezenet/esgftaficx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aorjvbyxhw\n",
      "Processing image: output_frames_squeezenet/aorjvbyxhw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: emgjphonqb\n",
      "Processing image: output_frames_squeezenet/emgjphonqb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cksanfsjhc\n",
      "Processing image: output_frames_squeezenet/cksanfsjhc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cwqlvzefpg\n",
      "Processing image: output_frames_squeezenet/cwqlvzefpg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: afoovlsmtx\n",
      "Processing image: output_frames_squeezenet/afoovlsmtx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ajqslcypsw\n",
      "Processing image: output_frames_squeezenet/ajqslcypsw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: btugrnoton\n",
      "Processing image: output_frames_squeezenet/btugrnoton/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: abofeumbvv\n",
      "Processing image: output_frames_squeezenet/abofeumbvv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: agqphdxmwt\n",
      "Processing image: output_frames_squeezenet/agqphdxmwt/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ebywfrmhtd\n",
      "Processing image: output_frames_squeezenet/ebywfrmhtd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cfyduhpbps\n",
      "Processing image: output_frames_squeezenet/cfyduhpbps/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bgaogsjehq\n",
      "Processing image: output_frames_squeezenet/bgaogsjehq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bhbdugnurr\n",
      "Processing image: output_frames_squeezenet/bhbdugnurr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: altziddtxi\n",
      "Processing image: output_frames_squeezenet/altziddtxi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: agrmhtjdlk\n",
      "Processing image: output_frames_squeezenet/agrmhtjdlk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bkmdzhfzfh\n",
      "Processing image: output_frames_squeezenet/bkmdzhfzfh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: esxrvsgpvb\n",
      "Processing image: output_frames_squeezenet/esxrvsgpvb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bopqhhalml\n",
      "Processing image: output_frames_squeezenet/bopqhhalml/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ccfoszqabv\n",
      "Processing image: output_frames_squeezenet/ccfoszqabv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dgmevclvzy\n",
      "Processing image: output_frames_squeezenet/dgmevclvzy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dzieklokdr\n",
      "Processing image: output_frames_squeezenet/dzieklokdr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cyclgfjdrv\n",
      "Processing image: output_frames_squeezenet/cyclgfjdrv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ecujsjhscd\n",
      "Processing image: output_frames_squeezenet/ecujsjhscd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dbtbbhakdv\n",
      "Processing image: output_frames_squeezenet/dbtbbhakdv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: apogckdfrz\n",
      "Processing image: output_frames_squeezenet/apogckdfrz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eiriyukqqy\n",
      "Processing image: output_frames_squeezenet/eiriyukqqy/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eejswgycjc\n",
      "Processing image: output_frames_squeezenet/eejswgycjc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bejhvclboh\n",
      "Processing image: output_frames_squeezenet/bejhvclboh/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cxrfacemmq\n",
      "Processing image: output_frames_squeezenet/cxrfacemmq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cdaxixbosp\n",
      "Processing image: output_frames_squeezenet/cdaxixbosp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bmioepcpsx\n",
      "Processing image: output_frames_squeezenet/bmioepcpsx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: acqfdwsrhi\n",
      "Processing image: output_frames_squeezenet/acqfdwsrhi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ebkzwjgjhq\n",
      "Processing image: output_frames_squeezenet/ebkzwjgjhq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bgvhtpzknn\n",
      "Processing image: output_frames_squeezenet/bgvhtpzknn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avvdgsennp\n",
      "Processing image: output_frames_squeezenet/avvdgsennp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dnyvfblxpm\n",
      "Processing image: output_frames_squeezenet/dnyvfblxpm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cpjxareypw\n",
      "Processing image: output_frames_squeezenet/cpjxareypw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dptbnjnkdg\n",
      "Processing image: output_frames_squeezenet/dptbnjnkdg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: asvcrfdpnq\n",
      "Processing image: output_frames_squeezenet/asvcrfdpnq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: alaijyygdv\n",
      "Processing image: output_frames_squeezenet/alaijyygdv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhoqofwoxa\n",
      "Processing image: output_frames_squeezenet/dhoqofwoxa/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bguwlyazau\n",
      "Processing image: output_frames_squeezenet/bguwlyazau/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cxttmymlbn\n",
      "Processing image: output_frames_squeezenet/cxttmymlbn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eiwopxzjfn\n",
      "Processing image: output_frames_squeezenet/eiwopxzjfn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eprybmbpba\n",
      "Processing image: output_frames_squeezenet/eprybmbpba/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: doanjploai\n",
      "Processing image: output_frames_squeezenet/doanjploai/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cgvrgibpfo\n",
      "Processing image: output_frames_squeezenet/cgvrgibpfo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dnexlwbcxq\n",
      "Processing image: output_frames_squeezenet/dnexlwbcxq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehevsxtecd\n",
      "Processing image: output_frames_squeezenet/ehevsxtecd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: byijojkdba\n",
      "Processing image: output_frames_squeezenet/byijojkdba/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: chtapglbcj\n",
      "Processing image: output_frames_squeezenet/chtapglbcj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bbhtdfuqxq\n",
      "Processing image: output_frames_squeezenet/bbhtdfuqxq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: covdcysmbi\n",
      "Processing image: output_frames_squeezenet/covdcysmbi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ahdbuwqxit\n",
      "Processing image: output_frames_squeezenet/ahdbuwqxit/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bzmdrafeex\n",
      "Processing image: output_frames_squeezenet/bzmdrafeex/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eebrkicpry\n",
      "Processing image: output_frames_squeezenet/eebrkicpry/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bourlmzsio\n",
      "Processing image: output_frames_squeezenet/bourlmzsio/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cettndmvzl\n",
      "Processing image: output_frames_squeezenet/cettndmvzl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: akvmwkdyuv\n",
      "Processing image: output_frames_squeezenet/akvmwkdyuv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bydaidkpdp\n",
      "Processing image: output_frames_squeezenet/bydaidkpdp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhcselezer\n",
      "Processing image: output_frames_squeezenet/dhcselezer/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bmjzrlszhi\n",
      "Processing image: output_frames_squeezenet/bmjzrlszhi/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aevrfsexku\n",
      "Processing image: output_frames_squeezenet/aevrfsexku/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: augtsuxpzc\n",
      "Processing image: output_frames_squeezenet/augtsuxpzc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cwrtyzndpx\n",
      "Processing image: output_frames_squeezenet/cwrtyzndpx/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: akzbnazxtz\n",
      "Processing image: output_frames_squeezenet/akzbnazxtz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dqppxmoqdl\n",
      "Processing image: output_frames_squeezenet/dqppxmoqdl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: avtycwsgyb\n",
      "Processing image: output_frames_squeezenet/avtycwsgyb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: axntxmycwd\n",
      "Processing image: output_frames_squeezenet/axntxmycwd/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bofqajtwve\n",
      "Processing image: output_frames_squeezenet/bofqajtwve/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ebebgmtlcu\n",
      "Processing image: output_frames_squeezenet/ebebgmtlcu/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eahlqmfvtj\n",
      "Processing image: output_frames_squeezenet/eahlqmfvtj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cepxysienc\n",
      "Processing image: output_frames_squeezenet/cepxysienc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aqpnvjhuzw\n",
      "Processing image: output_frames_squeezenet/aqpnvjhuzw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ebeknhudxq\n",
      "Processing image: output_frames_squeezenet/ebeknhudxq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dzwkmcwkwl\n",
      "Processing image: output_frames_squeezenet/dzwkmcwkwl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cglxirfaey\n",
      "Processing image: output_frames_squeezenet/cglxirfaey/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: abarnvbtwb\n",
      "Processing image: output_frames_squeezenet/abarnvbtwb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: atxvxouljq\n",
      "Processing image: output_frames_squeezenet/atxvxouljq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: esnntzzajv\n",
      "Processing image: output_frames_squeezenet/esnntzzajv/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bgmlwsoamc\n",
      "Processing image: output_frames_squeezenet/bgmlwsoamc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: acxwigylke\n",
      "Processing image: output_frames_squeezenet/acxwigylke/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: eczrseixwq\n",
      "Processing image: output_frames_squeezenet/eczrseixwq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bjjbwsqjir\n",
      "Processing image: output_frames_squeezenet/bjjbwsqjir/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dcamvmuors\n",
      "Processing image: output_frames_squeezenet/dcamvmuors/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhkwmjxwrn\n",
      "Processing image: output_frames_squeezenet/dhkwmjxwrn/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bkwxhglwct\n",
      "Processing image: output_frames_squeezenet/bkwxhglwct/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: awnwkrqibf\n",
      "Processing image: output_frames_squeezenet/awnwkrqibf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ccmonzqfrz\n",
      "Processing image: output_frames_squeezenet/ccmonzqfrz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: crezycjqyk\n",
      "Processing image: output_frames_squeezenet/crezycjqyk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aelfnikyqj\n",
      "Processing image: output_frames_squeezenet/aelfnikyqj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: drtbksnpol\n",
      "Processing image: output_frames_squeezenet/drtbksnpol/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: degpbqvcay\n",
      "Processing image: output_frames_squeezenet/degpbqvcay/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dwediigjit\n",
      "Processing image: output_frames_squeezenet/dwediigjit/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ddhfabwpuz\n",
      "Processing image: output_frames_squeezenet/ddhfabwpuz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cwbacdwrzo\n",
      "Processing image: output_frames_squeezenet/cwbacdwrzo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dlpoieqvfb\n",
      "Processing image: output_frames_squeezenet/dlpoieqvfb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aczrgyricp\n",
      "Processing image: output_frames_squeezenet/aczrgyricp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: clihsshdkq\n",
      "Processing image: output_frames_squeezenet/clihsshdkq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: byqzyxifza\n",
      "Processing image: output_frames_squeezenet/byqzyxifza/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ehccixxzoe\n",
      "Processing image: output_frames_squeezenet/ehccixxzoe/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqtuuwzdtr\n",
      "Processing image: output_frames_squeezenet/bqtuuwzdtr/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: asdpeebotb\n",
      "Processing image: output_frames_squeezenet/asdpeebotb/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: beyebyhrph\n",
      "Processing image: output_frames_squeezenet/beyebyhrph/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bntlodcfeg\n",
      "Processing image: output_frames_squeezenet/bntlodcfeg/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: azpuxunqyo\n",
      "Processing image: output_frames_squeezenet/azpuxunqyo/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bzythlfnhq\n",
      "Processing image: output_frames_squeezenet/bzythlfnhq/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqqpbzjgup\n",
      "Processing image: output_frames_squeezenet/bqqpbzjgup/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: aelzhcnwgf\n",
      "Processing image: output_frames_squeezenet/aelzhcnwgf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cprhtltsjp\n",
      "Processing image: output_frames_squeezenet/cprhtltsjp/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dkrvorliqc\n",
      "Processing image: output_frames_squeezenet/dkrvorliqc/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhevettufk\n",
      "Processing image: output_frames_squeezenet/dhevettufk/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: ctzmavwror\n",
      "Processing image: output_frames_squeezenet/ctzmavwror/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bqeiblbxtl\n",
      "Processing image: output_frames_squeezenet/bqeiblbxtl/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: etohcvnzbj\n",
      "Processing image: output_frames_squeezenet/etohcvnzbj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dhxctgyoqj\n",
      "Processing image: output_frames_squeezenet/dhxctgyoqj/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: bulkxhhknf\n",
      "Processing image: output_frames_squeezenet/bulkxhhknf/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dakiztgtnw\n",
      "Processing image: output_frames_squeezenet/dakiztgtnw/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: adohikbdaz\n",
      "Processing image: output_frames_squeezenet/adohikbdaz/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: cqfugiqupm\n",
      "Processing image: output_frames_squeezenet/cqfugiqupm/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n",
      "Processing video folder: dfbpceeaox\n",
      "Processing image: output_frames_squeezenet/dfbpceeaox/error_level_plot.png\n",
      "Image tensor shape: torch.Size([1, 3, 224, 224])\n",
      "Extracted features for error_level_plot.png\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T08:21:18.149030Z",
     "start_time": "2024-10-11T08:21:17.751001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#FOR INCEPTION\n",
    "# ORAGANIZED THE FEATURES.NPY OF EACH VIDEO ACCORDING TO THERE LABEL FROM METADATA.JSON FILE \n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "input_frames_dir = \"output_frames_inception\"\n",
    "output_dir = \"organized_frames_inception\"\n",
    "metadata_file = \"metadata.json\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(os.path.join(output_dir, \"REAL\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, \"FAKE\"), exist_ok=True)\n",
    "\n",
    "# Read metadata\n",
    "with open(metadata_file, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Process each video\n",
    "for video, info in metadata.items():\n",
    "    label = info[\"label\"]\n",
    "    video_name = os.path.splitext(video)[0]  # Remove the .mp4 extension\n",
    "\n",
    "    # Source and destination paths\n",
    "    src_path = os.path.join(input_frames_dir, video_name)\n",
    "    dst_path = os.path.join(output_dir, label, video_name)\n",
    "\n",
    "    # Check if the source directory exists\n",
    "    if os.path.exists(src_path):\n",
    "        # Copy the frame folder to the appropriate category\n",
    "        shutil.copytree(src_path, dst_path)\n",
    "        print(f\"Copied {video_name} to {label} category\")\n",
    "    else:\n",
    "        print(f\"Warning: Frame folder for {video_name} not found\")\n",
    "\n",
    "print(\"Organization complete!\")"
   ],
   "id": "628df3aa0393f5c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied aagfhgtpmv to FAKE category\n",
      "Copied aapnvogymq to FAKE category\n",
      "Copied abarnvbtwb to REAL category\n",
      "Copied abofeumbvv to FAKE category\n",
      "Copied abqwwspghj to FAKE category\n",
      "Copied acifjvzvpm to FAKE category\n",
      "Copied acqfdwsrhi to FAKE category\n",
      "Copied acxnxvbsxk to FAKE category\n",
      "Copied acxwigylke to FAKE category\n",
      "Copied aczrgyricp to FAKE category\n",
      "Copied adhsbajydo to FAKE category\n",
      "Copied adohikbdaz to FAKE category\n",
      "Copied adylbeequz to FAKE category\n",
      "Copied aelfnikyqj to REAL category\n",
      "Copied aelzhcnwgf to FAKE category\n",
      "Copied aettqgevhz to FAKE category\n",
      "Copied aevrfsexku to FAKE category\n",
      "Copied afoovlsmtx to REAL category\n",
      "Copied agdkmztvby to FAKE category\n",
      "Copied agqphdxmwt to FAKE category\n",
      "Copied agrmhtjdlk to REAL category\n",
      "Copied ahbweevwpv to FAKE category\n",
      "Copied ahdbuwqxit to FAKE category\n",
      "Copied ahfazfbntc to FAKE category\n",
      "Copied ahqqqilsxt to REAL category\n",
      "Copied aipfdnwpoo to FAKE category\n",
      "Copied ajqslcypsw to REAL category\n",
      "Copied ajwpjhrbcv to FAKE category\n",
      "Copied aklqzsddfl to FAKE category\n",
      "Copied aknbdpmgua to FAKE category\n",
      "Copied aknmpoonls to FAKE category\n",
      "Copied akvmwkdyuv to FAKE category\n",
      "Copied akxoopqjqz to FAKE category\n",
      "Copied akzbnazxtz to FAKE category\n",
      "Copied aladcziidp to FAKE category\n",
      "Copied alaijyygdv to FAKE category\n",
      "Copied alninxcyhg to FAKE category\n",
      "Copied altziddtxi to FAKE category\n",
      "Copied alvgwypubw to FAKE category\n",
      "Copied amaivqofda to FAKE category\n",
      "Copied amowujxmzc to FAKE category\n",
      "Copied andaxzscny to FAKE category\n",
      "Copied aneclqfpbt to FAKE category\n",
      "Copied anpuvshzoo to REAL category\n",
      "Copied aorjvbyxhw to FAKE category\n",
      "Copied apatcsqejh to FAKE category\n",
      "Copied apgjqzkoma to FAKE category\n",
      "Copied apogckdfrz to FAKE category\n",
      "Copied aqpnvjhuzw to FAKE category\n",
      "Copied arkroixhey to FAKE category\n",
      "Copied arlmiizoob to FAKE category\n",
      "Copied arrhsnjqku to FAKE category\n",
      "Copied asaxgevnnp to REAL category\n",
      "Copied asdpeebotb to FAKE category\n",
      "Copied aslsvlvpth to FAKE category\n",
      "Copied asmpfjfzif to FAKE category\n",
      "Copied asvcrfdpnq to FAKE category\n",
      "Copied atkdltyyen to REAL category\n",
      "Copied atvmxvwyns to REAL category\n",
      "Copied atxvxouljq to FAKE category\n",
      "Copied atyntldecu to FAKE category\n",
      "Copied atzdznmder to FAKE category\n",
      "Copied aufmsmnoye to FAKE category\n",
      "Copied augtsuxpzc to FAKE category\n",
      "Copied avfitoutyn to FAKE category\n",
      "Copied avgiuextiz to FAKE category\n",
      "Copied avibnnhwhp to FAKE category\n",
      "Copied avmjormvsx to REAL category\n",
      "Copied avnqydkqjj to FAKE category\n",
      "Copied avssvvsdhz to FAKE category\n",
      "Copied avtycwsgyb to FAKE category\n",
      "Copied avvdgsennp to FAKE category\n",
      "Copied avywawptfc to FAKE category\n",
      "Copied awhmfnnjih to FAKE category\n",
      "Copied awnwkrqibf to FAKE category\n",
      "Copied awukslzjra to FAKE category\n",
      "Copied axczxisdtb to FAKE category\n",
      "Copied axntxmycwd to REAL category\n",
      "Copied axoygtekut to FAKE category\n",
      "Copied axwgcsyphv to FAKE category\n",
      "Copied axwovszumc to FAKE category\n",
      "Copied aybgughjxh to REAL category\n",
      "Copied aybumesmpk to REAL category\n",
      "Copied ayqvfdhslr to FAKE category\n",
      "Copied aytzyidmgs to REAL category\n",
      "Copied azpuxunqyo to FAKE category\n",
      "Copied azsmewqghg to FAKE category\n",
      "Copied bahdpoesir to FAKE category\n",
      "Copied bbhpvrmbse to FAKE category\n",
      "Copied bbhtdfuqxq to FAKE category\n",
      "Copied bbvgxeczei to FAKE category\n",
      "Copied bchnbulevv to FAKE category\n",
      "Copied bctvsmddgq to FAKE category\n",
      "Copied bdbhekrrwo to FAKE category\n",
      "Copied bddjdhzfze to REAL category\n",
      "Copied bdgipnyobr to FAKE category\n",
      "Copied bdnaqemxmr to REAL category\n",
      "Copied bdxuhamuqx to FAKE category\n",
      "Copied beboztfcme to REAL category\n",
      "Copied bejhvclboh to REAL category\n",
      "Copied benmsfzfaz to FAKE category\n",
      "Copied beyebyhrph to REAL category\n",
      "Copied bffwsjxghk to REAL category\n",
      "Copied bgaogsjehq to FAKE category\n",
      "Copied bggsurpgpr to FAKE category\n",
      "Copied bghphrsfxf to FAKE category\n",
      "Copied bgmlwsoamc to FAKE category\n",
      "Copied bguwlyazau to FAKE category\n",
      "Copied bgvhtpzknn to REAL category\n",
      "Copied bgwmmujlmc to REAL category\n",
      "Copied bhaaboftbc to FAKE category\n",
      "Copied bhbdugnurr to FAKE category\n",
      "Copied bhpwpydzpo to FAKE category\n",
      "Copied bhsluedavd to FAKE category\n",
      "Copied bilnggbxgu to REAL category\n",
      "Copied bjjbwsqjir to FAKE category\n",
      "Copied bjkmjilrxp to FAKE category\n",
      "Copied bjsmaqefoi to FAKE category\n",
      "Copied bkmdzhfzfh to FAKE category\n",
      "Copied bkvetcojbt to FAKE category\n",
      "Copied bkwxhglwct to FAKE category\n",
      "Copied blpchvmhxx to FAKE category\n",
      "Copied blzydqdfem to FAKE category\n",
      "Copied bmbbkwmxqj to FAKE category\n",
      "Copied bmehkyanbj to FAKE category\n",
      "Copied bmhvktyiwp to FAKE category\n",
      "Copied bmioepcpsx to FAKE category\n",
      "Copied bmjmjmbglm to FAKE category\n",
      "Copied bmjzrlszhi to REAL category\n",
      "Copied bnbuonyoje to FAKE category\n",
      "Copied bndybcqhfr to FAKE category\n",
      "Copied bnjcdrfuov to FAKE category\n",
      "Copied bntlodcfeg to FAKE category\n",
      "Copied bofqajtwve to FAKE category\n",
      "Copied boovltmuwi to FAKE category\n",
      "Copied bopqhhalml to FAKE category\n",
      "Copied bourlmzsio to FAKE category\n",
      "Copied bpapbctoao to REAL category\n",
      "Copied bpwzipqtxf to FAKE category\n",
      "Copied bpxckdzddv to FAKE category\n",
      "Copied bqdjzqhcft to FAKE category\n",
      "Copied bqeiblbxtl to FAKE category\n",
      "Copied bqhtpqmmqp to FAKE category\n",
      "Copied bqkdbcqjvb to FAKE category\n",
      "Copied bqnymlsayl to FAKE category\n",
      "Copied bqqpbzjgup to FAKE category\n",
      "Copied bqtuuwzdtr to FAKE category\n",
      "Copied brhalypwoo to FAKE category\n",
      "Copied brvqtabyxj to FAKE category\n",
      "Copied brwrlczjvi to REAL category\n",
      "Copied bseamdrpbj to FAKE category\n",
      "Copied bsfmwclnqy to FAKE category\n",
      "Copied bsqgziaylx to FAKE category\n",
      "Copied btiysiskpf to FAKE category\n",
      "Copied btjlfpzbdu to FAKE category\n",
      "Copied btjwbtsgln to FAKE category\n",
      "Copied btmsngnqhv to FAKE category\n",
      "Copied btohlidmru to FAKE category\n",
      "Copied btugrnoton to FAKE category\n",
      "Copied btunxncpjh to FAKE category\n",
      "Copied btxlttbpkj to FAKE category\n",
      "Copied bulkxhhknf to REAL category\n",
      "Copied bvgwelbeof to FAKE category\n",
      "Copied bvzjkezkms to FAKE category\n",
      "Copied bweezhfpzp to FAKE category\n",
      "Copied bwhlgysghg to REAL category\n",
      "Copied bwipwzzxxu to REAL category\n",
      "Copied bwuwstvsbw to FAKE category\n",
      "Copied bxzakyopjf to REAL category\n",
      "Copied bydaidkpdp to FAKE category\n",
      "Copied byfenovjnf to FAKE category\n",
      "Copied byijojkdba to FAKE category\n",
      "Copied byofowlkki to FAKE category\n",
      "Copied byqzyxifza to FAKE category\n",
      "Copied byunigvnay to FAKE category\n",
      "Copied byyqectxqa to FAKE category\n",
      "Copied bzmdrafeex to FAKE category\n",
      "Copied bzythlfnhq to REAL category\n",
      "Copied caifxvsozs to REAL category\n",
      "Copied caqbrkogkb to FAKE category\n",
      "Copied cbbibzcoih to FAKE category\n",
      "Copied cbltdtxglo to FAKE category\n",
      "Copied ccfoszqabv to REAL category\n",
      "Copied ccmonzqfrz to FAKE category\n",
      "Copied cdaxixbosp to FAKE category\n",
      "Copied cdbsbdymzd to FAKE category\n",
      "Copied cdphtzqrvp to FAKE category\n",
      "Copied cdyakrxkia to FAKE category\n",
      "Copied cepxysienc to FAKE category\n",
      "Copied cettndmvzl to FAKE category\n",
      "Copied ceymbecxnj to FAKE category\n",
      "Copied cferslmfwh to FAKE category\n",
      "Copied cffffbcywc to FAKE category\n",
      "Copied cfxkpiweqt to REAL category\n",
      "Copied cfyduhpbps to FAKE category\n",
      "Copied cglxirfaey to FAKE category\n",
      "Copied cgvrgibpfo to FAKE category\n",
      "Copied chtapglbcj to REAL category\n",
      "Copied chviwxsfhg to REAL category\n",
      "Copied chzieimrwu to FAKE category\n",
      "Copied ciyoudyhly to REAL category\n",
      "Copied cizlkenljw to REAL category\n",
      "Copied ckbdwedgmc to FAKE category\n",
      "Copied ckjaibzfxa to REAL category\n",
      "Copied ckkuyewywx to REAL category\n",
      "Copied cknyxaqouy to FAKE category\n",
      "Copied cksanfsjhc to FAKE category\n",
      "Copied clihsshdkq to FAKE category\n",
      "Copied clrycekyst to REAL category\n",
      "Copied cmbzllswnl to REAL category\n",
      "Copied cmxcfkrjiv to FAKE category\n",
      "Copied cnilkgvfei to FAKE category\n",
      "Copied coadfnerlk to FAKE category\n",
      "Copied cobjrlugvp to REAL category\n",
      "Copied covdcysmbi to FAKE category\n",
      "Copied cpjxareypw to REAL category\n",
      "Copied cppdvdejkc to REAL category\n",
      "Copied cprhtltsjp to REAL category\n",
      "Copied cqfugiqupm to FAKE category\n",
      "Copied cqhngvpgyi to FAKE category\n",
      "Copied cqrskwiqng to FAKE category\n",
      "Copied crezycjqyk to REAL category\n",
      "Copied crktehraph to FAKE category\n",
      "Copied crzfebnfgb to FAKE category\n",
      "Copied cthdnahrkh to FAKE category\n",
      "Copied ctpqeykqdp to FAKE category\n",
      "Copied cttqtsjvgn to FAKE category\n",
      "Copied ctzmavwror to FAKE category\n",
      "Copied curpwogllm to FAKE category\n",
      "Copied cuzrgrbvil to FAKE category\n",
      "Copied cvaksbpssm to FAKE category\n",
      "Copied cwbacdwrzo to FAKE category\n",
      "Copied cwqlvzefpg to FAKE category\n",
      "Copied cwrtyzndpx to FAKE category\n",
      "Copied cwsbspfzck to FAKE category\n",
      "Copied cwwandrkus to FAKE category\n",
      "Copied cxfujlvsuw to FAKE category\n",
      "Copied cxrfacemmq to FAKE category\n",
      "Copied cxttmymlbn to FAKE category\n",
      "Copied cyboodqqyr to FAKE category\n",
      "Copied cycacemkmt to FAKE category\n",
      "Copied cyclgfjdrv to FAKE category\n",
      "Copied cyxlcuyznd to REAL category\n",
      "Copied czfunozvwp to FAKE category\n",
      "Copied czkdanyadc to FAKE category\n",
      "Copied czmqpxrqoh to FAKE category\n",
      "Copied dafhtipaml to FAKE category\n",
      "Copied dakiztgtnw to REAL category\n",
      "Copied dakqwktlbi to FAKE category\n",
      "Copied dbhoxkblzx to FAKE category\n",
      "Copied dbhrpizyeq to FAKE category\n",
      "Copied dbnygxtwek to REAL category\n",
      "Copied dboxtiehng to FAKE category\n",
      "Copied dbtbbhakdv to REAL category\n",
      "Copied dbzcqmxzaj to FAKE category\n",
      "Copied dbzpcjntve to FAKE category\n",
      "Copied dcamvmuors to FAKE category\n",
      "Copied dcuiiorugd to FAKE category\n",
      "Copied ddepeddixj to REAL category\n",
      "Copied ddhfabwpuz to FAKE category\n",
      "Copied ddjggcasdw to FAKE category\n",
      "Copied ddpvuimigj to FAKE category\n",
      "Copied ddqccgmtka to FAKE category\n",
      "Copied degpbqvcay to FAKE category\n",
      "Copied deywhkarol to FAKE category\n",
      "Copied deyyistcrd to FAKE category\n",
      "Copied dfbpceeaox to FAKE category\n",
      "Copied dgmevclvzy to FAKE category\n",
      "Copied dgxrqjdomn to FAKE category\n",
      "Copied dgzklxjmix to FAKE category\n",
      "Copied dhcndnuwta to REAL category\n",
      "Copied dhcselezer to FAKE category\n",
      "Copied dhevettufk to FAKE category\n",
      "Copied dhjmzhrcav to FAKE category\n",
      "Copied dhkwmjxwrn to FAKE category\n",
      "Copied dhoqofwoxa to FAKE category\n",
      "Copied dhxctgyoqj to REAL category\n",
      "Copied diomeixhrg to FAKE category\n",
      "Copied diopzaywor to FAKE category\n",
      "Copied diqraixiov to FAKE category\n",
      "Copied diuzrpqjli to FAKE category\n",
      "Copied djvtbgwdcc to FAKE category\n",
      "Copied djvutyvaio to FAKE category\n",
      "Copied djxdyjopjd to REAL category\n",
      "Copied dkdwxmtpuo to FAKE category\n",
      "Copied dkhlttuvmx to FAKE category\n",
      "Copied dkrvorliqc to FAKE category\n",
      "Copied dkuayagnmc to REAL category\n",
      "Copied dkwjwbwgey to FAKE category\n",
      "Copied dkzvdrzcnr to REAL category\n",
      "Copied dlpoieqvfb to REAL category\n",
      "Copied dlrsbscitn to FAKE category\n",
      "Copied dnexlwbcxq to FAKE category\n",
      "Copied dnhvalzvrt to FAKE category\n",
      "Copied dntkzzzcdh to FAKE category\n",
      "Copied dnyvfblxpm to FAKE category\n",
      "Copied doanjploai to FAKE category\n",
      "Copied dofusvhnib to FAKE category\n",
      "Copied dozyddhild to FAKE category\n",
      "Copied dptbnjnkdg to FAKE category\n",
      "Copied dptrzdvwpg to FAKE category\n",
      "Copied dqnyszdong to FAKE category\n",
      "Copied dqppxmoqdl to FAKE category\n",
      "Copied dqqtjcryjv to FAKE category\n",
      "Copied dqswpjoepo to FAKE category\n",
      "Copied dqzreruvje to FAKE category\n",
      "Copied drcyabprvt to REAL category\n",
      "Copied drgjzlxzxj to FAKE category\n",
      "Copied drsakwyvqv to FAKE category\n",
      "Copied drtbksnpol to FAKE category\n",
      "Copied dsdoseflas to FAKE category\n",
      "Copied dsgpbgsrdm to FAKE category\n",
      "Copied dsjbknkujw to REAL category\n",
      "Copied dsndhujjjb to FAKE category\n",
      "Copied dtbpmdqvao to FAKE category\n",
      "Copied dtocdfbwca to FAKE category\n",
      "Copied dubiroskqn to FAKE category\n",
      "Copied dulanfulol to FAKE category\n",
      "Copied duvyaxbzvp to FAKE category\n",
      "Copied duycddgtrl to REAL category\n",
      "Copied duzuusuajr to FAKE category\n",
      "Copied dvakowbgbt to FAKE category\n",
      "Copied dvumqqhoac to FAKE category\n",
      "Copied dwediigjit to FAKE category\n",
      "Copied dxbqjxrhin to REAL category\n",
      "Copied dxuliowugt to FAKE category\n",
      "Copied dxuplhwvig to FAKE category\n",
      "Copied dzieklokdr to FAKE category\n",
      "Copied dzqwgqewhu to FAKE category\n",
      "Copied dzvyfiarrq to FAKE category\n",
      "Copied dzwkmcwkwl to FAKE category\n",
      "Copied dzyuwjkjui to REAL category\n",
      "Copied eahlqmfvtj to FAKE category\n",
      "Copied eajlrktemq to FAKE category\n",
      "Copied ebchwmwayp to FAKE category\n",
      "Copied ebebgmtlcu to FAKE category\n",
      "Copied ebeknhudxq to FAKE category\n",
      "Copied ebkzwjgjhq to FAKE category\n",
      "Copied ebywfrmhtd to FAKE category\n",
      "Copied eckvhdusax to REAL category\n",
      "Copied ecnihjlfyt to FAKE category\n",
      "Copied ecujsjhscd to REAL category\n",
      "Copied ecuvtoltue to FAKE category\n",
      "Copied ecwaxgutkc to FAKE category\n",
      "Copied eczrseixwq to FAKE category\n",
      "Copied edyncaijwx to REAL category\n",
      "Copied eebrkicpry to FAKE category\n",
      "Copied eebserckhh to FAKE category\n",
      "Copied eejswgycjc to FAKE category\n",
      "Copied eekozbeafq to FAKE category\n",
      "Copied eepezmygaq to FAKE category\n",
      "Copied eeyhxisdfh to FAKE category\n",
      "Copied efdyrflcpg to FAKE category\n",
      "Copied efwfxwwlbw to REAL category\n",
      "Copied egbbcxcuqy to FAKE category\n",
      "Copied eggbjzxnmg to REAL category\n",
      "Copied egghxjjmfg to REAL category\n",
      "Copied ehbnclaukr to FAKE category\n",
      "Copied ehccixxzoe to REAL category\n",
      "Copied ehdkmxgtxh to FAKE category\n",
      "Copied ehevsxtecd to FAKE category\n",
      "Copied ehfiekigla to FAKE category\n",
      "Copied ehieahnhte to FAKE category\n",
      "Copied ehtdtkmmli to REAL category\n",
      "Copied eiriyukqqy to FAKE category\n",
      "Copied eivxffliio to FAKE category\n",
      "Copied eiwopxzjfn to FAKE category\n",
      "Copied eixwxvxbbn to FAKE category\n",
      "Copied ejkqesyvam to FAKE category\n",
      "Copied ekcrtigpab to REAL category\n",
      "Copied ekhacizpah to FAKE category\n",
      "Copied ekkdjkirzq to FAKE category\n",
      "Copied elginszwtk to FAKE category\n",
      "Copied ellavthztb to REAL category\n",
      "Copied elvvackpjh to FAKE category\n",
      "Copied emaalmsonj to FAKE category\n",
      "Copied emfbhytfhc to FAKE category\n",
      "Copied emgjphonqb to FAKE category\n",
      "Copied ensyyivobf to FAKE category\n",
      "Copied eoewqcpbgt to FAKE category\n",
      "Copied eprybmbpba to FAKE category\n",
      "Copied epymyyiblu to FAKE category\n",
      "Copied eqjscdagiv to FAKE category\n",
      "Copied eqnoqyfquo to REAL category\n",
      "Copied eqvuznuwsa to FAKE category\n",
      "Copied erlvuvjsjf to REAL category\n",
      "Copied erqgqacbqe to FAKE category\n",
      "Copied errocgcham to FAKE category\n",
      "Copied esckbnkkvb to FAKE category\n",
      "Copied esgftaficx to FAKE category\n",
      "Copied esnntzzajv to FAKE category\n",
      "Copied esxrvsgpvb to FAKE category\n",
      "Copied esyhwdfnxs to FAKE category\n",
      "Copied esyrimvzsa to FAKE category\n",
      "Copied etdcqxabww to FAKE category\n",
      "Copied etejaapnxh to FAKE category\n",
      "Copied etmcruaihe to FAKE category\n",
      "Copied etohcvnzbj to FAKE category\n",
      "Copied eudeqjhdfd to REAL category\n",
      "Copied eukvucdetx to FAKE category\n",
      "Organization complete!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T08:21:25.833506Z",
     "start_time": "2024-10-11T08:21:25.439124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#FOR SQUEEZENET\n",
    "# ORAGANIZED THE FEATURES.NPY OF EACH VIDEO ACCORDING TO THERE LABEL FROM METADATA.JSON FILE \n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "input_frames_dir = \"output_frames_squeezenet\"\n",
    "output_dir = \"organized_frames_squeezenet\"\n",
    "metadata_file = \"metadata.json\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(os.path.join(output_dir, \"REAL\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, \"FAKE\"), exist_ok=True)\n",
    "\n",
    "# Read metadata\n",
    "with open(metadata_file, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Process each video\n",
    "for video, info in metadata.items():\n",
    "    label = info[\"label\"]\n",
    "    video_name = os.path.splitext(video)[0]  # Remove the .mp4 extension\n",
    "\n",
    "    # Source and destination paths\n",
    "    src_path = os.path.join(input_frames_dir, video_name)\n",
    "    dst_path = os.path.join(output_dir, label, video_name)\n",
    "\n",
    "    # Check if the source directory exists\n",
    "    if os.path.exists(src_path):\n",
    "        # Copy the frame folder to the appropriate category\n",
    "        shutil.copytree(src_path, dst_path)\n",
    "        print(f\"Copied {video_name} to {label} category\")\n",
    "    else:\n",
    "        print(f\"Warning: Frame folder for {video_name} not found\")\n",
    "\n",
    "print(\"Organization complete!\")"
   ],
   "id": "6fa8ba5136001350",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied aagfhgtpmv to FAKE category\n",
      "Copied aapnvogymq to FAKE category\n",
      "Copied abarnvbtwb to REAL category\n",
      "Copied abofeumbvv to FAKE category\n",
      "Copied abqwwspghj to FAKE category\n",
      "Copied acifjvzvpm to FAKE category\n",
      "Copied acqfdwsrhi to FAKE category\n",
      "Copied acxnxvbsxk to FAKE category\n",
      "Copied acxwigylke to FAKE category\n",
      "Copied aczrgyricp to FAKE category\n",
      "Copied adhsbajydo to FAKE category\n",
      "Copied adohikbdaz to FAKE category\n",
      "Copied adylbeequz to FAKE category\n",
      "Copied aelfnikyqj to REAL category\n",
      "Copied aelzhcnwgf to FAKE category\n",
      "Copied aettqgevhz to FAKE category\n",
      "Copied aevrfsexku to FAKE category\n",
      "Copied afoovlsmtx to REAL category\n",
      "Copied agdkmztvby to FAKE category\n",
      "Copied agqphdxmwt to FAKE category\n",
      "Copied agrmhtjdlk to REAL category\n",
      "Copied ahbweevwpv to FAKE category\n",
      "Copied ahdbuwqxit to FAKE category\n",
      "Copied ahfazfbntc to FAKE category\n",
      "Copied ahqqqilsxt to REAL category\n",
      "Copied aipfdnwpoo to FAKE category\n",
      "Copied ajqslcypsw to REAL category\n",
      "Copied ajwpjhrbcv to FAKE category\n",
      "Copied aklqzsddfl to FAKE category\n",
      "Copied aknbdpmgua to FAKE category\n",
      "Copied aknmpoonls to FAKE category\n",
      "Copied akvmwkdyuv to FAKE category\n",
      "Copied akxoopqjqz to FAKE category\n",
      "Copied akzbnazxtz to FAKE category\n",
      "Copied aladcziidp to FAKE category\n",
      "Copied alaijyygdv to FAKE category\n",
      "Copied alninxcyhg to FAKE category\n",
      "Copied altziddtxi to FAKE category\n",
      "Copied alvgwypubw to FAKE category\n",
      "Copied amaivqofda to FAKE category\n",
      "Copied amowujxmzc to FAKE category\n",
      "Copied andaxzscny to FAKE category\n",
      "Copied aneclqfpbt to FAKE category\n",
      "Copied anpuvshzoo to REAL category\n",
      "Copied aorjvbyxhw to FAKE category\n",
      "Copied apatcsqejh to FAKE category\n",
      "Copied apgjqzkoma to FAKE category\n",
      "Copied apogckdfrz to FAKE category\n",
      "Copied aqpnvjhuzw to FAKE category\n",
      "Copied arkroixhey to FAKE category\n",
      "Copied arlmiizoob to FAKE category\n",
      "Copied arrhsnjqku to FAKE category\n",
      "Copied asaxgevnnp to REAL category\n",
      "Copied asdpeebotb to FAKE category\n",
      "Copied aslsvlvpth to FAKE category\n",
      "Copied asmpfjfzif to FAKE category\n",
      "Copied asvcrfdpnq to FAKE category\n",
      "Copied atkdltyyen to REAL category\n",
      "Copied atvmxvwyns to REAL category\n",
      "Copied atxvxouljq to FAKE category\n",
      "Copied atyntldecu to FAKE category\n",
      "Copied atzdznmder to FAKE category\n",
      "Copied aufmsmnoye to FAKE category\n",
      "Copied augtsuxpzc to FAKE category\n",
      "Copied avfitoutyn to FAKE category\n",
      "Copied avgiuextiz to FAKE category\n",
      "Copied avibnnhwhp to FAKE category\n",
      "Copied avmjormvsx to REAL category\n",
      "Copied avnqydkqjj to FAKE category\n",
      "Copied avssvvsdhz to FAKE category\n",
      "Copied avtycwsgyb to FAKE category\n",
      "Copied avvdgsennp to FAKE category\n",
      "Copied avywawptfc to FAKE category\n",
      "Copied awhmfnnjih to FAKE category\n",
      "Copied awnwkrqibf to FAKE category\n",
      "Copied awukslzjra to FAKE category\n",
      "Copied axczxisdtb to FAKE category\n",
      "Copied axntxmycwd to REAL category\n",
      "Copied axoygtekut to FAKE category\n",
      "Copied axwgcsyphv to FAKE category\n",
      "Copied axwovszumc to FAKE category\n",
      "Copied aybgughjxh to REAL category\n",
      "Copied aybumesmpk to REAL category\n",
      "Copied ayqvfdhslr to FAKE category\n",
      "Copied aytzyidmgs to REAL category\n",
      "Copied azpuxunqyo to FAKE category\n",
      "Copied azsmewqghg to FAKE category\n",
      "Copied bahdpoesir to FAKE category\n",
      "Copied bbhpvrmbse to FAKE category\n",
      "Copied bbhtdfuqxq to FAKE category\n",
      "Copied bbvgxeczei to FAKE category\n",
      "Copied bchnbulevv to FAKE category\n",
      "Copied bctvsmddgq to FAKE category\n",
      "Copied bdbhekrrwo to FAKE category\n",
      "Copied bddjdhzfze to REAL category\n",
      "Copied bdgipnyobr to FAKE category\n",
      "Copied bdnaqemxmr to REAL category\n",
      "Copied bdxuhamuqx to FAKE category\n",
      "Copied beboztfcme to REAL category\n",
      "Copied bejhvclboh to REAL category\n",
      "Copied benmsfzfaz to FAKE category\n",
      "Copied beyebyhrph to REAL category\n",
      "Copied bffwsjxghk to REAL category\n",
      "Copied bgaogsjehq to FAKE category\n",
      "Copied bggsurpgpr to FAKE category\n",
      "Copied bghphrsfxf to FAKE category\n",
      "Copied bgmlwsoamc to FAKE category\n",
      "Copied bguwlyazau to FAKE category\n",
      "Copied bgvhtpzknn to REAL category\n",
      "Copied bgwmmujlmc to REAL category\n",
      "Copied bhaaboftbc to FAKE category\n",
      "Copied bhbdugnurr to FAKE category\n",
      "Copied bhpwpydzpo to FAKE category\n",
      "Copied bhsluedavd to FAKE category\n",
      "Copied bilnggbxgu to REAL category\n",
      "Copied bjjbwsqjir to FAKE category\n",
      "Copied bjkmjilrxp to FAKE category\n",
      "Copied bjsmaqefoi to FAKE category\n",
      "Copied bkmdzhfzfh to FAKE category\n",
      "Copied bkvetcojbt to FAKE category\n",
      "Copied bkwxhglwct to FAKE category\n",
      "Copied blpchvmhxx to FAKE category\n",
      "Copied blzydqdfem to FAKE category\n",
      "Copied bmbbkwmxqj to FAKE category\n",
      "Copied bmehkyanbj to FAKE category\n",
      "Copied bmhvktyiwp to FAKE category\n",
      "Copied bmioepcpsx to FAKE category\n",
      "Copied bmjmjmbglm to FAKE category\n",
      "Copied bmjzrlszhi to REAL category\n",
      "Copied bnbuonyoje to FAKE category\n",
      "Copied bndybcqhfr to FAKE category\n",
      "Copied bnjcdrfuov to FAKE category\n",
      "Copied bntlodcfeg to FAKE category\n",
      "Copied bofqajtwve to FAKE category\n",
      "Copied boovltmuwi to FAKE category\n",
      "Copied bopqhhalml to FAKE category\n",
      "Copied bourlmzsio to FAKE category\n",
      "Copied bpapbctoao to REAL category\n",
      "Copied bpwzipqtxf to FAKE category\n",
      "Copied bpxckdzddv to FAKE category\n",
      "Copied bqdjzqhcft to FAKE category\n",
      "Copied bqeiblbxtl to FAKE category\n",
      "Copied bqhtpqmmqp to FAKE category\n",
      "Copied bqkdbcqjvb to FAKE category\n",
      "Copied bqnymlsayl to FAKE category\n",
      "Copied bqqpbzjgup to FAKE category\n",
      "Copied bqtuuwzdtr to FAKE category\n",
      "Copied brhalypwoo to FAKE category\n",
      "Copied brvqtabyxj to FAKE category\n",
      "Copied brwrlczjvi to REAL category\n",
      "Copied bseamdrpbj to FAKE category\n",
      "Copied bsfmwclnqy to FAKE category\n",
      "Copied bsqgziaylx to FAKE category\n",
      "Copied btiysiskpf to FAKE category\n",
      "Copied btjlfpzbdu to FAKE category\n",
      "Copied btjwbtsgln to FAKE category\n",
      "Copied btmsngnqhv to FAKE category\n",
      "Copied btohlidmru to FAKE category\n",
      "Copied btugrnoton to FAKE category\n",
      "Copied btunxncpjh to FAKE category\n",
      "Copied btxlttbpkj to FAKE category\n",
      "Copied bulkxhhknf to REAL category\n",
      "Copied bvgwelbeof to FAKE category\n",
      "Copied bvzjkezkms to FAKE category\n",
      "Copied bweezhfpzp to FAKE category\n",
      "Copied bwhlgysghg to REAL category\n",
      "Copied bwipwzzxxu to REAL category\n",
      "Copied bwuwstvsbw to FAKE category\n",
      "Copied bxzakyopjf to REAL category\n",
      "Copied bydaidkpdp to FAKE category\n",
      "Copied byfenovjnf to FAKE category\n",
      "Copied byijojkdba to FAKE category\n",
      "Copied byofowlkki to FAKE category\n",
      "Copied byqzyxifza to FAKE category\n",
      "Copied byunigvnay to FAKE category\n",
      "Copied byyqectxqa to FAKE category\n",
      "Copied bzmdrafeex to FAKE category\n",
      "Copied bzythlfnhq to REAL category\n",
      "Copied caifxvsozs to REAL category\n",
      "Copied caqbrkogkb to FAKE category\n",
      "Copied cbbibzcoih to FAKE category\n",
      "Copied cbltdtxglo to FAKE category\n",
      "Copied ccfoszqabv to REAL category\n",
      "Copied ccmonzqfrz to FAKE category\n",
      "Copied cdaxixbosp to FAKE category\n",
      "Copied cdbsbdymzd to FAKE category\n",
      "Copied cdphtzqrvp to FAKE category\n",
      "Copied cdyakrxkia to FAKE category\n",
      "Copied cepxysienc to FAKE category\n",
      "Copied cettndmvzl to FAKE category\n",
      "Copied ceymbecxnj to FAKE category\n",
      "Copied cferslmfwh to FAKE category\n",
      "Copied cffffbcywc to FAKE category\n",
      "Copied cfxkpiweqt to REAL category\n",
      "Copied cfyduhpbps to FAKE category\n",
      "Copied cglxirfaey to FAKE category\n",
      "Copied cgvrgibpfo to FAKE category\n",
      "Copied chtapglbcj to REAL category\n",
      "Copied chviwxsfhg to REAL category\n",
      "Copied chzieimrwu to FAKE category\n",
      "Copied ciyoudyhly to REAL category\n",
      "Copied cizlkenljw to REAL category\n",
      "Copied ckbdwedgmc to FAKE category\n",
      "Copied ckjaibzfxa to REAL category\n",
      "Copied ckkuyewywx to REAL category\n",
      "Copied cknyxaqouy to FAKE category\n",
      "Copied cksanfsjhc to FAKE category\n",
      "Copied clihsshdkq to FAKE category\n",
      "Copied clrycekyst to REAL category\n",
      "Copied cmbzllswnl to REAL category\n",
      "Copied cmxcfkrjiv to FAKE category\n",
      "Copied cnilkgvfei to FAKE category\n",
      "Copied coadfnerlk to FAKE category\n",
      "Copied cobjrlugvp to REAL category\n",
      "Copied covdcysmbi to FAKE category\n",
      "Copied cpjxareypw to REAL category\n",
      "Copied cppdvdejkc to REAL category\n",
      "Copied cprhtltsjp to REAL category\n",
      "Copied cqfugiqupm to FAKE category\n",
      "Copied cqhngvpgyi to FAKE category\n",
      "Copied cqrskwiqng to FAKE category\n",
      "Copied crezycjqyk to REAL category\n",
      "Copied crktehraph to FAKE category\n",
      "Copied crzfebnfgb to FAKE category\n",
      "Copied cthdnahrkh to FAKE category\n",
      "Copied ctpqeykqdp to FAKE category\n",
      "Copied cttqtsjvgn to FAKE category\n",
      "Copied ctzmavwror to FAKE category\n",
      "Copied curpwogllm to FAKE category\n",
      "Copied cuzrgrbvil to FAKE category\n",
      "Copied cvaksbpssm to FAKE category\n",
      "Copied cwbacdwrzo to FAKE category\n",
      "Copied cwqlvzefpg to FAKE category\n",
      "Copied cwrtyzndpx to FAKE category\n",
      "Copied cwsbspfzck to FAKE category\n",
      "Copied cwwandrkus to FAKE category\n",
      "Copied cxfujlvsuw to FAKE category\n",
      "Copied cxrfacemmq to FAKE category\n",
      "Copied cxttmymlbn to FAKE category\n",
      "Copied cyboodqqyr to FAKE category\n",
      "Copied cycacemkmt to FAKE category\n",
      "Copied cyclgfjdrv to FAKE category\n",
      "Copied cyxlcuyznd to REAL category\n",
      "Copied czfunozvwp to FAKE category\n",
      "Copied czkdanyadc to FAKE category\n",
      "Copied czmqpxrqoh to FAKE category\n",
      "Copied dafhtipaml to FAKE category\n",
      "Copied dakiztgtnw to REAL category\n",
      "Copied dakqwktlbi to FAKE category\n",
      "Copied dbhoxkblzx to FAKE category\n",
      "Copied dbhrpizyeq to FAKE category\n",
      "Copied dbnygxtwek to REAL category\n",
      "Copied dboxtiehng to FAKE category\n",
      "Copied dbtbbhakdv to REAL category\n",
      "Copied dbzcqmxzaj to FAKE category\n",
      "Copied dbzpcjntve to FAKE category\n",
      "Copied dcamvmuors to FAKE category\n",
      "Copied dcuiiorugd to FAKE category\n",
      "Copied ddepeddixj to REAL category\n",
      "Copied ddhfabwpuz to FAKE category\n",
      "Copied ddjggcasdw to FAKE category\n",
      "Copied ddpvuimigj to FAKE category\n",
      "Copied ddqccgmtka to FAKE category\n",
      "Copied degpbqvcay to FAKE category\n",
      "Copied deywhkarol to FAKE category\n",
      "Copied deyyistcrd to FAKE category\n",
      "Copied dfbpceeaox to FAKE category\n",
      "Copied dgmevclvzy to FAKE category\n",
      "Copied dgxrqjdomn to FAKE category\n",
      "Copied dgzklxjmix to FAKE category\n",
      "Copied dhcndnuwta to REAL category\n",
      "Copied dhcselezer to FAKE category\n",
      "Copied dhevettufk to FAKE category\n",
      "Copied dhjmzhrcav to FAKE category\n",
      "Copied dhkwmjxwrn to FAKE category\n",
      "Copied dhoqofwoxa to FAKE category\n",
      "Copied dhxctgyoqj to REAL category\n",
      "Copied diomeixhrg to FAKE category\n",
      "Copied diopzaywor to FAKE category\n",
      "Copied diqraixiov to FAKE category\n",
      "Copied diuzrpqjli to FAKE category\n",
      "Copied djvtbgwdcc to FAKE category\n",
      "Copied djvutyvaio to FAKE category\n",
      "Copied djxdyjopjd to REAL category\n",
      "Copied dkdwxmtpuo to FAKE category\n",
      "Copied dkhlttuvmx to FAKE category\n",
      "Copied dkrvorliqc to FAKE category\n",
      "Copied dkuayagnmc to REAL category\n",
      "Copied dkwjwbwgey to FAKE category\n",
      "Copied dkzvdrzcnr to REAL category\n",
      "Copied dlpoieqvfb to REAL category\n",
      "Copied dlrsbscitn to FAKE category\n",
      "Copied dnexlwbcxq to FAKE category\n",
      "Copied dnhvalzvrt to FAKE category\n",
      "Copied dntkzzzcdh to FAKE category\n",
      "Copied dnyvfblxpm to FAKE category\n",
      "Copied doanjploai to FAKE category\n",
      "Copied dofusvhnib to FAKE category\n",
      "Copied dozyddhild to FAKE category\n",
      "Copied dptbnjnkdg to FAKE category\n",
      "Copied dptrzdvwpg to FAKE category\n",
      "Copied dqnyszdong to FAKE category\n",
      "Copied dqppxmoqdl to FAKE category\n",
      "Copied dqqtjcryjv to FAKE category\n",
      "Copied dqswpjoepo to FAKE category\n",
      "Copied dqzreruvje to FAKE category\n",
      "Copied drcyabprvt to REAL category\n",
      "Copied drgjzlxzxj to FAKE category\n",
      "Copied drsakwyvqv to FAKE category\n",
      "Copied drtbksnpol to FAKE category\n",
      "Copied dsdoseflas to FAKE category\n",
      "Copied dsgpbgsrdm to FAKE category\n",
      "Copied dsjbknkujw to REAL category\n",
      "Copied dsndhujjjb to FAKE category\n",
      "Copied dtbpmdqvao to FAKE category\n",
      "Copied dtocdfbwca to FAKE category\n",
      "Copied dubiroskqn to FAKE category\n",
      "Copied dulanfulol to FAKE category\n",
      "Copied duvyaxbzvp to FAKE category\n",
      "Copied duycddgtrl to REAL category\n",
      "Copied duzuusuajr to FAKE category\n",
      "Copied dvakowbgbt to FAKE category\n",
      "Copied dvumqqhoac to FAKE category\n",
      "Copied dwediigjit to FAKE category\n",
      "Copied dxbqjxrhin to REAL category\n",
      "Copied dxuliowugt to FAKE category\n",
      "Copied dxuplhwvig to FAKE category\n",
      "Copied dzieklokdr to FAKE category\n",
      "Copied dzqwgqewhu to FAKE category\n",
      "Copied dzvyfiarrq to FAKE category\n",
      "Copied dzwkmcwkwl to FAKE category\n",
      "Copied dzyuwjkjui to REAL category\n",
      "Copied eahlqmfvtj to FAKE category\n",
      "Copied eajlrktemq to FAKE category\n",
      "Copied ebchwmwayp to FAKE category\n",
      "Copied ebebgmtlcu to FAKE category\n",
      "Copied ebeknhudxq to FAKE category\n",
      "Copied ebkzwjgjhq to FAKE category\n",
      "Copied ebywfrmhtd to FAKE category\n",
      "Copied eckvhdusax to REAL category\n",
      "Copied ecnihjlfyt to FAKE category\n",
      "Copied ecujsjhscd to REAL category\n",
      "Copied ecuvtoltue to FAKE category\n",
      "Copied ecwaxgutkc to FAKE category\n",
      "Copied eczrseixwq to FAKE category\n",
      "Copied edyncaijwx to REAL category\n",
      "Copied eebrkicpry to FAKE category\n",
      "Copied eebserckhh to FAKE category\n",
      "Copied eejswgycjc to FAKE category\n",
      "Copied eekozbeafq to FAKE category\n",
      "Copied eepezmygaq to FAKE category\n",
      "Copied eeyhxisdfh to FAKE category\n",
      "Copied efdyrflcpg to FAKE category\n",
      "Copied efwfxwwlbw to REAL category\n",
      "Copied egbbcxcuqy to FAKE category\n",
      "Copied eggbjzxnmg to REAL category\n",
      "Copied egghxjjmfg to REAL category\n",
      "Copied ehbnclaukr to FAKE category\n",
      "Copied ehccixxzoe to REAL category\n",
      "Copied ehdkmxgtxh to FAKE category\n",
      "Copied ehevsxtecd to FAKE category\n",
      "Copied ehfiekigla to FAKE category\n",
      "Copied ehieahnhte to FAKE category\n",
      "Copied ehtdtkmmli to REAL category\n",
      "Copied eiriyukqqy to FAKE category\n",
      "Copied eivxffliio to FAKE category\n",
      "Copied eiwopxzjfn to FAKE category\n",
      "Copied eixwxvxbbn to FAKE category\n",
      "Copied ejkqesyvam to FAKE category\n",
      "Copied ekcrtigpab to REAL category\n",
      "Copied ekhacizpah to FAKE category\n",
      "Copied ekkdjkirzq to FAKE category\n",
      "Copied elginszwtk to FAKE category\n",
      "Copied ellavthztb to REAL category\n",
      "Copied elvvackpjh to FAKE category\n",
      "Copied emaalmsonj to FAKE category\n",
      "Copied emfbhytfhc to FAKE category\n",
      "Copied emgjphonqb to FAKE category\n",
      "Copied ensyyivobf to FAKE category\n",
      "Copied eoewqcpbgt to FAKE category\n",
      "Copied eprybmbpba to FAKE category\n",
      "Copied epymyyiblu to FAKE category\n",
      "Copied eqjscdagiv to FAKE category\n",
      "Copied eqnoqyfquo to REAL category\n",
      "Copied eqvuznuwsa to FAKE category\n",
      "Copied erlvuvjsjf to REAL category\n",
      "Copied erqgqacbqe to FAKE category\n",
      "Copied errocgcham to FAKE category\n",
      "Copied esckbnkkvb to FAKE category\n",
      "Copied esgftaficx to FAKE category\n",
      "Copied esnntzzajv to FAKE category\n",
      "Copied esxrvsgpvb to FAKE category\n",
      "Copied esyhwdfnxs to FAKE category\n",
      "Copied esyrimvzsa to FAKE category\n",
      "Copied etdcqxabww to FAKE category\n",
      "Copied etejaapnxh to FAKE category\n",
      "Copied etmcruaihe to FAKE category\n",
      "Copied etohcvnzbj to FAKE category\n",
      "Copied eudeqjhdfd to REAL category\n",
      "Copied eukvucdetx to FAKE category\n",
      "Organization complete!\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T08:23:50.012256Z",
     "start_time": "2024-10-11T08:23:49.934273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DID CLASSIFICATION USING SVM AND KNN FOR INCEPTION\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames_inception\"\n",
    "categories = [\"FAKE\", \"REAL\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM Model\n",
    "print(\"Training SVM model...\")\n",
    "svm_model = SVC(kernel='sigmoid')  # You can experiment with different kernels like 'rbf'\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# KNN Model\n",
    "print(\"Training KNN model...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=4)  # You can adjust the number of neighbors\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate KNN\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(f\"KNN Accuracy: {accuracy_score(y_test, y_pred_knn):.2f}\")"
   ],
   "id": "609fdbf4ce2e6eb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FAKE videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:00<00:00, 9839.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing REAL videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 8825.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM model...\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        64\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.40      0.50      0.44        80\n",
      "weighted avg       0.64      0.80      0.71        80\n",
      "\n",
      "SVM Accuracy: 0.80\n",
      "Training KNN model...\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89        64\n",
      "           1       0.67      0.12      0.21        16\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.74      0.55      0.55        80\n",
      "weighted avg       0.79      0.81      0.76        80\n",
      "\n",
      "KNN Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T08:24:03.235864Z",
     "start_time": "2024-10-11T08:24:03.168433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DID CLASSIFICATION USING SVM AND KNN FOR SQUEEZENET\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames_squeezenet\"\n",
    "categories = [\"FAKE\", \"REAL\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM Model\n",
    "print(\"Training SVM model...\")\n",
    "svm_model = SVC(kernel='sigmoid')  # You can experiment with different kernels like 'rbf'\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# KNN Model\n",
    "print(\"Training KNN model...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=4)  # You can adjust the number of neighbors\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate KNN\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(f\"KNN Accuracy: {accuracy_score(y_test, y_pred_knn):.2f}\")"
   ],
   "id": "5cbcb0cc3a384f46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FAKE videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:00<00:00, 9949.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing REAL videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 10426.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM model...\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        64\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.40      0.50      0.44        80\n",
      "weighted avg       0.64      0.80      0.71        80\n",
      "\n",
      "SVM Accuracy: 0.80\n",
      "Training KNN model...\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89        64\n",
      "           1       0.67      0.12      0.21        16\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.74      0.55      0.55        80\n",
      "weighted avg       0.79      0.81      0.76        80\n",
      "\n",
      "KNN Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/Implementation/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T08:35:52.645501Z",
     "start_time": "2024-10-11T08:35:50.494252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#before code is class imbalanced\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE for oversampling\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames_squeezenet\"\n",
    "categories = [\"FAKE\", \"REAL\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "print(\"Applying SMOTE to balance classes...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# SVM Model with class weights\n",
    "print(\"Training SVM model with class weights...\")\n",
    "svm_model = SVC(kernel='sigmoid', class_weight='balanced')  # Use 'balanced' to handle class imbalance\n",
    "svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# KNN Model\n",
    "print(\"Training KNN model...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=4)  # Adjust the number of neighbors as needed\n",
    "knn_model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate KNN\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(f\"KNN Accuracy: {accuracy_score(y_test, y_pred_knn):.2f}\")\n"
   ],
   "id": "11ff439f82e40016",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FAKE videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:00<00:00, 5576.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing REAL videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 6692.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE to balance classes...\n",
      "Training SVM model with class weights...\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.34      0.48        64\n",
      "           1       0.21      0.69      0.32        16\n",
      "\n",
      "    accuracy                           0.41        80\n",
      "   macro avg       0.51      0.52      0.40        80\n",
      "weighted avg       0.69      0.41      0.45        80\n",
      "\n",
      "SVM Accuracy: 0.41\n",
      "Training KNN model...\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.48      0.61        64\n",
      "           1       0.23      0.62      0.34        16\n",
      "\n",
      "    accuracy                           0.51        80\n",
      "   macro avg       0.54      0.55      0.48        80\n",
      "weighted avg       0.72      0.51      0.56        80\n",
      "\n",
      "KNN Accuracy: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T08:43:11.638793Z",
     "start_time": "2024-10-11T08:43:11.524440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#before code is class imbalanced\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE for oversampling\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames_inception\"\n",
    "categories = [\"FAKE\", \"REAL\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "print(\"Applying SMOTE to balance classes...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# SVM Model with class weights\n",
    "print(\"Training SVM model with class weights...\")\n",
    "svm_model = SVC(kernel='sigmoid', class_weight='balanced')  # Use 'balanced' to handle class imbalance\n",
    "svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# KNN Model\n",
    "print(\"Training KNN model...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=4)  # Adjust the number of neighbors as needed\n",
    "knn_model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate KNN\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(f\"KNN Accuracy: {accuracy_score(y_test, y_pred_knn):.2f}\")\n"
   ],
   "id": "ff8cc60e852fab9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FAKE videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:00<00:00, 11202.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing REAL videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 11201.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE to balance classes...\n",
      "Training SVM model with class weights...\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.34      0.48        64\n",
      "           1       0.21      0.69      0.32        16\n",
      "\n",
      "    accuracy                           0.41        80\n",
      "   macro avg       0.51      0.52      0.40        80\n",
      "weighted avg       0.69      0.41      0.45        80\n",
      "\n",
      "SVM Accuracy: 0.41\n",
      "Training KNN model...\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.48      0.61        64\n",
      "           1       0.23      0.62      0.34        16\n",
      "\n",
      "    accuracy                           0.51        80\n",
      "   macro avg       0.54      0.55      0.48        80\n",
      "weighted avg       0.72      0.51      0.56        80\n",
      "\n",
      "KNN Accuracy: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T08:42:06.183131Z",
     "start_time": "2024-10-11T08:40:50.007883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE for oversampling\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames_squeezenet\"\n",
    "categories = [\"FAKE\", \"REAL\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "print(\"Applying SMOTE to balance classes...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# SVM Model with class weights\n",
    "print(\"Training SVM model with class weights...\")\n",
    "svm_model = SVC(kernel='sigmoid', class_weight='balanced')  # Use 'balanced' to handle class imbalance\n",
    "svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# Random Forest with Hyperparameter Tuning\n",
    "print(\"Training Random Forest model with hyperparameter tuning...\")\n",
    "\n",
    "# Define the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "print(f\"Best parameters for Random Forest: {grid_search.best_params_}\")\n",
    "\n",
    "# Make predictions with the tuned Random Forest model\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf):.2f}\")\n"
   ],
   "id": "62f8ae2cc70b7c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FAKE videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:00<00:00, 6390.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing REAL videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 6093.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE to balance classes...\n",
      "Training SVM model with class weights...\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.34      0.48        64\n",
      "           1       0.21      0.69      0.32        16\n",
      "\n",
      "    accuracy                           0.41        80\n",
      "   macro avg       0.51      0.52      0.40        80\n",
      "weighted avg       0.69      0.41      0.45        80\n",
      "\n",
      "SVM Accuracy: 0.41\n",
      "Training Random Forest model with hyperparameter tuning...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        64\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.39      0.46      0.42        80\n",
      "weighted avg       0.63      0.74      0.68        80\n",
      "\n",
      "Random Forest Accuracy: 0.74\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T08:45:03.342638Z",
     "start_time": "2024-10-11T08:43:50.461230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE for oversampling\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames_inception\"\n",
    "categories = [\"FAKE\", \"REAL\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "print(\"Applying SMOTE to balance classes...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# SVM Model with class weights\n",
    "print(\"Training SVM model with class weights...\")\n",
    "svm_model = SVC(kernel='sigmoid', class_weight='balanced')  # Use 'balanced' to handle class imbalance\n",
    "svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# Random Forest with Hyperparameter Tuning\n",
    "print(\"Training Random Forest model with hyperparameter tuning...\")\n",
    "\n",
    "# Define the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best estimator from the grid search\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "print(f\"Best parameters for Random Forest: {grid_search.best_params_}\")\n",
    "\n",
    "# Make predictions with the tuned Random Forest model\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf):.2f}\")\n"
   ],
   "id": "34e17ee548d66670",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FAKE videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:00<00:00, 11449.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing REAL videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 9409.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE to balance classes...\n",
      "Training SVM model with class weights...\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.34      0.48        64\n",
      "           1       0.21      0.69      0.32        16\n",
      "\n",
      "    accuracy                           0.41        80\n",
      "   macro avg       0.51      0.52      0.40        80\n",
      "weighted avg       0.69      0.41      0.45        80\n",
      "\n",
      "SVM Accuracy: 0.41\n",
      "Training Random Forest model with hyperparameter tuning...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "Best parameters for Random Forest: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        64\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.39      0.46      0.42        80\n",
      "weighted avg       0.63      0.74      0.68        80\n",
      "\n",
      "Random Forest Accuracy: 0.74\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T08:47:05.068599Z",
     "start_time": "2024-10-11T08:45:43.152346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE for oversampling\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames_inception\"\n",
    "categories = [\"FAKE\", \"REAL\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "print(\"Applying SMOTE to balance classes...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale the features for better SVM performance\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Hyperparameter Tuning for SVM\n",
    "print(\"Training SVM model with hyperparameter tuning...\")\n",
    "\n",
    "# Define the SVM classifier\n",
    "svm_model = SVC()\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [2, 3, 4]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best hyperparameters for SVM\n",
    "svm_grid_search = GridSearchCV(estimator=svm_model, param_grid=svm_param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "svm_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best SVM model\n",
    "best_svm_model = svm_grid_search.best_estimator_\n",
    "print(f\"Best parameters for SVM: {svm_grid_search.best_params_}\")\n",
    "\n",
    "# Make predictions with the tuned SVM model\n",
    "y_pred_svm = best_svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# Random Forest with Hyperparameter Tuning (same as before)\n",
    "print(\"Training Random Forest model with hyperparameter tuning...\")\n",
    "\n",
    "# Define the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best hyperparameters for Random Forest\n",
    "rf_grid_search = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "rf_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best Random Forest model\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "print(f\"Best parameters for Random Forest: {rf_grid_search.best_params_}\")\n",
    "\n",
    "# Make predictions with the tuned Random Forest model\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf):.2f}\")\n"
   ],
   "id": "996215ec217f0bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FAKE videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:00<00:00, 5896.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing REAL videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 6121.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE to balance classes...\n",
      "Training SVM model with hyperparameter tuning...\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVM: {'C': 100, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        64\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.38      0.41      0.40        80\n",
      "weighted avg       0.61      0.66      0.64        80\n",
      "\n",
      "SVM Accuracy: 0.66\n",
      "Training Random Forest model with hyperparameter tuning...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "Best parameters for Random Forest: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        64\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.39      0.46      0.42        80\n",
      "weighted avg       0.63      0.74      0.68        80\n",
      "\n",
      "Random Forest Accuracy: 0.74\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# SVM O.66 AND KNN 0.74",
   "id": "9ab150630e7f10c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T08:50:12.361935Z",
     "start_time": "2024-10-11T08:48:31.014695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE  # Import SMOTE for oversampling\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"organized_frames_squeezenet\"\n",
    "categories = [\"FAKE\", \"REAL\"]\n",
    "\n",
    "# Initialize data lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load features and labels\n",
    "for category in categories:\n",
    "    category_path = os.path.join(data_dir, category, \"\")\n",
    "    label = categories.index(category)\n",
    "    print(f\"Processing {category} videos...\")\n",
    "\n",
    "    for video_folder in tqdm(os.listdir(category_path)):\n",
    "        video_path = os.path.join(category_path, video_folder)\n",
    "        features_path = os.path.join(video_path, \"features.npy\")\n",
    "\n",
    "        if os.path.exists(features_path):\n",
    "            video_features = np.load(features_path)\n",
    "            features.append(video_features)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: features.npy not found in {video_path}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Ensure features and labels are not empty\n",
    "if len(features) == 0:\n",
    "    raise ValueError(\"Features array is empty. Please check the data loading process.\")\n",
    "\n",
    "# Flatten the features if necessary\n",
    "if len(features.shape) > 2:\n",
    "    features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "print(\"Applying SMOTE to balance classes...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale the features for better SVM performance\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Hyperparameter Tuning for SVM\n",
    "print(\"Training SVM model with hyperparameter tuning...\")\n",
    "\n",
    "# Define the SVM classifier\n",
    "svm_model = SVC()\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [2, 3, 4]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best hyperparameters for SVM\n",
    "svm_grid_search = GridSearchCV(estimator=svm_model, param_grid=svm_param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "svm_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best SVM model\n",
    "best_svm_model = svm_grid_search.best_estimator_\n",
    "print(f\"Best parameters for SVM: {svm_grid_search.best_params_}\")\n",
    "\n",
    "# Make predictions with the tuned SVM model\n",
    "y_pred_svm = best_svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate SVM\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
    "\n",
    "# Random Forest with Hyperparameter Tuning (same as before)\n",
    "print(\"Training Random Forest model with hyperparameter tuning...\")\n",
    "\n",
    "# Define the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best hyperparameters for Random Forest\n",
    "rf_grid_search = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "rf_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best Random Forest model\n",
    "best_rf_model = rf_grid_search.best_estimator_\n",
    "print(f\"Best parameters for Random Forest: {rf_grid_search.best_params_}\")\n",
    "\n",
    "# Make predictions with the tuned Random Forest model\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf):.2f}\")\n"
   ],
   "id": "38e5ee286816d6c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FAKE videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [00:00<00:00, 6618.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing REAL videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 6226.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE to balance classes...\n",
      "Training SVM model with hyperparameter tuning...\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "Best parameters for SVM: {'C': 100, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        64\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.66        80\n",
      "   macro avg       0.38      0.41      0.40        80\n",
      "weighted avg       0.61      0.66      0.64        80\n",
      "\n",
      "SVM Accuracy: 0.66\n",
      "Training Random Forest model with hyperparameter tuning...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=100, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .............C=1, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=10, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=10, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=10, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=100, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=100, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=0.1, degree=2, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=1, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=1, degree=3, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=10, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..........C=10, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=10, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=100, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=100, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=100, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......C=100, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END ........C=0.1, degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=0.1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .............C=1, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=3, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=4, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ........C=10, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=10, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=10, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=10, degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .........C=100, degree=2, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=100, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=3, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .......C=100, degree=3, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ..........C=100, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......C=0.1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=2, gamma=auto, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=0.1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=0.1, degree=4, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=0.1, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........C=1, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=2, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .............C=1, degree=2, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=1, degree=3, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..............C=1, degree=3, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=1, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .........C=1, degree=4, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .........C=10, degree=2, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=2, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .........C=10, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=scale, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=10, degree=4, gamma=scale, kernel=poly; total time=   0.1s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END .............C=10, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ............C=10, degree=4, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......C=100, degree=2, gamma=scale, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ........C=100, degree=3, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ...........C=100, degree=3, gamma=auto, kernel=poly; total time=   0.1s\n",
      "[CV] END ........C=100, degree=3, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ............C=100, degree=4, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........C=100, degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "Best parameters for Random Forest: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        64\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.74        80\n",
      "   macro avg       0.39      0.46      0.42        80\n",
      "weighted avg       0.63      0.74      0.68        80\n",
      "\n",
      "Random Forest Accuracy: 0.74\n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
